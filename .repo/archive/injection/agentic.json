{
  "metadata": {
    "date": "2026-01-23",
    "purpose": "Comprehensive mapping of EVERY file in the agentic coding system",
    "use_case": "Injection into other repositories, complete system documentation",
    "total_files_mapped": 120,
    "status": "Comprehensive mapping complete",
    "target_repository": "your-dedicated-marketer",
    "repository_type": "Next.js Marketing Website",
    "repository_characteristics": {
      "has_repo_directory": false,
      "has_governance_framework": false,
      "has_database": false,
      "has_user_auth": false,
      "deployment": "Cloudflare Pages",
      "tech_stack": ["Next.js 15.5.2", "React 19.2.3", "TypeScript 5.7.2", "Tailwind CSS"]
    },
    "orientation_note": "This mapping is oriented for your-dedicated-marketer. All .repo/ directory structure will be created. All paths remain as .repo/ paths. The priority/ directory can be deleted as it will be replaced by .repo/tasks/."
  },
  "categories": {
    "root_entry_points": {
      "description": "Root-level agent entry points",
      "files": [
        {
          "path": "/AGENTS.json",
          "type": "JSON Schema",
          "lines": 183,
          "purpose": "Machine-readable agent entry point with structured workflow definitions",
          "key_contents": [
            "Command routing (Start/Work/Task/Review/Security/Help)",
            "Required reading order (TODO.md → manifest.yaml → rules.json)",
            "Context determination logic (security, boundaries, backend/frontend, folder entry, unknown)",
            "Three-pass workflow definition (Pass 0: Context, Pass 1: Plan, Pass 2: Change, Pass 3: Verify)",
            "Task completion workflow",
            "PR creation requirements",
            "Rules (always/never)",
            "Decision trees (HITL needed?)",
            "Troubleshooting guidance"
          ],
          "dependencies": [
            ".repo/tasks/TODO.md",
            ".repo/repo.manifest.yaml",
            ".repo/agents/rules.json"
          ],
          "used_by": [
            "Agents as primary entry point"
          ],
          "schema": "JSON Schema draft-07",
          "content": "{\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"version\": \"1.0.0\",\n  \"type\": \"agent_entry_point\",\n  \"role\": \"AI coding agent operating in a governed repository. Complete tasks safely, following all rules and workflows.\",\n\n  \"command_routing\": {\n    \"Start\": \"follow_workflow\",\n    \"Work\": \"follow_workflow\",\n    \"Task\": \"follow_workflow\",\n    \"Review\": \"skip_to_pr_section\",\n    \"Security\": [\"read_security_baseline\", \"then_follow_workflow\"],\n    \"Help\": \"show_help_section\"\n  },\n\n  \"required_reading\": {\n    \"order\": [\n      \".repo/tasks/TODO.md\",\n      \".repo/repo.manifest.yaml\",\n      \".repo/agents/rules.json\"\n    ],\n    \"alternatives\": {\n      \"rules\": \".repo/agents/QUICK_REFERENCE.md\"\n    }\n  },\n\n  \"context_determination\": {\n    \"security\": {\n      \"triggers\": [\"auth\", \"money\", \"external_systems\", \"payment_flows\"],\n      \"action\": [\"read\", \".repo/policy/SECURITY_BASELINE.md\", \"create_hitl\", \"stop_work\"]\n    },\n    \"boundaries\": {\n      \"triggers\": [\"cross_module_imports\"],\n      \"action\": [\"read\", \".repo/policy/BOUNDARIES.md\", \"create_adr\"]\n    },\n    \"backend_frontend\": {\n      \"triggers\": [\"backend_code\", \"frontend_code\"],\n      \"action\": [\"read\", \".repo/policy/BESTPR.md\", \"read_folder_guide\", \"read_agent_context_json\"]\n    },\n    \"folder_entry\": {\n      \"triggers\": [\"entering_folder\"],\n      \"action\": [\"read\", \".agent-context.json\", \"read\", \".AGENT.md\"]\n    },\n    \"unknown\": {\n      \"triggers\": [\"not_in_docs\", \"not_in_manifest\", \"not_in_code\"],\n      \"action\": [\"mark_unknown\", \"read\", \".repo/policy/HITL.md\", \"create_hitl\", \"stop_work\"]\n    }\n  },\n\n  \"workflow\": {\n    \"three_pass\": {\n      \"pass0_context\": {\n        \"name\": \"Context\",\n        \"steps\": [\n          \"read_folder_context_files\",\n          \"read_agent_context_json_when_entering_folder\"\n        ],\n        \"description\": \"Read folder-level context files (.agent-context.json, .AGENT.md) when entering a folder\"\n      },\n      \"pass1_plan\": {\n        \"steps\": [\n          \"determine_change_type\",\n          \"list_all_actions\",\n          \"identify_risks\",\n          \"list_all_files_to_modify\",\n          \"mark_unknown_items\",\n          \"check_hitl_needed\",\n          \"create_task_packet_if_required\"\n        ],\n        \"output\": \"plan_with_actions_risks_files_unknowns_hitl\",\n        \"blockers\": {\n          \"hitl\": [\"create_hitl\", \"stop_work\", \"wait_completion\"],\n          \"adr\": [\"create_adr\", \"document_decision\"]\n        }\n      },\n      \"pass2_change\": {\n        \"steps\": [\n          \"apply_edits_from_plan\",\n          \"follow_existing_patterns\",\n          \"include_filepaths_global_rule\",\n          \"respect_boundaries\"\n        ],\n        \"output\": \"code_changes_with_filepaths\",\n        \"do_not_proceed_if\": [\n          \"pass1_blockers_exist\",\n          \"unknown_items_unresolved\",\n          \"security_risky_without_hitl_approval\"\n        ]\n      },\n      \"pass3_verify\": {\n        \"steps\": [\n          \"run_tests_from_manifest\",\n          \"provide_evidence\",\n          \"update_logs\",\n          \"check_quality_gates\",\n          \"document_in_pr\"\n        ],\n        \"output\": \"evidence_updated_logs_passing_tests\"\n      }\n    }\n  },\n\n  \"task_completion\": {\n    \"steps\": [\n      \"mark_acceptance_criteria_complete\",\n      \"add_completion_date\",\n      \"move_to_archive\",\n      \"promote_next_task\"\n    ],\n    \"files\": {\n      \"todo\": \".repo/tasks/TODO.md\",\n      \"archive\": \".repo/tasks/ARCHIVE.md\",\n      \"backlog\": \".repo/tasks/BACKLOG.md\"\n    }\n  },\n\n  \"pr_creation\": {\n    \"required_reading\": [\n      \".repo/agents/checklists/pr-review.md\",\n      \".repo/templates/PR_TEMPLATE.md\",\n      \".repo/policy/QUALITY_GATES.md\",\n      \".repo/policy/HITL.md\"\n    ],\n    \"required_sections\": [\n      \"what_changed\",\n      \"why_changed\",\n      \"filepaths_all_files\",\n      \"verification_evidence\",\n      \"risks_if_any\",\n      \"rollback_if_risky\"\n    ]\n  },\n\n  \"rules\": {\n    \"always\": [\n      \"include_filepaths_in_all_changes\",\n      \"link_changes_to_task_in_todo\",\n      \"mark_unknown_create_hitl\",\n      \"show_verification_evidence\"\n    ],\n    \"never\": [\n      \"guess_commands_use_manifest_or_hitl\",\n      \"skip_filepaths_required_everywhere\",\n      \"commit_secrets_or_env_files\",\n      \"cross_boundaries_without_adr\",\n      \"proceed_with_unknown_items\",\n      \"make_risky_changes_without_hitl\"\n    ]\n  },\n\n  \"decision_trees\": {\n    \"hitl_needed\": {\n      \"risky\": {\n        \"triggers\": [\"security\", \"money\", \"production\", \"external\"],\n        \"action\": \"create_hitl_stop\"\n      },\n      \"unknown\": {\n        \"triggers\": [\"not_in_docs\", \"not_in_manifest\", \"not_in_code\"],\n        \"action\": \"mark_unknown_create_hitl_stop\"\n      },\n      \"cross_boundaries\": {\n        \"triggers\": true,\n        \"action\": \"requires_adr\"\n      }\n    }\n  },\n\n  \"troubleshooting\": {\n    \"todo_empty\": [\"check_backlog\", \"promote_highest_priority_task\"],\n    \"manifest_missing\": [\"mark_unknown\", \"create_hitl\", \"stop_work\"],\n    \"rules_json_missing\": [\"use_quick_reference\", \"or_read_constitution_principles\"]\n  },\n\n  \"next_steps\": {\n    \"after_reading_this\": [\n      \"read_agents_tasks_todo_md\",\n      \"read_repo_manifest_yaml\",\n      \"read_agents_rules_json\",\n      \"follow_three_pass_workflow\"\n    ]\n  }\n}\n"
        },
        {
          "path": "/AGENTS.md",
          "type": "Markdown",
          "lines": 164,
          "purpose": "Human-readable agent entry point (fallback for non-JSON parsers)",
          "key_contents": [
            "Command routing instructions",
            "Step-by-step workflow (Read files → Determine context → Three-pass workflow → Complete task)",
            "PR creation checklist",
            "Rules summary (always/never)",
            "Decision tree for HITL",
            "Troubleshooting section"
          ],
          "dependencies": [
            ".repo/tasks/TODO.md",
            ".repo/repo.manifest.yaml",
            ".repo/agents/rules.json"
          ],
          "used_by": [
            "Human agents",
            "AI agents that prefer markdown"
          ],
          "relationship": "Human-readable version of AGENTS.json",
          "content": "# Agent Entry Point\n\n**Role:** AI coding agent. Complete tasks safely following all rules.\n\n**Command received:** Start/Work/Task/Review/Security/Help\n\n---\n\n## Command Routing\n\n- `Start`/`Work`/`Task` → Follow workflow below\n- `Review` → Skip to \"Creating a PR\" section\n- `Security` → Read `.repo/policy/SECURITY_BASELINE.md` first, then workflow\n- `Help` → See \"Next Steps\" section\n\n---\n\n## Step 1: Read These Files (In Order)\n\n1. `.repo/tasks/TODO.md` - Current task\n2. `.repo/repo.manifest.yaml` - Commands (source of truth)\n3. `.repo/agents/rules.json` - All rules (or `QUICK_REFERENCE.md` for human-readable)\n\n---\n\n## Step 2: Determine Context\n\n**When entering a folder:**\n→ Read `.agent-context.json` (if exists) → Read `.AGENT.md` (if exists) → Use folder-specific context\n\n**If security/auth/money/external:**\n→ Read `.repo/policy/SECURITY_BASELINE.md` → Create HITL → Stop work\n\n**If cross-module boundaries:**\n→ Read `.repo/policy/BOUNDARIES.md` → Create ADR\n\n**If backend/frontend:**\n→ Read `.repo/policy/BESTPR.md` + folder guide (`backend/BACKEND.md` or `frontend/FRONTEND.md`) + `.agent-context.json`\n\n**If UNKNOWN:**\n→ Mark `<UNKNOWN>` → Read `.repo/policy/HITL.md` → Create HITL → Stop work\n\n---\n\n## Step 3: Three-Pass Workflow\n\n### Pass 0: Context (When Entering Folder)\n1. Read `.agent-context.json` if it exists in the folder\n2. Read `.AGENT.md` if it exists in the folder\n3. Use folder-specific patterns, boundaries, and rules\n\n### Pass 1: Plan\n1. **Determine change type** (feature/api_change/security/cross_module/non_doc_change)\n2. List actions\n3. Identify risks\n4. List files to modify (include filepaths)\n5. Mark UNKNOWN items\n6. Check if HITL needed\n7. Create task packet if required for change type\n\n**If HITL needed:** Create HITL → Stop → Wait\n**If ADR needed:** Create ADR → Document decision\n\n**Output:** Plan with actions, risks, files, UNKNOWNs, HITL items\n\n### Pass 2: Change\n1. Apply edits from plan\n2. Follow existing patterns\n3. Include filepaths (global rule)\n4. Respect boundaries\n\n**Do not proceed if:** Blockers exist, UNKNOWN unresolved, risky without HITL approval\n\n**Output:** Code changes with filepaths\n\n### Pass 3: Verify\n1. Run tests (use manifest commands: `make lint`, `make test`, `make verify`)\n2. Provide evidence (outputs, results, filepaths)\n3. Update logs (trace log, agent log)\n4. Check quality gates\n5. Document in PR\n\n**Output:** Evidence, updated logs, passing tests\n\n---\n\n## Step 4: Complete Task\n\n1. Mark criteria `[x]` in `.repo/tasks/TODO.md`\n2. Add `Completed: YYYY-MM-DD`\n3. Move to `.repo/tasks/ARCHIVE.md` (prepend)\n4. Promote next task from `.repo/tasks/BACKLOG.md` to `.repo/tasks/TODO.md`\n\n---\n\n## Creating a PR\n\n**Read:**\n- `.repo/agents/checklists/pr-review.md`\n- `.repo/templates/PR_TEMPLATE.md`\n- `.repo/policy/QUALITY_GATES.md`\n- `.repo/policy/HITL.md`\n\n**PR must include:**\n- What changed\n- Why changed\n- Filepaths (all files)\n- Verification evidence\n- Risks (if any)\n- Rollback (if risky)\n\n---\n\n## Rules\n\n**Always:**\n- Include filepaths (global rule)\n- Link to task in `.repo/tasks/TODO.md`\n- Mark UNKNOWN → Create HITL\n- Show verification evidence\n\n**Never:**\n- Guess commands (use manifest or HITL)\n- Skip filepaths\n- Commit secrets/.env files\n- Cross boundaries without ADR\n- Proceed with UNKNOWN items\n- Make risky changes without HITL\n\n---\n\n## Decision Tree: HITL Needed?\n\n- Risky? (security/money/prod/external) → **YES** → Create HITL → Stop\n- UNKNOWN? (not in docs/manifest/code) → **YES** → Mark `<UNKNOWN>` → Create HITL → Stop\n- Cross boundaries? → **YES** → Requires ADR\n\n**Full tree:** See `.repo/agents/rules.json` or `QUICK_REFERENCE.md`\n\n---\n\n## Troubleshooting\n\n**TODO.md empty:** Check `.repo/tasks/BACKLOG.md` → Promote highest priority task\n\n**manifest.yaml missing:** Mark `<UNKNOWN>` → Create HITL → Stop\n\n**rules.json missing:** Use `QUICK_REFERENCE.md` or read `CONSTITUTION.md` + `PRINCIPLES.md`\n\n---\n\n## Next Steps\n\n1. Read `.repo/tasks/TODO.md`\n2. Read `.repo/repo.manifest.yaml`\n3. Read `.repo/agents/rules.json` (or `QUICK_REFERENCE.md`)\n4. Follow three-pass workflow above\n\n**For context:** See `.repo/DOCUMENT_MAP.md`\n\n---\n\n**Note:** For structured/machine-readable format, see `AGENTS.json`\n"
        }
      ]
    },
    "policy_governance": {
      "description": "Policy and governance files",
      "files": [
        {
          "path": ".repo/policy/CONSTITUTION.md",
          "type": "Markdown",
          "lines": 43,
          "purpose": "Immutable constitutional articles (8 articles) - highest level governance",
          "key_contents": [
            "Article 1: Final Authority (solo founder)",
            "Article 2: Verifiable over Persuasive (proof required)",
            "Article 3: No Guessing (UNKNOWN → HITL → Stop)",
            "Article 4: Incremental Delivery (small PRs)",
            "Article 5: Strict Traceability (link to tasks, archive)",
            "Article 6: Safety Before Speed (risky → HITL)",
            "Article 7: Per-Repo Variation (manifest allows variation)",
            "Article 8: HITL for External Systems (credentials, billing, production)"
          ],
          "status": "IMMUTABLE (unless solo founder approves)",
          "referenced_by": [
            "All policy files",
            "rules.json",
            "QUICK_REFERENCE.md"
          ],
          "content": "# Repository Constitution\n\n**File**: `.repo/policy/CONSTITUTION.md`\n\n> **IMMUTABLE**: This file is immutable unless the solo founder explicitly approves changes.\n\n> **Operating Principles**: See `.repo/policy/PRINCIPLES.md` for detailed operating principles that implement these constitutional articles.\n> **Quality Gates**: See `.repo/policy/QUALITY_GATES.md` for merge rules and verification requirements.\n> **Security**: See `.repo/policy/SECURITY_BASELINE.md` for security rules and HITL triggers.\n> **HITL**: See `.repo/policy/HITL.md` for Human-In-The-Loop process and item management.\n> **Boundaries**: See `.repo/policy/BOUNDARIES.md` for module boundary enforcement.\n\n## Article 1: Final Authority\nThe solo founder is the final authority for any ambiguity, conflict, or decision.\n\n## Article 2: Verifiable over Persuasive\nWork is not \"done\" without verification evidence. Proof beats persuasion.\n\n## Article 3: No Guessing\nIf something is not explicitly known from repo docs, manifest, or code:\n- Mark it as **UNKNOWN**\n- Route to HITL (Human-In-The-Loop) or explicit questions\n- Do not proceed on that uncertain portion\n\n## Article 4: Incremental Delivery\nShip small, reviewable, testable increments.\nLarge tasks must be decomposed into smaller tasks. No mega-PRs without explicit approval.\n\n## Article 5: Strict Traceability\nEvery meaningful change must be traceable to an explicit task definition and include verification proof.\nCompleted tasks must be archived to preserve a compact history of what changed, why, and how it was verified.\n\n## Article 6: Safety Before Speed\nIf a change could break logins, money flows, user data, privacy, security, external services, or production behavior:\n**SAFETY WINS.**\nFor risky/uncertain changes: **STOP → ASK (HITL) → VERIFY → THEN PROCEED.**\n\n## Article 7: Per-Repo Variation Allowed\nGovernance structure is consistent, but per-repo workflow/execution may vary via manifest, packs, and repo checks.\n\n## Article 8: HITL for External Systems\nAnything involving credentials, vendor dashboards, production systems, billing, legal/compliance, or irreversible changes is HITL-gated.\n"
        },
        {
          "path": ".repo/policy/PRINCIPLES.md",
          "type": "Markdown",
          "lines": 78,
          "purpose": "Operating principles (25 principles) implementing the constitution",
          "key_contents": [
            "Global rule: Filepaths required everywhere",
            "P3-P25: Detailed operating principles covering change types, shippability, surprises, evidence, UNKNOWN handling, assumptions, risk triggers, guardrails, rollback, boundaries, complexity, consistency, decisions, PR narration, scope, docs, examples, naming, waivers, ADRs, logs, TODO discipline"
          ],
          "status": "Updateable (flexibility below constitution)",
          "referenced_by": [
            "rules.json",
            "QUICK_REFERENCE.md",
            "BESTPR.md"
          ],
          "content": "# Operating Principles\n\n**File**: `.repo/policy/PRINCIPLES.md`\n\nThese are the operating principles that sit below the Constitution. See `.repo/policy/CONSTITUTION.md` for governance rules.\n\n## Global rule\nFilepaths are required everywhere: PRs, Task Packets, logs, ADRs, waivers, and inline commentary.\n\n## 3. One Change Type Per PR\nA PR declares exactly one change type. If you need multiple types, split the work.\n\n## 4. Make It Shippable\nEach PR should be safe to merge and ship (or clearly blocked by HITL/waivers).\n\n## 5. Don't Break Surprises\nIf users, security, money, or production behavior could change: call it out, add tests, add rollback plan, use HITL.\n\n## 6. Evidence Over Vibes\nShow proof: commands run, outputs, test results, links to artifacts (filepaths).\n\n## 7. UNKNOWN Is a First-Class State\nUNKNOWN is allowed and required. Mark it explicitly and route to HITL.\n\n## 8. Read Repo First\nUse `.repo/` docs + `repo.manifest.yaml` before deciding anything.\n\n## 9. Assumptions Must Be Declared\nAny assumption must be written down and labeled as an assumption.\n\n## 10. Risk Triggers a Stop\nIf risk is non-trivial: STOP → HITL → VERIFY.\n\n## 11. Prefer Guardrails Over Heroics\nPrefer checks, tooling, and automation over \"trust me\".\n\n## 12. Rollback Thinking\nEvery risky change must have rollback thinking (how to undo safely).\n\n## 13. Respect Boundaries by Default\nDo not cross module boundaries unless rules allow.\n\n## 14. Localize Complexity (Option B)\nPut complexity where it belongs. Keep it contained. Avoid spreading special cases.\n\n## 15. Consistency Beats Novelty\nPrefer existing patterns and names. Novelty requires justification.\n\n## 16. Decisions Written Down (Token-Optimized)\nRecord decisions in the smallest durable place (ADR only when triggered).\n\n## 17. PR Narration\nPR must explain: what, why, filepaths, how verified, risks, rollback.\n\n## 18. No Silent Scope Creep\nDo not expand scope without updating Task Packet and calling it out.\n\n## 19. Docs Age With Code\nWhen code changes, docs must change too if they describe behavior.\n\n## 20. Examples Are Contracts\nExamples define expected behavior. If code changes, examples must be updated.\n\n## 21. Naming Matters\nNames must be clear. Avoid confusing abbreviations.\n\n## 22. Waivers Rare + Temporary\nWaivers are not permanent. They expire. They require a plan.\n\n## 23. ADR Required When Triggered\nIf an ADR trigger is met, create an ADR. No exceptions.\n\n## 24. Logs Required for Non-Docs\nNon-doc-only changes require agent logs + trace logs + reasoning summary.\n\n## 25. Token-Optimized TODO Discipline\nUse P0/P1/P2 TODO files + archive completed work to keep active context compact.\n"
        },
        {
          "path": ".repo/policy/SECURITY_BASELINE.md",
          "type": "Markdown",
          "lines": 62,
          "purpose": "Security rules, triggers, and forbidden patterns",
          "key_contents": [
            "Absolute prohibitions (no secrets/tokens/keys)",
            "Dependency vulnerability handling (always HITL)",
            "Security check frequency (every PR)",
            "Security review triggers (IDs 1,2,4,5,6,8,9,10)",
            "Forbidden patterns (regex patterns A-H: API keys, secrets, AWS credentials, private keys, OAuth tokens, database strings, JWT secrets, Stripe keys)",
            "Mandatory HITL actions (IDs 1-8)",
            "Evidence requirements"
          ],
          "referenced_by": [
            "rules.json",
            "governance-verify scripts",
            "CI workflows"
          ],
          "enforced_by": "check:security command",
          "content": "# Security Baseline\n\n**File**: `.repo/policy/SECURITY_BASELINE.md`\n\nThis file defines the minimum security rules.\n\n> **Related**: See `.repo/policy/CONSTITUTION.md` Article 6 & 8 for safety-first governance, `.repo/policy/QUALITY_GATES.md` for merge requirements, and `.repo/policy/HITL.md` for HITL item management process.\n\n## Absolute prohibitions\n- Secrets/tokens/keys must never be committed or logged (absolute prohibition).\n\n## Dependency vulnerabilities\nIf dependency vulnerabilities are detected:\n- ALWAYS create HITL item(s)\n- do not merge until HITL is Completed (or explicitly waived by human with expiration)\n\n## Security check frequency\nSecurity checks run on every PR.\n\n## Security review triggers\nTrigger IDs: [1,2,4,5,6,8,9,10]\nThese IDs are a stable registry for this standard.\nDefault meanings (editable only by human in this file if needed):\n1) Auth/login behavior change\n2) Money/payment flow change\n4) External service integration change\n5) Sensitive data handling change\n6) Permission/privacy change\n8) Production config/keys change\n9) Cryptography/security control change\n10) Dependency / supply-chain risk change\n\n## Forbidden patterns\nForbidden patterns list (regex patterns enforced by `check:security`):\n- **A**: Hardcoded API keys: `(api[_-]?key|apikey)\\s*[=:]\\s*['\"][a-zA-Z0-9]{20,}['\"]`\n- **B**: Hardcoded secrets: `(secret|password|pwd|passwd)\\s*[=:]\\s*['\"][^'\"]{8,}['\"]`\n- **C**: AWS credentials: `(aws[_-]?access[_-]?key[_-]?id|aws[_-]?secret[_-]?access[_-]?key)\\s*[=:]\\s*['\"][^'\"]+['\"]`\n- **D**: Private keys: `-----BEGIN\\s+(RSA\\s+)?PRIVATE\\s+KEY-----`\n- **E**: OAuth tokens: `(oauth[_-]?token|access[_-]?token)\\s*[=:]\\s*['\"][a-zA-Z0-9_-]{20,}['\"]`\n- **F**: Database connection strings with passwords: `(postgres|mysql|mongodb)://[^:]+:[^@]+@`\n- **G**: JWT secrets: `(jwt[_-]?secret|jwt[_-]?key)\\s*[=:]\\s*['\"][^'\"]{16,}['\"]`\n- **H**: Stripe keys: `(sk_live|pk_live|sk_test|pk_test)[a-zA-Z0-9]{24,}`\n\nThese patterns are enforced by `check:security` command. Patterns may be refined based on false positives.\nIf a pattern is unknown or needs adjustment, mark UNKNOWN and create HITL (see Article 3: No Guessing, Principle 7: UNKNOWN Is a First-Class State).\n\n## Mandatory HITL actions\nMandatory HITL action IDs: [1,2,3,4,5,6,7,8]\nDefault meanings (editable only by human if needed):\n1) Human approves security risk assessment\n2) Human confirms no secrets exposed\n3) Human reviews dependency vulnerability report (if any)\n4) Human confirms login/security test evidence for risky changes\n5) Human confirms money-flow test evidence for risky changes\n6) Human approves waiver (if needed) with expiration\n7) Human confirms rollback plan for risky changes\n8) Human confirms external system steps completed (if any)\n\n## Evidence requirements\nEvidence requirements: standard\nMeaning: show what was run and the results (filepaths + command outputs summarized).\n"
        },
        {
          "path": ".repo/policy/BOUNDARIES.md",
          "type": "Markdown",
          "lines": 58,
          "purpose": "Module boundary enforcement rules",
          "key_contents": [
            "Model: hybrid_domain_feature_layer",
            "Directory pattern: src/<domain>/<feature>/<layer>/",
            "Default allowed import direction: ui → domain → data → shared_platform",
            "Cross-feature rule: Requires ADR",
            "Enforcement method: hybrid_static_checker_plus_manifest",
            "Exceptions: Small (Task Packet) vs Large (ADR)",
            "Violation severity: waiver_plus_auto_task",
            "Boundary visibility: inline_comments_plus_summary",
            "Practical examples (allowed/forbidden)",
            "UBOS-specific notes (Django modules, firm-scoped multi-tenancy)"
          ],
          "referenced_by": [
            "check-boundaries.js",
            "rules.json",
            "BESTPR.md"
          ],
          "enforced_by": "lint-imports with .importlinter config",
          "content": "# Module Boundaries\n\n**File**: `.repo/policy/BOUNDARIES.md`\n\nThis file defines module boundaries. Boundaries are enforced.\n\n> **Related**: See `.repo/policy/PRINCIPLES.md` Principle 13 (Respect Boundaries by Default) and Principle 14 (Localize Complexity).\n\n## Model\nhybrid_domain_feature_layer\n\n## Directory pattern\nsrc/<domain>/<feature>/<layer>/\nShared platform directory: src/platform/\n\n## Default allowed import direction (Plain English)\n- UI layer may depend on Domain layer\n- Domain layer may depend on Data layer\n- Data layer may depend on Platform (shared) layer\n- Platform depends on nothing\n\nMachine form:\nui → domain → data → shared_platform\n\n## Cross-feature rule\nCross-feature imports require an ADR (see Principle 23: ADR Required When Triggered).\n\n## Enforcement method\nhybrid_static_checker_plus_manifest\nMeaning: a static boundary checker runs AND the manifest contains explicit edges for allowed exceptions.\n\n## Exceptions\n- Small exception: allowed only with explicit Task Packet justification + filepaths.\n- Large exception: requires ADR.\nAll exceptions must be represented as explicit edges in `repo.manifest.yaml`.\n\n## Violation severity\nwaiver_plus_auto_task\nMeaning: if boundaries are violated:\n- PR is blocked unless fixed or waived\n- if waived, an auto-task is created in TODOs with remediation plan\n\n## Boundary visibility\ninline_comments_plus_summary\nMeaning: boundary-related decisions must be visible in code comments where relevant and summarized in PR narration (see Principle 17: PR Narration).\n\n## Practical examples (Plain English)\nAllowed:\n- `src/sales/checkout/ui/*` imports `src/sales/checkout/domain/*`\n\nForbidden:\n- UI imports Data directly\n- Any layer imports another feature in a different feature folder without ADR\n- Anything imports Platform and then re-exports it as a shortcut across features\n\n## UBOS-Specific Notes\nThis repository uses Django modules (`backend/modules/`) with firm-scoped multi-tenancy. Each module should be self-contained (models, views, serializers, urls). Cross-module imports should be minimal and well-justified. See `.repo/policy/BESTPR.md` for module organization patterns.\n"
        },
        {
          "path": ".repo/policy/QUALITY_GATES.md",
          "type": "Markdown",
          "lines": 72,
          "purpose": "Merge rules and verification requirements",
          "key_contents": [
            "Merge policy: soft block with auto-generated waivers",
            "Hard gates (must pass, not waiverable): Required artifacts missing, Trace log missing/invalid, Required HITL items not Completed, Waiver missing/expired, governance-verify fails",
            "Waiverable gates: Coverage targets (gradual ratchet), Performance/bundle budgets, Warning budgets (zero warnings), Test coverage regression",
            "Test requirements: Minimum coverage thresholds (backend 80%, frontend 70%), Test file requirements, Coverage validation, Test patterns",
            "Coverage strategy: gradual ratchet",
            "Performance budgets: strict with fallback",
            "Warnings: zero warnings policy",
            "PR size policy: no limits (but Article 4 requires decomposition)",
            "Required checks: all governance_verify_checks"
          ],
          "referenced_by": [
            "governance-verify.sh",
            "governance-verify.js",
            "CI workflows"
          ],
          "enforced_by": "governance-verify command",
          "content": "# Quality Gates\n\n**File**: `.repo/policy/QUALITY_GATES.md`\n\nQuality Gates are the merge rules. `governance-verify` enforces them.\n\n> **Related**: See `.repo/policy/CONSTITUTION.md` for governance rules, `.repo/policy/PRINCIPLES.md` for operating principles, `.repo/policy/SECURITY_BASELINE.md` for security checks, `.repo/policy/HITL.md` for HITL item management, and `.repo/policy/BOUNDARIES.md` for boundary enforcement.\n\n## Merge policy\nPolicy: soft block with auto-generated waivers for waiverable gate failures.\nMeaning: if a waiverable gate fails, a waiver is generated and must be approved/expired rules apply.\n\n## Hard gates (must pass; not waiverable)\nThese are \"governance integrity\" gates. If these fail, the repo is not self-governing.\n- Required artifacts are missing for the declared change type (Task Packet, required logs, trace, ADR/HITL when triggered).\n- Trace log is missing or invalid against `.repo/templates/AGENT_TRACE_SCHEMA.json`.\n- Required HITL items are not Completed (or validly waived where policy allows).\n- Waiver referenced is missing or expired.\n- `governance-verify` fails.\n\n## Waiverable gates (waiver required when failing)\n- Coverage targets (gradual ratchet).\n- Performance/bundle budgets (strict with fallback to default).\n- Warning budgets (zero warnings; waiver required if warnings exist).\n- Test coverage regression (coverage should not decrease).\nNote: waivers must be rare + temporary (see Principle 22).\n\n## Test Requirements\n\n**Minimum Coverage Thresholds:**\n- Backend: 80% for new code, gradual ratchet for existing code\n- Frontend: 70% for new components, gradual ratchet for existing code\n- Integration tests: Required for API changes and cross-module work\n\n**Test File Requirements:**\n- New viewsets must have corresponding test files\n- New components must have corresponding test files\n- New API endpoints must have integration tests\n- Test files should be co-located or in `tests/` directory\n\n**Coverage Validation:**\n- `governance-verify` checks that test files exist for modified code\n- Coverage regression is detected (coverage should not decrease)\n- Missing tests for new code trigger warnings (waiverable)\n\n**Test Patterns:**\n- See `.repo/templates/examples/` for test examples:\n  - `example_test_viewset.py` - Django ViewSet tests\n  - `example_test_component.tsx` - React component tests\n  - `example_test_api_integration.py` - API integration tests\n- See folder-level `.AGENT.md` files for module-specific test patterns\n\n## Coverage strategy: gradual ratchet\n- Do not require perfection immediately.\n- Each change should improve coverage or keep it from regressing.\n- Over time, the minimum bar rises.\n\n## Performance budgets: strict with fallback to default\n- Repo may define explicit budgets.\n- If missing, use the default budgets described in this file (or referenced standard).\n- If budgets are exceeded: fail + require waiver + remediation plan.\n\n## Warnings: zero warnings\nWarnings are treated as failures. If a warning exists, it must be fixed or waived.\n\n## PR size policy: no limits\nNo hard PR size limits. Constitution still requires decomposition into shippable increments (Article 4: Incremental Delivery).\n\n## Required checks\n`governance_verify_checks`: all\nMeaning: `governance-verify` checks everything it knows how to check for this repo type.\n"
        },
        {
          "path": ".repo/policy/HITL.md",
          "type": "Markdown",
          "lines": 73,
          "purpose": "Human-In-The-Loop process and item management",
          "key_contents": [
            "Storage model: Split (index in HITL.md, items in .repo/hitl/)",
            "Rule: minimal human effort (human sets status + evidence, agents do mechanical work)",
            "Categories: External Integration, Clarification, Risk, Feedback, Vendor",
            "Statuses: Pending | In Progress | Blocked | Completed | Superseded",
            "Merge blocking rule: PR blocked if required HITL not Completed",
            "Who can do what: Agents create, humans complete, agents sync",
            "External systems detection: keywords + manifest + change type",
            "HITL item file format (HITL-XXXX.md): ID, Category, Required For, Owner, Reviewer, Status, Date Required, Date Completed, Summary, Required Human Action steps, Evidence, Related artifacts",
            "Index tables: Active and Archived",
            "Archiving process"
          ],
          "referenced_by": [
            "create-hitl-item.sh",
            "sync-hitl-to-pr.py",
            "governance-verify scripts"
          ],
          "used_by": [
            "All agents when encountering risky/unknown situations"
          ],
          "content": "# Human-In-The-Loop (HITL)\n\n**File**: `.repo/policy/HITL.md`\n\nHITL = Human-In-The-Loop. This is the single binding place for human-required actions.\n\n> **Related**: See `.repo/policy/CONSTITUTION.md` Article 3 (No Guessing), Article 6 (Safety Before Speed), Article 8 (HITL for External Systems), `.repo/policy/SECURITY_BASELINE.md` for security triggers, and `.repo/policy/QUALITY_GATES.md` for merge blocking rules.\n\n## Storage model\nSplit, same folder:\n- Index (this file): `.repo/policy/HITL.md`\n- Items: `.repo/hitl/HITL-XXXX.md`\n\n## Rule: minimal human effort\nThe human does the smallest action possible (usually: set Status + add Evidence line).\nAgents do all mechanical work: syncing PR body, archiving, and governance-verify reruns.\n\n## Categories\n- External Integration\n- Clarification\n- Risk\n- Feedback\n- Vendor\n\n## Statuses\nPending | In Progress | Blocked | Completed | Superseded\n\n## Merge blocking rule\nIf a PR has any required HITL item not in Completed status (or not validly waived), merge is blocked (see `.repo/policy/QUALITY_GATES.md` hard gates).\n\n## Who can do what\n- Agents may create HITL items and propose wording.\n- Only the human may mark HITL items Completed.\n- Agents must auto-sync HITL status changes into PR body and archive when completed.\n\n## External systems detection (how to trigger HITL)\nDetection is keywords + manifest + change type:\n- If the change type implies external systems (security, release, schema), HITL is required.\n- If the manifest command involves external credentials/dashboards, HITL is required.\n- If keywords appear (credentials, token, billing, app store, vendor dashboard, prod deploy, payment, oauth), HITL is required.\n\nSee `.repo/policy/SECURITY_BASELINE.md` for security review triggers that require HITL.\n\n## HITL item file format (HITL-XXXX.md)\nRequired fields:\n- ID (HITL-XXXX)\n- Category\n- Required For (change types)\n- Owner (human)\n- Reviewer (human)\n- Status\n- Date Required\n- Date Completed\n- Summary\n- Required Human Action steps\n- Evidence of completion (filepaths or notes; no secrets)\n- Related artifacts (filepaths): PR, ADR, Waiver, Task Packet\n\n## Index tables\n### Active\n|ID|Category|Status|Summary|Filepath|\n|---|---|---|---|---|\n\n### Archived\n|ID|Category|Status|Summary|Filepath|\n|---|---|---|---|---|\n\n## Archiving\nWhen an item becomes Completed or Superseded:\n- Agent moves it from Active to Archived table\n- Agent adds Archived On: YYYY-MM-DD in the item file\n- Agent updates PR body HITL section to reflect completion\n"
        },
        {
          "path": ".repo/policy/BESTPR.md",
          "type": "Markdown",
          "lines": 106,
          "purpose": "Repository-specific best practices (UBOS-specific)",
          "key_contents": [
            "Repository map (where to work): backend/modules/, backend/api/, backend/config/, frontend/src/, tests/, docs/, .repo/tasks/, scripts/",
            "Tech stack & core libraries: Backend (Django 4.2, Python 3.11, PostgreSQL 15, DRF), Frontend (React 18.3, TypeScript 5.9, Vite 5.4), State (TanStack React Query 5.90), Forms (React Hook Form 7.69), Routing (React Router DOM 6.30), Visualization (ReactFlow 11.10), Testing (pytest, Vitest, Playwright, Testing Library), Formatting (ruff, black, mypy, ESLint, Prettier, tsc), Observability (Sentry)",
            "Delivery workflow: Local checks (make lint, make typecheck, make test, make verify), OpenAPI regeneration (make -C backend openapi)",
            "Repo-specific coding practices: Backend (Django REST Framework viewsets, FirmScopedMixin, module boundaries), Frontend (Functional components, React Query, React Hook Form), Shared (Integration tests, OpenAPI schema, firm-scoped multi-tenancy)",
            "Documentation expectations",
            "Governance alignment"
          ],
          "referenced_by": [
            ".agent-context.json files",
            "folder guides",
            "rules.json"
          ],
          "used_by": [
            "Agents working in backend/frontend"
          ],
          "content": "# BESTPR — UBOS Best Practices (Repo-Specific)\n\n**File**: `.repo/policy/BESTPR.md`\n\n## Purpose\nUse this guide to ship changes that align with UBOS architecture, workflows, and quality bars. It captures the stack, repo layout, and the checks expected before delivery.\n\n## Repository Map (where to work)\n- **backend/modules/** — Domain modules with firm-scoped multi-tenancy (clients, crm, finance, projects, documents, etc.). Each module contains models, views, serializers, urls, and migrations.\n- **backend/api/** — API endpoints organized by domain (clients, crm, finance, documents, projects, portal, webhooks).\n- **backend/config/** — Django settings, middleware, health checks, permissions, and core configuration.\n- **frontend/src/** — React application source (components, pages, hooks, contexts, API clients, tracking).\n- **frontend/src/api/** — API client functions organized by domain, using TanStack React Query.\n- **frontend/src/components/** — Reusable React components (Layout, ErrorBoundary, CommandCenter, etc.).\n- **frontend/src/pages/** — Page components and their associated styles.\n- **frontend/src/contexts/** — React contexts (AuthContext, ImpersonationContext).\n- **tests/** — Cross-cutting and integration tests shared across modules.\n- **docs/** — Primary documentation source tree (architecture, onboarding, development, runbooks).\n- **agents/tasks/** — Task management (TODO.md, BACKLOG.md, ARCHIVE.md) for traceability.\n- **scripts/** — Project automation and migration scripts.\n\n## Tech Stack & Core Libraries\n- **Backend:** Django 4.2 + Python 3.11, PostgreSQL 15, Django REST Framework for APIs.\n- **Frontend:** React 18.3 + TypeScript 5.9 + Vite 5.4 for the client app.\n- **State & Data Fetching:** TanStack React Query 5.90 for API data management.\n- **Forms:** React Hook Form 7.69 for form handling.\n- **Routing:** React Router DOM 6.30 for client-side navigation.\n- **Data Visualization:** ReactFlow 11.10 for workflow/flow diagrams.\n- **Testing:** pytest (backend), Vitest + Playwright (frontend), Testing Library for React components.\n- **Formatting & Linting:** ruff + black + mypy (backend), ESLint + Prettier + tsc (frontend).\n- **Observability:** Sentry for error tracking (backend and frontend).\n\n## Delivery Workflow (what to run)\n1. **Local checks before PR:**\n   - `make lint` — Run all linters (backend + frontend)\n   - `make typecheck` — Type checking (backend mypy, frontend tsc)\n   - `make test` — Run test suites (pytest + vitest)\n   - `make verify` — Full local CI suite (light checks by default)\n   - `make verify SKIP_HEAVY=0` — Full suite including tests, build, and OpenAPI validation\n2. **When touching APIs:** Regenerate and commit OpenAPI schema (`make -C backend openapi`).\n3. **When touching docs:** Keep documentation in the organized `/docs` structure and update canonical root guides as needed.\n\n## Repo-Specific Coding Practices\n### Backend (Django)\n- Prefer Django REST Framework viewsets for CRUD operations. Use `FirmScopedMixin` for all model viewsets to enforce multi-tenancy.\n- Keep domain logic in `backend/modules/` with clear module boundaries. Each module should be self-contained (models, views, serializers, urls, migrations).\n- Use serializers for request/response validation and transformation. Keep API-specific serializers in `backend/api/` when they differ from module serializers.\n- Place shared utilities and middleware in `backend/config/` (permissions, pagination, throttling, health checks).\n- Use type hints where practical (mypy is relaxed but preferred for new code).\n- All models must be firm-scoped (inherit from FirmScopedMixin or use firm filtering).\n\nExample:\n```python\nclass ClientViewSet(FirmScopedMixin, viewsets.ModelViewSet):\n    queryset = Client.objects.all()\n    serializer_class = ClientSerializer\n```\n\n### Frontend (React + TypeScript)\n- Prefer existing component patterns in `frontend/src/components/` before introducing new abstractions.\n- Use TanStack React Query for all API data fetching. Keep API client functions in `frontend/src/api/` organized by domain.\n- Use React Hook Form for form handling with TypeScript types.\n- Keep page components in `frontend/src/pages/` with co-located CSS files.\n- Use React contexts (`frontend/src/contexts/`) for global state (auth, impersonation).\n- Prefer functional components with TypeScript. Use React.FC for component type annotations.\n\nExample:\n```typescript\nexport const KnowledgeCenter: React.FC = () => {\n  const { data } = useQuery({ queryKey: ['knowledge'] });\n  return <div>...</div>;\n};\n```\n\n### Shared / Cross-Cutting\n- Keep integration and cross-module tests in `tests/` directory.\n- Use OpenAPI schema (`backend/openapi.yaml`) as the contract between frontend and backend.\n- Follow firm-scoped multi-tenancy patterns consistently across all modules.\n- Reference `docs/ARCHITECTURE.md` for system design decisions.\n\n## Documentation Expectations\n- Follow the documentation structure in `/docs`:\n  - `docs/ARCHITECTURE.md` — System architecture and design decisions\n  - `docs/ONBOARDING.md` — Getting started guide\n  - `docs/DEVELOPMENT.md` — Development workflow and commands\n  - `docs/RUNBOOK.md` — Operational procedures\n- Root-level guides like `README.md` and `AGENTS.md` should contain high-level navigation or onboarding details.\n- When adding new modules or significant features, update relevant architecture documentation.\n\n## Governance Alignment\n- Follow the project governance rules in `.repo/policy/CONSTITUTION.md` for PR review, task traceability, verification evidence, and documentation rigor.\n- Apply operating principles from `.repo/policy/PRINCIPLES.md` for day-to-day development practices.\n- Quality gates in `.repo/policy/QUALITY_GATES.md` define merge requirements and verification checks.\n- Security rules in `.repo/policy/SECURITY_BASELINE.md` define security checks, HITL triggers, and forbidden patterns.\n- HITL process in `.repo/policy/HITL.md` defines how human-required actions are tracked and managed.\n- Module boundaries in `.repo/policy/BOUNDARIES.md` define import rules and enforcement (Principle 13: Respect Boundaries).\n- All changes must be traceable to tasks in `agents/tasks/` (Article 5: Strict Traceability, Principle 25).\n- Completed tasks must be archived to `agents/tasks/ARCHIVE.md` after PR merge.\n- For risky changes (logins, money flows, user data, security), route to HITL per Article 6 & 8, Principle 10, SECURITY_BASELINE.md triggers, and HITL.md process.\n- PRs must include filepaths, verification evidence, and rollback plans per Principles 6, 12, and 17.\n- All quality gates must pass before merge (hard gates) or have approved waivers (waiverable gates).\n- Never commit secrets (SECURITY_BASELINE.md: absolute prohibition).\n\n---\n**Canonical reference:** This document is the single source of truth for repo-specific best practices. Link to it from all AGENTS.md files and governance docs.\n"
        }
      ]
    },
    "agent_framework": {
      "description": "Agent framework files",
      "files": [
        {
          "path": ".repo/agents/rules.json",
          "type": "JSON Schema",
          "lines": 240,
          "purpose": "Machine-readable agent rules and policies",
          "key_contents": [
            "Schema metadata (version 1.0.0, last_updated 2026-01-23)",
            "Required files (startup, conditional)",
            "Constitution (8 articles with rules and workflows)",
            "Principles (25 principles with global rule)",
            "Workflows (three-pass, unknown, hitl_decision)",
            "Security (triggers, absolute_prohibitions)",
            "Rules (always, never)",
            "Artifacts (by change type)",
            "Commands (from manifest)",
            "Tech stack (backend, frontend)",
            "Project structure",
            "Code style (backend, frontend patterns)"
          ],
          "dependencies": [
            "CONSTITUTION.md",
            "PRINCIPLES.md",
            "repo.manifest.yaml"
          ],
          "used_by": [
            "Agents as machine-readable rules source"
          ],
          "relationship": "Machine-readable version of QUICK_REFERENCE.md",
          "content": "{\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"version\": \"1.0.0\",\n  \"metadata\": {\n    \"description\": \"Machine-readable agent rules and policies\",\n    \"source\": \"Extracted from CONSTITUTION.md, PRINCIPLES.md, and agent framework\",\n    \"last_updated\": \"2026-01-23\"\n  },\n  \"required_files\": {\n    \"startup\": [\n      \".repo/tasks/TODO.md\",\n      \".repo/repo.manifest.yaml\",\n      \".repo/agents/QUICK_REFERENCE.md\"\n    ],\n    \"conditional\": {\n      \"security\": [\".repo/policy/SECURITY_BASELINE.md\", \".repo/policy/HITL.md\"],\n      \"boundaries\": [\".repo/policy/BOUNDARIES.md\"],\n      \"pr\": [\".repo/policy/QUALITY_GATES.md\", \".repo/templates/PR_TEMPLATE.md\"],\n      \"unknown\": [\".repo/policy/HITL.md\"]\n    }\n  },\n  \"constitution\": {\n    \"articles\": [\n      {\n        \"id\": 1,\n        \"title\": \"Final Authority\",\n        \"rule\": \"Solo founder has final say on ambiguity/conflicts\"\n      },\n      {\n        \"id\": 2,\n        \"title\": \"Verifiable over Persuasive\",\n        \"rule\": \"Work needs verification evidence. Proof beats persuasion.\"\n      },\n      {\n        \"id\": 3,\n        \"title\": \"No Guessing\",\n        \"rule\": \"If unknown: Mark <UNKNOWN> → Create HITL → Stop work\",\n        \"workflow\": [\"mark_unknown\", \"create_hitl\", \"stop_work\"]\n      },\n      {\n        \"id\": 4,\n        \"title\": \"Incremental Delivery\",\n        \"rule\": \"Ship small, reviewable, testable increments. No mega-PRs.\"\n      },\n      {\n        \"id\": 5,\n        \"title\": \"Strict Traceability\",\n        \"rule\": \"Every change must link to task in .repo/tasks/TODO.md. Archive completed tasks.\",\n        \"requirements\": [\"link_to_task\", \"archive_completed\"]\n      },\n      {\n        \"id\": 6,\n        \"title\": \"Safety Before Speed\",\n        \"rule\": \"Risky changes: STOP → ASK (HITL) → VERIFY → THEN PROCEED\",\n        \"workflow\": [\"stop\", \"ask_hitl\", \"verify\", \"proceed\"]\n      },\n      {\n        \"id\": 7,\n        \"title\": \"Per-Repo Variation\",\n        \"rule\": \"Workflow may vary per repo (via manifest)\"\n      },\n      {\n        \"id\": 8,\n        \"title\": \"HITL for External Systems\",\n        \"rule\": \"Credentials, billing, production, external services = always HITL\",\n        \"triggers\": [\"credentials\", \"billing\", \"production\", \"external_services\"]\n      }\n    ]\n  },\n  \"principles\": {\n    \"global_rule\": \"Filepaths required everywhere (PRs, logs, ADRs, waivers, comments)\",\n    \"principles\": [\n      {\"id\": 3, \"rule\": \"One Change Type Per PR\"},\n      {\"id\": 4, \"rule\": \"Make It Shippable\"},\n      {\"id\": 5, \"rule\": \"Don't Break Surprises\"},\n      {\"id\": 6, \"rule\": \"Evidence Over Vibes\"},\n      {\"id\": 7, \"rule\": \"UNKNOWN Is First-Class\"},\n      {\"id\": 8, \"rule\": \"Read Repo First\"},\n      {\"id\": 9, \"rule\": \"Assumptions Must Be Declared\"},\n      {\"id\": 10, \"rule\": \"Risk Triggers a Stop\"},\n      {\"id\": 11, \"rule\": \"Prefer Guardrails Over Heroics\"},\n      {\"id\": 12, \"rule\": \"Rollback Thinking\"},\n      {\"id\": 13, \"rule\": \"Respect Boundaries\"},\n      {\"id\": 14, \"rule\": \"Localize Complexity\"},\n      {\"id\": 15, \"rule\": \"Consistency Beats Novelty\"},\n      {\"id\": 16, \"rule\": \"Decisions Written Down\"},\n      {\"id\": 17, \"rule\": \"PR Narration\"},\n      {\"id\": 18, \"rule\": \"No Silent Scope Creep\"},\n      {\"id\": 19, \"rule\": \"Docs Age With Code\"},\n      {\"id\": 20, \"rule\": \"Examples Are Contracts\"},\n      {\"id\": 21, \"rule\": \"Naming Matters\"},\n      {\"id\": 22, \"rule\": \"Waivers Rare + Temporary\"},\n      {\"id\": 23, \"rule\": \"ADR Required When Triggered\"},\n      {\"id\": 24, \"rule\": \"Logs Required for Non-Docs\"},\n      {\"id\": 25, \"rule\": \"Token-Optimized TODO\"}\n    ]\n  },\n  \"workflows\": {\n    \"three_pass\": {\n      \"pass1\": {\n        \"name\": \"Plan\",\n        \"steps\": [\"list_actions\", \"identify_risks\", \"list_files\", \"mark_unknowns\", \"get_approval\"]\n      },\n      \"pass2\": {\n        \"name\": \"Change\",\n        \"steps\": [\"apply_edits\", \"follow_patterns\", \"include_filepaths\"],\n        \"blockers\": [\"pass1_blockers\"]\n      },\n      \"pass3\": {\n        \"name\": \"Verify\",\n        \"steps\": [\"run_tests\", \"provide_evidence\", \"update_logs\", \"check_quality_gates\", \"document_in_pr\"]\n      }\n    },\n    \"unknown\": {\n      \"steps\": [\"mark_unknown\", \"create_hitl\", \"stop_work\", \"wait_resolution\"]\n    },\n    \"hitl_decision\": {\n      \"triggers\": [\"risky\", \"unknown\", \"cross_boundaries\"],\n      \"risky\": {\n        \"conditions\": [\"security\", \"money\", \"production\", \"external_systems\"],\n        \"action\": \"create_hitl\"\n      },\n      \"unknown\": {\n        \"conditions\": [\"not_in_docs\", \"not_in_manifest\", \"not_in_code\"],\n        \"action\": \"mark_unknown_create_hitl\"\n      },\n      \"cross_boundaries\": {\n        \"action\": \"requires_adr\"\n      }\n    }\n  },\n  \"security\": {\n    \"triggers\": [\n      {\"id\": 1, \"type\": \"auth_login_behavior_change\"},\n      {\"id\": 2, \"type\": \"money_payment_flow_change\"},\n      {\"id\": 3, \"type\": \"external_service_integration\"},\n      {\"id\": 4, \"type\": \"sensitive_data_handling\"},\n      {\"id\": 5, \"type\": \"production_config_keys\"},\n      {\"id\": 6, \"type\": \"cryptography_security_controls\"},\n      {\"id\": 7, \"type\": \"dependency_vulnerabilities\"}\n    ],\n    \"absolute_prohibitions\": [\n      \"commit_secrets\",\n      \"commit_env_files\"\n    ]\n  },\n  \"rules\": {\n    \"always\": [\n      {\"rule\": \"Include filepaths in all changes\", \"source\": \"global_rule\"},\n      {\"rule\": \"Link changes to task in .repo/tasks/TODO.md\", \"source\": \"article_5\"},\n      {\"rule\": \"Mark UNKNOWN → Create HITL\", \"source\": \"article_3\"},\n      {\"rule\": \"Follow three-pass workflow\", \"source\": \"workflow\"},\n      {\"rule\": \"Run make lint before PR\", \"source\": \"best_practice\"},\n      {\"rule\": \"Archive completed tasks\", \"source\": \"article_5\"},\n      {\"rule\": \"Show verification evidence\", \"source\": \"article_2_p6\"},\n      {\"rule\": \"Explain what/why/filepaths/verification/risks/rollback in PR\", \"source\": \"p17\"},\n      {\"rule\": \"Update docs when code behavior changes\", \"source\": \"p19\"},\n      {\"rule\": \"Update examples when code changes\", \"source\": \"p20\"},\n      {\"rule\": \"Declare assumptions explicitly\", \"source\": \"p9\"},\n      {\"rule\": \"Think about rollback for risky changes\", \"source\": \"p12\"}\n    ],\n    \"never\": [\n      {\"rule\": \"Guess commands\", \"source\": \"article_3\", \"alternative\": \"use_manifest_or_hitl\"},\n      {\"rule\": \"Skip filepaths\", \"source\": \"global_rule\"},\n      {\"rule\": \"Modify policy files without approval\", \"source\": \"governance\"},\n      {\"rule\": \"Commit secrets or .env files\", \"source\": \"absolute_prohibition\"},\n      {\"rule\": \"Cross boundaries without ADR\", \"source\": \"p23\"},\n      {\"rule\": \"Proceed with UNKNOWN items\", \"source\": \"article_3\"},\n      {\"rule\": \"Make risky changes without HITL\", \"source\": \"article_6_8\"},\n      {\"rule\": \"Create mega-PRs\", \"source\": \"article_4\"},\n      {\"rule\": \"Skip verification evidence\", \"source\": \"article_2\"},\n      {\"rule\": \"Expand scope silently\", \"source\": \"p18\"},\n      {\"rule\": \"Make assumptions without declaring them\", \"source\": \"p9\"}\n    ]\n  },\n  \"artifacts\": {\n    \"feature\": [\"task_packet\", \"trace_log\", \"tests\"],\n    \"api_change\": [\"task_packet\", \"adr\", \"trace_log\", \"openapi_update\"],\n    \"security\": [\"hitl\", \"trace_log\", \"security_tests\"],\n    \"cross_module\": [\"adr\", \"task_packet\", \"trace_log\"],\n    \"non_doc_change\": [\"agent_log\", \"trace_log\", \"reasoning_summary\"]\n  },\n  \"commands\": {\n    \"source\": \".repo/repo.manifest.yaml\",\n    \"common\": {\n      \"setup\": \"make setup\",\n      \"lint\": \"make lint\",\n      \"test\": \"make test\",\n      \"verify\": \"make verify\",\n      \"verify_full\": \"make verify SKIP_HEAVY=0\",\n      \"ci\": \"make ci\"\n    },\n    \"backend\": {\n      \"migrate\": \"make -C backend migrate\",\n      \"openapi\": \"make -C backend openapi\"\n    },\n    \"frontend\": {\n      \"test\": \"make -C frontend test\",\n      \"e2e\": \"make -C frontend e2e\"\n    }\n  },\n  \"tech_stack\": {\n    \"backend\": {\n      \"framework\": \"Django 4.2\",\n      \"language\": \"Python 3.11\",\n      \"database\": \"PostgreSQL 15\"\n    },\n    \"frontend\": {\n      \"framework\": \"React 18.3\",\n      \"language\": \"TypeScript 5.9\",\n      \"build\": \"Vite 5.4\",\n      \"data_fetching\": \"TanStack React Query\",\n      \"forms\": \"React Hook Form\"\n    }\n  },\n  \"project_structure\": {\n    \"backend\": {\n      \"modules\": \"Domain modules (firm-scoped multi-tenancy)\",\n      \"api\": \"API endpoints\",\n      \"config\": \"Django settings, middleware\"\n    },\n    \"frontend\": {\n      \"src\": \"React components, pages, hooks\"\n    },\n    \"tasks\": \".repo/tasks/ (TODO/BACKLOG/ARCHIVE)\"\n  },\n  \"code_style\": {\n    \"backend\": {\n      \"pattern\": \"Django REST Framework viewsets with FirmScopedMixin\",\n      \"example\": \"class ClientViewSet(FirmScopedMixin, viewsets.ModelViewSet):\",\n      \"requirements\": [\"firm_scoped_models\", \"type_hints_preferred\"]\n    },\n    \"frontend\": {\n      \"pattern\": \"Functional components with TypeScript\",\n      \"example\": \"export const Component: React.FC = () => { const { data } = useQuery(...); }\",\n      \"requirements\": [\"functional_components\", \"react_query_for_data\", \"react_hook_form_for_forms\"]\n    }\n  }\n}\n"
        },
        {
          "path": ".repo/agents/QUICK_REFERENCE.md",
          "type": "Markdown",
          "lines": 537,
          "purpose": "Human-readable quick reference card with essential rules",
          "key_contents": [
            "Reading order instructions",
            "Decision tree: Do I Need HITL?",
            "Constitution (8 articles summary)",
            "Key principles (most critical)",
            "Change type determination (decision tree with examples)",
            "Three-pass workflow details: Pass 0 (Context), Pass 1 (Plan), Pass 2 (Change), Pass 3 (Verify)",
            "Artifact requirements by change type",
            "Command reference (from manifest)",
            "Quality gates summary",
            "HITL workflow",
            "Boundary enforcement",
            "Task lifecycle",
            "Troubleshooting"
          ],
          "dependencies": [
            "All policy files",
            "manifest",
            "templates"
          ],
          "used_by": [
            "Agents as primary human-readable reference"
          ],
          "relationship": "Human-readable version of rules.json",
          "content": "# Agent Quick Reference Card\n\n**File**: `.repo/agents/QUICK_REFERENCE.md`\n\n> **Essential Rules:** This document contains ALL critical rules agents need to operate. Full policy documents (CONSTITUTION.md, PRINCIPLES.md) provide deeper context when needed.\n\n**Agent Instructions:** This is your quick reference. Read in this order:\n\n1. `.repo/tasks/TODO.md` - Current task (MUST READ FIRST)\n2. `.repo/repo.manifest.yaml` - Commands (BEFORE ANY COMMAND)\n3. This file (`.repo/agents/QUICK_REFERENCE.md`) - Rules (START HERE)\n\n**When entering a folder:**\n- Read `.agent-context.json` (if exists) - Machine-readable folder context\n- Read `.AGENT.md` (if exists) - Human-readable folder quick reference\n\n**Use this as reference while working.** Follow three-pass workflow from `AGENTS.json`. Use decision trees below for UNKNOWN or risky situations.\n\n---\n\n## 🚦 Decision Tree: Do I Need HITL?\n\n```text\nIs it risky? (security, money, production, external systems)\n├─ YES → Create HITL item → Stop work → Wait for completion\n└─ NO → Continue\n\nIs it UNKNOWN? (not in docs, manifest, or code)\n├─ YES → Mark <UNKNOWN> → Create HITL → Stop work\n└─ NO → Continue\n\nDoes it cross module boundaries?\n├─ YES → Requires ADR (Principle 23)\n└─ NO → Continue\n\nDid a waiverable gate fail? (coverage, performance, warnings)\n├─ YES → Create waiver using template → Link in PR\n└─ NO → Continue\n```\n\n---\n\n## 📜 Constitution (8 Articles) - Essential Rules\n\n**Article 1: Final Authority** - Solo founder has final say on ambiguity/conflicts\n\n**Article 2: Verifiable over Persuasive** - Work needs verification evidence. Proof beats persuasion.\n\n**Article 3: No Guessing** - If unknown: Mark `<UNKNOWN>` → Create HITL → Stop work\n\n**Article 4: Incremental Delivery** - Ship small, reviewable, testable increments. No mega-PRs.\n\n**Article 5: Strict Traceability** - Every change must link to task in `.repo/tasks/TODO.md`. Archive completed tasks.\n\n**Article 6: Safety Before Speed** - Risky changes: **STOP → ASK (HITL) → VERIFY → THEN PROCEED**\n\n**Article 7: Per-Repo Variation** - Workflow may vary per repo (via manifest)\n\n**Article 8: HITL for External Systems** - Credentials, billing, production, external services = always HITL\n\n---\n\n## 🎯 Key Principles (Most Critical)\n\n**Global Rule:** Filepaths required everywhere (PRs, logs, ADRs, waivers, comments)\n\n**P3: One Change Type Per PR** - Split work if multiple types needed\n\n**P4: Make It Shippable** - Each PR should be safe to merge and ship (or clearly blocked by HITL/waivers)\n\n**P5: Don't Break Surprises** - If users, security, money, or production behavior could change: call it out, add tests, add rollback plan, use HITL\n\n**P6: Evidence Over Vibes** - Show proof: commands, outputs, test results, filepaths\n\n**P7: UNKNOWN Is First-Class** - Mark explicitly, route to HITL\n\n**P8: Read Repo First** - Use `.repo/` docs + `repo.manifest.yaml` before deciding anything\n\n**P9: Assumptions Must Be Declared** - Any assumption must be written down and labeled as an assumption\n\n**P10: Risk Triggers a Stop** - Non-trivial risk → STOP → HITL → VERIFY\n\n**P11: Prefer Guardrails Over Heroics** - Prefer checks, tooling, and automation over \"trust me\"\n\n**P12: Rollback Thinking** - Every risky change must have rollback thinking (how to undo safely)\n\n**P13: Respect Boundaries** - Don't cross module boundaries unless rules allow\n\n**P14: Localize Complexity** - Put complexity where it belongs. Keep it contained.\n\n**P15: Consistency Beats Novelty** - Prefer existing patterns and names. Novelty requires justification.\n\n**P16: Decisions Written Down** - Record decisions in the smallest durable place (ADR only when triggered)\n\n**P17: PR Narration** - PR must explain: what, why, filepaths, verification, risks, rollback\n\n**P18: No Silent Scope Creep** - Do not expand scope without updating Task Packet and calling it out\n\n**P19: Docs Age With Code** - When code changes, docs must change too if they describe behavior\n\n**P20: Examples Are Contracts** - Examples define expected behavior. If code changes, examples must be updated\n\n**P21: Naming Matters** - Names must be clear. Avoid confusing abbreviations.\n\n**P22: Waivers Rare + Temporary** - Waivers are not permanent. They expire. They require a plan.\n\n**P23: ADR Required When Triggered** - Cross-feature imports require ADR. No exceptions.\n\n**P24: Logs Required for Non-Docs** - Non-doc-only changes require agent logs + trace logs + reasoning summary\n\n**P25: Token-Optimized TODO** - Use TODO/BACKLOG/ARCHIVE, archive completed work\n\n---\n\n## 📋 Three-Pass Workflow\n\n**Pass 0: Context** (When entering folder)\n- Read `.agent-context.json` if exists (machine-readable folder context)\n- Read `.AGENT.md` if exists (human-readable folder quick reference)\n\n1. **Plan**: Determine change type → Check boundaries → Create task packet (if required) → List actions, risks, files, UNKNOWNs → Get approval if needed\n   - **First:** Determine change type (feature/api_change/security/cross_module/non_doc_change)\n   - **Check boundaries:** Run `lint-imports --config .importlinter` or `node .repo/automation/scripts/check-boundaries.js` (see Boundary Checking below)\n   - **If feature/api_change/cross_module:** Create task packet in Pass 1 (see Task Packet Workflow below)\n   - If crossing boundaries → Create ADR (see ADR Workflow below)\n   - If risky/unknown → Create HITL → Stop work\n2. **Change**: Apply edits → Follow patterns → Include filepaths\n3. **Verify**: Run tests → Show evidence → Update logs → Document in PR\n   - Create trace log using `scripts/generate-trace-log.sh` (for non-doc changes)\n   - Create agent log using `scripts/generate-agent-log.sh` (for reasoning summary, P24)\n\n---\n\n## 🔍 Before Starting Work\n\n- [ ] Read `.repo/tasks/TODO.md` (current task) - **MUST READ FIRST**\n- [ ] Read `.repo/repo.manifest.yaml` (commands) - **BEFORE ANY COMMAND**\n- [ ] Check `.repo/policy/HITL.md` (blocking items?)\n- [ ] If crossing boundaries → Read `.repo/policy/BOUNDARIES.md`\n- [ ] If security-related → Read `.repo/policy/SECURITY_BASELINE.md`\n\n---\n\n## ⚠️ Never Do These\n\n- ❌ Guess commands (use manifest or HITL) - Article 3\n- ❌ Skip filepaths (required everywhere - global rule)\n- ❌ Modify policy files without approval\n- ❌ Commit secrets or `.env` files (absolute prohibition)\n- ❌ Cross boundaries without ADR (Principle 23)\n- ❌ Proceed with UNKNOWN items (Article 3)\n- ❌ Make risky changes without HITL (Article 6 & 8)\n- ❌ Create mega-PRs (Article 4: incremental delivery)\n- ❌ Skip verification evidence (Article 2)\n- ❌ Expand scope silently (Principle 18)\n- ❌ Make assumptions without declaring them (Principle 9)\n\n---\n\n## ✅ Always Do These\n\n- ✅ Include filepaths in all changes (global rule)\n- ✅ Link changes to task in `.repo/tasks/TODO.md` (Article 5)\n- ✅ Mark UNKNOWN → Create HITL (Article 3)\n- ✅ Follow three-pass workflow\n- ✅ Run `make lint` before PR\n- ✅ Archive completed tasks to `.repo/tasks/ARCHIVE.md` (Article 5)\n- ✅ Show verification evidence (Article 2, P6)\n- ✅ Explain what/why/filepaths/verification/risks/rollback in PR (P17)\n- ✅ Update docs when code behavior changes (P19)\n- ✅ Update examples when code changes (P20)\n- ✅ Declare assumptions explicitly (P9)\n- ✅ Think about rollback for risky changes (P12)\n\n---\n\n## 🛠️ Commands\n\n**Source of Truth:** `.repo/repo.manifest.yaml` (read this, don't guess - Article 3)\n\n```bash\nmake setup          # Install dependencies\nmake lint           # Run linters (backend + frontend)\nmake test           # Run tests (pytest + vitest)\nmake verify         # Full CI suite (light checks)\nmake verify SKIP_HEAVY=0  # Full suite (tests/build/OpenAPI)\nmake ci             # Alias for verify\n```\n\n**Backend:** `make -C backend migrate` | `make -C backend openapi`\n**Frontend:** `make -C frontend test` | `make -C frontend e2e`\n\n---\n\n## 🔗 Security Triggers (Require HITL - Article 8)\n\n1. Auth/login behavior change\n2. Money/payment flow change\n3. External service integration\n4. Sensitive data handling\n5. Production config/keys\n6. Cryptography/security controls\n7. Dependency vulnerabilities\n\n**Action:** Read `.repo/policy/SECURITY_BASELINE.md` → Create HITL → Stop work\n\n---\n\n## 🎯 Change Type Determination\n\n**When:** Determine change type in **Pass 1 (Plan)** before creating artifacts.\n\n**Decision Tree:**\n```\nDoes it touch security/auth/money/external systems?\n├─ YES → Change Type: \"security\" (requires HITL)\n└─ NO → Continue\n\nDoes it cross module/feature boundaries?\n├─ YES → Change Type: \"cross_module\" (requires ADR)\n└─ NO → Continue\n\nDoes it change API contracts/endpoints?\n├─ YES → Change Type: \"api_change\" (requires ADR + OpenAPI update)\n└─ NO → Continue\n\nDoes it add new functionality/features?\n├─ YES → Change Type: \"feature\"\n└─ NO → Continue\n\nIs it only documentation changes?\n├─ YES → No artifacts required (doc-only)\n└─ NO → Change Type: \"non_doc_change\" (requires agent log + trace log)\n```\n\n**Examples:**\n- **Feature:** Adding new user profile page, new dashboard widget, new report\n- **API Change:** Adding new endpoint, changing request/response format, versioning API\n- **Security:** Auth changes, payment flows, external service integration, sensitive data handling\n- **Cross-module:** Importing from one module into another, shared utilities across modules\n- **Non-doc change:** Bug fixes, refactoring, configuration changes, test updates\n\n**Important:** One change type per PR (Principle 3). If multiple types, split into separate PRs.\n\n---\n\n## 📝 Artifact Requirements\n\n| Change Type | Required Artifacts |\n|-------------|--------------------|\n| Feature | Task Packet, Trace Log, Tests |\n| API Change | Task Packet, ADR, Trace Log, OpenAPI update |\n| Security | HITL, Trace Log, Security tests |\n| Cross-module | ADR, Task Packet, Trace Log |\n| Non-doc change | Agent Log, Trace Log, Reasoning Summary (P24) |\n\n---\n\n## 🎯 Task Workflow\n\n1. Read `.repo/tasks/TODO.md` → Work on task\n   - **If TODO.md is empty:** Promote top task from `BACKLOG.md` to `TODO.md`\n2. Complete → Mark criteria `[x]`\n3. Move to `ARCHIVE.md` (prepend)\n4. Promote top task from `BACKLOG.md` to `TODO.md`\n\n---\n\n## 📝 Trace Log Workflow\n\n**When:** Create trace log in **Pass 3 (Verify)** after tests pass, for **non-doc changes only**.\n\n**How:**\n1. Run `scripts/generate-trace-log.sh [task-id] [intent]`\n2. Fill in required fields: `intent`, `files`, `commands`, `evidence`, `hitl`, `unknowns`\n3. Validate: `scripts/validate-trace-log.sh [trace-log-file]`\n4. Store in `.repo/traces/`\n\n**What it tracks:** What changed (files, commands, evidence)\n\n---\n\n## 📋 Agent Log Workflow\n\n**When:** Create agent log in **Pass 3 (Verify)** for **non-doc changes** (P24 requirement).\n\n**How:**\n1. Run `scripts/generate-agent-log.sh [task-id] [action]`\n2. Fill in: `intent`, `plan`, `actions`, `evidence`, `decisions`, `risks`, `reasoning_summary`\n3. Store in `.repo/logs/`\n\n**What it tracks:** Why/how (reasoning, decisions, assumptions)\n\n**Difference from trace log:**\n- **Trace log** = What changed (files, commands, evidence)\n- **Agent log** = Why/how (reasoning, decisions, assumptions)\n\n---\n\n## 📊 Agent Interaction Logging\n\n**When:** Log interactions during **Pass 0, 1, 2, 3** of workflow for metrics and debugging.\n\n**How:**\n1. Use logging SDK: `const logger = require('.repo/automation/scripts/agent-logger.js')`\n2. Log interactions: `logger.logInteraction({ agent, action, file, duration_ms, success, context })`\n3. Log errors: `logger.logError({ agent, action, error, context })`\n4. Logs are automatically written to `.agent-logs/interactions/` (JSONL format)\n5. Errors are written to `.agent-logs/errors/`\n6. Metrics are generated daily in `.agent-logs/metrics/`\n\n**Example:**\n```javascript\nconst logger = require('.repo/automation/scripts/agent-logger.js');\n\n// Log a file read operation\nconst startTime = Date.now();\ntry {\n  const content = fs.readFileSync('file.txt', 'utf8');\n  logger.logInteraction({\n    agent: 'Auto',\n    action: 'read_file',\n    file: 'file.txt',\n    duration_ms: Date.now() - startTime,\n    success: true,\n    context: { task: 'TASK-001', folder: 'backend' }\n  });\n} catch (err) {\n  logger.logError({\n    agent: 'Auto',\n    action: 'read_file',\n    error: err.message,\n    context: { file: 'file.txt' }\n  });\n}\n```\n\n**When to log:**\n- **Pass 0:** Log context file reads\n- **Pass 1:** Log planning actions (determining change type, creating task packets)\n- **Pass 2:** Log file operations (read, write, search)\n- **Pass 3:** Log verification actions (test runs, validation)\n\n**Note:** Logging is optional but recommended for metrics collection. If logger is unavailable, workflow continues without logging.\n\n---\n\n## 🔒 Boundary Checking\n\n**When:** Run in **Pass 1 (Plan)** before making changes, especially for cross-module work.\n\n**How:**\n1. Run boundary check: `lint-imports --config .importlinter`\n   - Or use script: `node .repo/automation/scripts/check-boundaries.js`\n2. Review violations (if any)\n3. If violations exist:\n   - **Fix:** Refactor to respect boundaries\n   - **Or create ADR:** If cross-module import is justified (see ADR Workflow)\n   - **Or create waiver:** If exception is needed (see Waiver Workflow)\n4. Re-run check until clean or waived\n\n**Boundary Rules:**\n- See `.repo/policy/BOUNDARIES.md` for full rules\n- Core module cannot depend on business modules\n- Business modules should not import each other directly\n- Cross-module imports require ADR (Principle 23)\n- API modules should not import from each other\n\n**CI Integration:** Boundary checks run automatically in CI. PRs with violations are blocked unless fixed or waived.\n\n---\n\n## 🏗️ ADR Workflow\n\n**When:** Required when crossing module/feature boundaries (Principle 23, BOUNDARIES.md).\n\n**Trigger:** Cross-feature imports detected → Create ADR in **Pass 1 (Plan)**.\n\n**How:**\n1. Detect triggers: `scripts/detect-adr-triggers.sh` or run boundary check\n2. Read `.repo/policy/BOUNDARIES.md` for boundary rules\n3. Create ADR: `scripts/create-adr-from-trigger.sh` or use template `.repo/templates/ADR_TEMPLATE.md`\n4. Store in `docs/adr/ADR-XXXX.md` (directory auto-created by script)\n5. Link ADR in PR description\n\n**Required for:** Cross-module imports, API contract changes, schema changes\n\n**Note:** `docs/adr/` directory must exist. If missing, create it: `mkdir -p docs/adr`\n\n---\n\n## 📦 Task Packet Workflow\n\n**When:** Required in **Pass 1 (Plan)** for change types: `feature`, `api_change`, `cross_module`.\n\n**How:**\n1. Determine change type (feature/api_change/cross_module)\n2. Create task packet using template `.repo/agents/prompts/task_packet.md`\n3. Store task packet:\n   - **Option 1 (Recommended):** Store as JSON file in `.repo/tasks/packets/TASK-XXX-packet.json`\n   - **Option 2:** Include in `.repo/tasks/TODO.md` as a code block or section\n4. Fill in all required fields:\n   - `goal`: What you're building/changing\n   - `non_goals`: What you're NOT doing\n   - `acceptance_criteria`: How to verify completion\n   - `approach`: How you'll implement it\n   - `files_touched`: List of files to modify (include filepaths)\n   - `verification_plan`: How you'll test/verify\n   - `risks`: Potential issues\n   - `rollback_plan`: How to undo if needed\n   - `hitl_requirements`: Any HITL items needed\n5. Link task packet in PR description\n\n**Examples:**\n- Feature: `.repo/templates/examples/example_task_packet.json`\n- API Change: See `.repo/templates/examples/` (create if missing)\n- Cross-module: See `.repo/templates/examples/` (create if missing)\n\n**Validation:** `governance-verify` checks that task packets exist for required change types.\n\n---\n\n## 📦 HITL Creation Workflow\n\n**When:** Required for risky changes (security, money, production, external systems) or UNKNOWN items.\n\n**How:**\n1. Run: `scripts/create-hitl-item.sh [category] [summary]`\n   - Categories: `External Integration`, `Clarification`, `Risk`, `Feedback`, `Vendor`\n   - Example: `scripts/create-hitl-item.sh Risk \"Payment flow change\" \"Modifying payment processing logic\"`\n2. Script creates `HITL-XXXX.md` in `.repo/hitl/`\n3. Script updates `.repo/policy/HITL.md` index automatically\n4. Link HITL item in PR description: `HITL-XXXX`\n5. Wait for HITL item status to be \"Completed\" before proceeding\n\n**Required for:**\n- Security changes (auth, money, external systems)\n- UNKNOWN items (not in docs/manifest/code)\n- Risky production changes\n\n**See:** `.repo/policy/HITL.md` for full process\n\n---\n\n## 🎫 Waiver Workflow\n\n**When:** Waiverable gate fails (coverage, performance, warnings) per QUALITY_GATES.md.\n\n**How:**\n1. `governance-verify` detects waiverable failure → suggests waiver\n2. Create waiver: `scripts/create-waiver.sh` or use template `.repo/templates/WAIVER_TEMPLATE.md`\n3. Store in `.repo/waivers/WAIVER-XXX.md`\n4. Add to `.repo/policy/WAIVERS.md` index\n5. Set expiration date (waivers are temporary per Principle 22)\n6. Link waiver in PR description\n\n**Check expired:** `scripts/check-expired-waivers.sh`\n\n---\n\n## 📚 When to Read Full Policy Documents\n\n**Read full documents only when:**\n- Need deeper context on a specific article/principle\n- Encountering edge case not covered here\n- Need to understand full policy structure\n- Creating ADR/waiver and need full context\n\n**Full documents:**\n- `.repo/policy/CONSTITUTION.md` - All 8 articles (detailed)\n- `.repo/policy/PRINCIPLES.md` - All 25 principles (detailed)\n- `.repo/policy/QUALITY_GATES.md` - Merge requirements (before PR)\n- `.repo/policy/SECURITY_BASELINE.md` - Security rules (security work)\n- `.repo/policy/BOUNDARIES.md` - Boundary rules (cross-module work)\n- `.repo/policy/HITL.md` - HITL process (creating HITL items)\n- `.repo/policy/BESTPR.md` - Repo-specific patterns (backend/frontend work)\n\n**Document map:** See `.repo/DOCUMENT_MAP.md` for when to read what\n\n---\n\n## 🔧 Governance Scripts\n\n```bash\n# HITL Management\n./scripts/create-hitl-item.sh [category] [summary]\npython3 scripts/sync-hitl-to-pr.py [PR_NUMBER]\n./scripts/archive-hitl-items.sh [--dry-run]\n\n# Trace Logs\n./scripts/generate-trace-log.sh [task-id] [intent]\n./scripts/validate-trace-log.sh [trace-log-file]\nnode .repo/automation/scripts/validate-agent-trace.js [trace-log-file]\n\n# Agent Logs\n./scripts/generate-agent-log.sh [task-id] [action]\n\n# Task Management\n./scripts/validate-task-format.sh [task-file]\n./scripts/get-next-task-number.sh\n./scripts/promote-task.sh [task-id]\npython3 scripts/archive-task.py [--force]\n\n# ADR Management\n./scripts/detect-adr-triggers.sh [base-branch]\n./scripts/create-adr-from-trigger.sh\n\n# Waiver Management\n./scripts/create-waiver.sh\n./scripts/suggest-waiver.sh\n./scripts/check-expired-waivers.sh\n\n# PR Validation\n./scripts/validate-pr-body.sh [pr-body-file]\n\n# Governance Verification\n./scripts/governance-verify.sh  # Bash version (canonical, used in CI)\nnode .repo/automation/scripts/governance-verify.js  # Node.js version (alternative)\n```\n\n---\n\n## 📁 Key Files\n\n| File | Purpose |\n|------|---------|\n| `.repo/tasks/TODO.md` | Current active task (ONE only) |\n| `.repo/tasks/BACKLOG.md` | Prioritized queue (P0→P3) |\n| `.repo/repo.manifest.yaml` | Commands (single source of truth) |\n| `.repo/policy/HITL.md` | Human-in-the-loop items |\n| `.repo/templates/examples/` | Format examples |\n\n\n---\n\n**Remember**: This document has all essential rules. Read full policy documents only when you need deeper context or encounter edge cases.\n"
        },
        {
          "path": ".repo/agents/AGENTS.md",
          "type": "Markdown",
          "purpose": "Deep dive on agent rules (if QUICK_REFERENCE insufficient)",
          "status": "Referenced but not read in detail (token optimization)",
          "used_by": [
            "Agents needing deeper context"
          ],
          "content": "# Agents Framework\n\n**File**: `.repo/agents/AGENTS.md`\n\nAgents operate ONLY within the rules defined in `.repo/policy/*.md` and `.repo/GOVERNANCE.md`.\n\n## Core Rules (Plain English)\n\n- **No guessing.** If something is not explicitly known, declare UNKNOWN and create a HITL item.\n- **Filepaths required everywhere.** All changes, PRs, logs, and documentation must include filepaths.\n- **Three-pass code generation required:**\n  1) Plan (list actions, risks, files, UNKNOWNs)\n  2) Change (apply edits)\n  3) Verify (tests, evidence, logs, trace)\n- **All logs must follow** `.repo/templates/AGENT_LOG_TEMPLATE.md`.\n- **All trace logs must follow** `.repo/templates/AGENT_TRACE_SCHEMA.json`.\n- **Cross-feature imports require ADR.** See `.repo/policy/BOUNDARIES.md` and Principle 23.\n- **Boundary model enforced:** For Django modules, see `.repo/policy/BOUNDARIES.md` for UBOS-specific rules (api → modules → config/core with firm-scoping).\n\n## UNKNOWN Workflow\n\nWhen encountering uncertainty:\n1. Mark the item as `<UNKNOWN>` in any relevant file (manifest, plan, etc.)\n2. Create a HITL item in `.repo/policy/HITL.md`\n3. Stop work on that uncertain portion\n4. Do not proceed until HITL item is resolved\n\n## Three-Pass Code Generation\n\n### Pass 1: Plan\n- List all actions to be taken\n- Identify risks and required HITL items\n- List all files that will be modified\n- Mark any UNKNOWN items\n- Get approval if required (HITL, ADR, etc.)\n\n### Pass 2: Change\n- Apply edits to files\n- Follow existing patterns and boundaries\n- Include filepaths in all changes\n- Do not proceed if Pass 1 identified blockers\n\n### Pass 3: Verify\n- Run tests (unit, integration, e2e as appropriate)\n- Provide evidence (command outputs, test results)\n- Update logs and trace files\n- Ensure all quality gates pass\n- Document verification in PR\n\n## Required References\n\nAll agents must reference:\n- `.repo/policy/CONSTITUTION.md` - Fundamental articles\n- `.repo/policy/PRINCIPLES.md` - Operating principles\n- `.repo/policy/BOUNDARIES.md` - Architectural boundaries\n- `.repo/policy/QUALITY_GATES.md` - Merge requirements\n- `.repo/policy/SECURITY_BASELINE.md` - Security rules\n- `.repo/policy/HITL.md` - Human-in-the-loop process\n- `.repo/repo.manifest.yaml` - Command definitions\n- `.repo/GOVERNANCE.md` - Framework entry point\n\n## Capabilities and Roles\n\n**Note:** This is a **single-agent system**. You are the only agent working on tasks. The role definitions in `.repo/agents/roles/` exist for potential future multi-agent scenarios but are not currently used.\n\nSee:\n- `.repo/agents/capabilities.md` - List of all capabilities\n- `.repo/agents/roles/` - Role definitions (for reference only, not currently used)\n\n## Quick Reference\n\nFor a one-page cheat sheet, see `.repo/agents/QUICK_REFERENCE.md`.\n\n## Trace Logs\n\n**When to create:** In Pass 3 (Verify) after tests pass, for **non-doc changes only**.\n\n**What it tracks:** What changed (files, commands, evidence, HITL items, unknowns).\n\n**How:**\n1. Create: `scripts/generate-trace-log.sh [task-id] [intent]`\n2. Fill in required fields per `.repo/templates/AGENT_TRACE_SCHEMA.json`\n3. Validate: `scripts/validate-trace-log.sh [trace-log-file]` or `node .repo/automation/scripts/validate-agent-trace.js [trace-log-file]`\n4. Store in `.repo/traces/` (directory auto-created by script)\n\n## Agent Logs\n\n**When to create:** In Pass 3 (Verify) for **non-doc changes** (P24 requirement: Logs Required for Non-Docs).\n\n**What it tracks:** Why/how (reasoning, decisions, assumptions, plan, risks).\n\n**How:**\n1. Create: `scripts/generate-agent-log.sh [task-id] [action]`\n2. Fill in: `intent`, `plan`, `actions`, `evidence`, `decisions`, `risks`, `reasoning_summary`\n3. Store in `.repo/logs/` (directory auto-created by script)\n\n**Difference from trace log:**\n- **Trace log** = What changed (files, commands, evidence)\n- **Agent log** = Why/how (reasoning, decisions, assumptions)\n\n## Examples\n\nSee `.repo/templates/examples/` for example files:\n- `example_trace_log.json` - Trace log format\n- `example_hitl_item.md` - HITL item format\n- `example_waiver.md` - Waiver format\n- `example_task_packet.json` - Task packet format\n"
        },
        {
          "path": ".repo/agents/capabilities.md",
          "type": "Markdown",
          "purpose": "What agent role can do",
          "used_by": [
            "Agents checking capabilities"
          ],
          "content": "# Agent Capabilities\n\n**File**: `.repo/agents/capabilities.md`\n\nThis file lists all available agent capabilities. See `.repo/agents/roles/` for which roles have access to which capabilities.\n\n## Capability List\n\n- `create_feature` - Create new features/modules\n- `modify_existing` - Modify existing code within boundaries\n- `add_dependency` - Add new dependencies (requires security review)\n- `change_api_contract` - Modify API contracts (requires ADR)\n- `change_schema` - Modify database schemas (requires migration planning)\n- `update_security` - Update security configurations (requires HITL)\n- `update_release_process` - Modify release/deployment process (release role only)\n- `apply_waiver` - Apply policy waivers (reviewer role only)\n- `create_adr` - Create Architecture Decision Records\n- `create_task_packet` - Create task definitions\n- `run_verification_profiles` - Execute verification commands from manifest\n"
        },
        {
          "path": ".repo/agents/rules-compact.md",
          "type": "Markdown",
          "purpose": "Compact version of rules",
          "used_by": [
            "Token-constrained scenarios"
          ],
          "content": "# Agent Rules (Compact)\n\n**Token-optimized essential rules. Full context: `.repo/agents/QUICK_REFERENCE.md`**\n\n## Required Files (Start)\n1. `.repo/tasks/TODO.md`\n2. `.repo/repo.manifest.yaml`\n3. `.repo/agents/QUICK_REFERENCE.md`\n\n## Constitution (8 Articles)\n- **A1:** Solo founder = final authority\n- **A2:** Verification evidence required (proof > persuasion)\n- **A3:** Unknown → Mark `<UNKNOWN>` → HITL → Stop\n- **A4:** Small, shippable increments (no mega-PRs)\n- **A5:** Link to task, archive completed\n- **A6:** Risky → STOP → HITL → VERIFY → PROCEED\n- **A7:** Workflow varies per repo (manifest)\n- **A8:** External systems = always HITL\n\n## Principles (Critical)\n- **Global:** Filepaths everywhere\n- **P3:** One change type per PR\n- **P6:** Evidence over vibes\n- **P7:** UNKNOWN is first-class\n- **P10:** Risk → STOP → HITL\n- **P13:** Respect boundaries\n- **P17:** PR: what/why/filepaths/verification/risks/rollback\n- **P23:** Cross-boundaries → ADR required\n\n## Workflow: Three-Pass\n1. **Plan:** Actions, risks, files, UNKNOWNs → Approval\n2. **Change:** Edits, patterns, filepaths\n3. **Verify:** Tests, evidence, logs, quality gates, PR docs\n\n## HITL Decision Tree\n```\nRisky? (security/money/prod/external) → YES → HITL → Stop\nUnknown? (not in docs/manifest/code) → YES → <UNKNOWN> → HITL → Stop\nCross-boundaries? → YES → ADR required\n```\n\n## Security Triggers (A8)\n1. Auth/login change\n2. Money/payment flow\n3. External service\n4. Sensitive data\n5. Production config/keys\n6. Cryptography/security\n7. Dependency vulns\n\n## Always\n- Filepaths in all changes\n- Link to `.repo/tasks/TODO.md` (A5)\n- UNKNOWN → HITL (A3)\n- Three-pass workflow\n- `make lint` before PR\n- Archive completed (A5)\n- Verification evidence (A2, P6)\n- PR: what/why/filepaths/verification/risks/rollback (P17)\n- Update docs/examples when code changes (P19, P20)\n- Declare assumptions (P9)\n- Rollback thinking for risky (P12)\n\n## Never\n- Guess commands (A3) → Use manifest/HITL\n- Skip filepaths (global)\n- Modify policies without approval\n- Commit secrets/.env (prohibited)\n- Cross boundaries without ADR (P23)\n- Proceed with UNKNOWN (A3)\n- Risky changes without HITL (A6, A8)\n- Mega-PRs (A4)\n- Skip verification (A2)\n- Silent scope creep (P18)\n- Undeclared assumptions (P9)\n\n## Artifacts by Change Type\n- **Feature:** Task packet, trace log, tests\n- **API:** Task packet, ADR, trace log, OpenAPI update\n- **Security:** HITL, trace log, security tests\n- **Cross-module:** ADR, task packet, trace log\n- **Non-doc:** Agent log, trace log, reasoning summary (P24)\n\n## Commands (Source: `.repo/repo.manifest.yaml`)\n```bash\nmake setup          # Install\nmake lint           # Lint\nmake test           # Test\nmake verify         # CI (light)\nmake verify SKIP_HEAVY=0  # CI (full)\nmake -C backend migrate/openapi\nmake -C frontend test/e2e\n```\n\n## Tech Stack\n- **Backend:** Django 4.2 + Python 3.11 + PostgreSQL 15\n- **Frontend:** React 18.3 + TypeScript 5.9 + Vite 5.4\n- **Data:** TanStack React Query, React Hook Form\n\n## Code Patterns\n- **Backend:** `class ViewSet(FirmScopedMixin, viewsets.ModelViewSet)`\n- **Frontend:** `export const Component: React.FC = () => { useQuery(...) }`\n\n## Conditional Reading\n- **Security work:** `.repo/policy/SECURITY_BASELINE.md` + `.repo/policy/HITL.md`\n- **Cross-boundaries:** `.repo/policy/BOUNDARIES.md`\n- **Creating PR:** `.repo/policy/QUALITY_GATES.md` + `.repo/templates/PR_TEMPLATE.md`\n- **Unknown:** `.repo/policy/HITL.md`\n\n**Full rules:** `.repo/agents/QUICK_REFERENCE.md` | **Machine-readable:** `.repo/agents/rules.json`\n"
        },
        {
          "path": ".repo/agents/FORMATS.md",
          "type": "Markdown",
          "purpose": "Format specifications for artifacts",
          "used_by": [
            "Agents creating artifacts"
          ],
          "content": "# Agent Rules Formats\n\n**Purpose:** Multiple formats for different use cases - machine-readable, compact, and comprehensive.\n\n---\n\n## Available Formats\n\n### 1. `rules.json` - Machine-Readable Format\n\n**Purpose:** Structured JSON for programmatic access, tooling, and automation\n\n**Use Cases:**\n- Agent tooling that needs to parse rules programmatically\n- Validation scripts\n- Rule checking automation\n- Generating documentation from structured data\n\n**Structure:**\n- JSON Schema compliant\n- Hierarchical organization\n- All rules with source references\n- Workflows as structured data\n- Commands, tech stack, code patterns\n\n**Token Cost:** ~300-400 tokens\n\n**Example Usage:**\n```python\nimport json\nwith open('.repo/agents/rules.json') as f:\n    rules = json.load(f)\n    if change_type == 'security':\n        triggers = rules['security']['triggers']\n```\n\n---\n\n### 2. `rules-compact.md` - Ultra-Compact Format\n\n**Purpose:** Minimal token usage while preserving all essential rules\n\n**Use Cases:**\n- Quick rule lookup when context is already loaded\n- Token-constrained environments\n- Quick reference during work\n- Mobile/limited context scenarios\n\n**Features:**\n- ~70% smaller than QUICK_REFERENCE.md\n- All essential rules preserved\n- Abbreviated but clear\n- References full QUICK_REFERENCE.md for context\n\n**Token Cost:** ~150-200 tokens\n\n**Trade-offs:**\n- Less explanatory text\n- Assumes some context already loaded\n- Best for agents familiar with framework\n\n---\n\n### 3. `QUICK_REFERENCE.md` - Comprehensive Format\n\n**Purpose:** Complete reference with all essential rules and context\n\n**Use Cases:**\n- First-time agent onboarding\n- When full context is needed\n- Reference for edge cases\n- Human review\n\n**Features:**\n- All 8 Constitutional Articles (detailed)\n- All 25 Principles (listed)\n- Complete decision trees\n- Full explanations\n- Examples and references\n\n**Token Cost:** ~400-500 tokens\n\n**Best For:** Primary reference document\n\n---\n\n## Format Comparison\n\n| Format | Tokens | Authority | Clarity | Machine-Readable | Use Case |\n|--------|--------|-----------|---------|------------------|----------|\n| `rules.json` | 300-400 | ✅ Full | ✅ Structured | ✅ Yes | Tooling, automation |\n| `rules-compact.md` | 150-200 | ✅ Full | ✅ Clear | ❌ No | Quick lookup, token-constrained |\n| `QUICK_REFERENCE.md` | 400-500 | ✅ Full | ✅ Excellent | ❌ No | Primary reference, onboarding |\n\n---\n\n## When to Use Which Format\n\n### Use `rules.json` when:\n- Building tooling/automation\n- Need programmatic rule access\n- Validating against rules\n- Generating documentation\n- Integrating with other systems\n\n### Use `rules-compact.md` when:\n- Token budget is tight\n- Quick rule lookup needed\n- Context already loaded\n- Mobile/limited context\n- Familiar with framework\n\n### Use `QUICK_REFERENCE.md` when:\n- First-time onboarding\n- Need full explanations\n- Encountering edge cases\n- Human review needed\n- Primary reference\n\n---\n\n## Token Optimization Strategy\n\n**Recommended Approach:**\n\n1. **Start with:** `rules-compact.md` (~200 tokens)\n2. **If insufficient:** Load `QUICK_REFERENCE.md` (~400-500 tokens)\n3. **For tooling:** Use `rules.json` (~300-400 tokens)\n\n**Total Savings:**\n- Using compact: ~200 tokens vs ~500 tokens = 60% savings\n- Using JSON: ~300 tokens vs ~500 tokens = 40% savings\n- Both maintain full authority and clarity\n\n---\n\n## Format Maintenance\n\n**Source of Truth:** `QUICK_REFERENCE.md`\n\n**Sync Strategy:**\n- `rules-compact.md` - Manually maintained, extract from QUICK_REFERENCE\n- `rules.json` - Manually maintained, structured version of QUICK_REFERENCE\n\n**Future:** Auto-generate compact and JSON from QUICK_REFERENCE.md\n\n---\n\n## Authority & Clarity\n\n**All formats maintain:**\n- ✅ Full authority (all rules included)\n- ✅ Clear structure (easy to understand)\n- ✅ Source references (traceable to origin)\n- ✅ Complete coverage (nothing missing)\n\n**Differences:**\n- **Compact:** Less explanation, same rules\n- **JSON:** Structured format, same rules\n- **QUICK_REFERENCE:** Full explanation, same rules\n\n**No information loss** - only format and verbosity differ.\n\n---\n\n**End of Formats Guide**\n"
        },
        {
          "path": ".repo/agents/checklists/change-plan.md",
          "type": "Markdown",
          "purpose": "Checklist for planning changes",
          "used_by": [
            "Agents in Pass 1 (Plan)"
          ],
          "content": "# /.repo/agents/checklists/change-plan.md\n- Identify change type.\n- Read relevant policy files.\n- Declare UNKNOWNs.\n- Create HITL items if needed.\n- List filepaths.\n- Outline approach.\n- Prepare verification plan.\n"
        },
        {
          "path": ".repo/agents/checklists/pr-review.md",
          "type": "Markdown",
          "lines": 9,
          "purpose": "PR review checklist",
          "key_contents": [
            "One change type?",
            "Task packet complete?",
            "Evidence present?",
            "Logs + Trace included?",
            "Boundaries respected?",
            "HITL satisfied?",
            "Waivers valid?"
          ],
          "used_by": [
            "Agents creating/reviewing PRs"
          ],
          "content": "# /.repo/agents/checklists/pr-review.md\n- One change type?\n- Task packet complete?\n- Evidence present?\n- Logs + Trace included?\n- Boundaries respected?\n- HITL satisfied?\n- Waivers valid?\n"
        },
        {
          "path": ".repo/agents/checklists/incident.md",
          "type": "Markdown",
          "purpose": "Incident response checklist",
          "used_by": [
            "Agents handling incidents"
          ],
          "content": "# /.repo/agents/checklists/incident.md\n- Describe issue.\n- Identify impacted files.\n- Assess risk.\n- Determine HITL needs.\n- Document fix plan.\n- Provide verification steps.\n"
        },
        {
          "path": ".repo/agents/prompts/pr_template.md",
          "type": "Markdown",
          "purpose": "PR template prompt",
          "used_by": [
            "Agents creating PRs"
          ],
          "content": "# /.repo/agents/prompts/pr_template.md\n{\n  \"change_type\": \"\",\n  \"summary\": \"\",\n  \"task_packet\": \"<embed-or-link>\",\n  \"filepath_changes\": [],\n  \"verification_commands_run\": [],\n  \"evidence\": [],\n  \"risks\": [],\n  \"rollback\": \"\",\n  \"hitl\": [],\n  \"notes\": \"One change type per PR. Evidence over vibes.\"\n}\n"
        },
        {
          "path": ".repo/agents/prompts/task_packet.md",
          "type": "Markdown",
          "purpose": "Task packet creation prompt",
          "used_by": [
            "Agents creating task packets"
          ],
          "content": "# /.repo/agents/prompts/task_packet.md\n{\n  \"goal\": \"\",\n  \"non_goals\": [],\n  \"acceptance_criteria\": [],\n  \"approach\": \"\",\n  \"files_touched\": [],\n  \"verification_plan\": [],\n  \"risks\": [],\n  \"rollback_plan\": \"\",\n  \"hitl_requirements\": [],\n  \"notes\": \"Filepaths required. No guessing. UNKNOWN → HITL.\"\n}\n"
        },
        {
          "path": ".repo/agents/roles/primary.md",
          "type": "Markdown",
          "purpose": "Primary agent role definition",
          "used_by": [
            "Primary agents"
          ],
          "content": "# Primary Agent Role\n\n**File**: `.repo/agents/roles/primary.md`\n\nPrimary agents have full capabilities except for waiver and release process management.\n\n## Capabilities\n\nPrimary agents can:\n- `create_feature`\n- `modify_existing`\n- `add_dependency` (with security review)\n- `change_api_contract` (with ADR)\n- `change_schema` (with migration planning)\n- `update_security` (with HITL)\n- `create_adr`\n- `create_task_packet`\n- `run_verification_profiles`\n\n## Restrictions\n\nPrimary agents CANNOT:\n- `apply_waiver` (reviewer role only)\n- `update_release_process` (release role only)\n\n## Workflow\n\nPrimary agents follow the standard three-pass workflow:\n1. Plan (with HITL escalation when needed)\n2. Change (within boundaries)\n3. Verify (with evidence)\n"
        },
        {
          "path": ".repo/agents/roles/secondary.md",
          "type": "Markdown",
          "purpose": "Secondary agent role definition",
          "used_by": [
            "Secondary agents"
          ],
          "content": "# Secondary Agent Role\n\n**File**: `.repo/agents/roles/secondary.md`\n\nSecondary agents have limited capabilities focused on modifications within existing boundaries.\n\n## Capabilities\n\nSecondary agents can:\n- `modify_existing` (within boundaries only)\n- Refactor/port code within module boundaries\n- `run_verification_profiles`\n\n## Restrictions\n\nSecondary agents CANNOT:\n- `create_feature`\n- `add_dependency`\n- `change_api_contract`\n- `change_schema`\n- `update_security`\n- `apply_waiver`\n- `update_release_process`\n- `create_adr`\n- `create_task_packet`\n\n## Workflow\n\nSecondary agents follow the standard three-pass workflow but with stricter boundary enforcement. All changes must stay within existing module boundaries.\n"
        },
        {
          "path": ".repo/agents/roles/reviewer.md",
          "type": "Markdown",
          "purpose": "Reviewer agent role definition",
          "used_by": [
            "Reviewer agents"
          ],
          "content": "# Reviewer Role\n\n**File**: `.repo/agents/roles/reviewer.md`\n\nReviewer is a human role that controls waivers and enforcement.\n\n## Capabilities\n\nReviewers can:\n- `apply_waiver` - Approve policy exceptions\n- Review and approve HITL items\n- Enforce quality gates\n- Review ADRs\n- Approve security changes\n\n## Responsibilities\n\n- Review PRs for compliance with governance rules\n- Approve or reject waivers\n- Mark HITL items as Completed\n- Ensure all quality gates are met before merge\n- Verify evidence and traceability\n\n## Workflow\n\nReviewers operate outside the three-pass agent workflow. They provide human judgment and approval for high-risk decisions.\n"
        },
        {
          "path": ".repo/agents/roles/release.md",
          "type": "Markdown",
          "purpose": "Release agent role definition",
          "used_by": [
            "Release agents"
          ],
          "content": "# Release Role\n\n**File**: `.repo/agents/roles/release.md`\n\nRelease is a human role that controls release process and deployment.\n\n## Capabilities\n\nRelease role can:\n- `update_release_process` - Modify release/deployment procedures\n- Deploy to production\n- Manage release artifacts\n- Control release gates\n\n## Responsibilities\n\n- Manage release process changes\n- Execute production deployments\n- Verify release readiness\n- Manage release artifacts and versioning\n\n## Workflow\n\nRelease role operates outside the three-pass agent workflow. They control the final step of getting code to production.\n"
        },
        {
          "path": ".repo/AGENT.md",
          "type": "Markdown",
          "lines": 25,
          "purpose": "Quick start guide pointing to rules.json",
          "key_contents": [
            "Points to rules.json for complete rules",
            "Quick start reading order",
            "Note about single-agent system"
          ],
          "used_by": [
            "Agents entering .repo directory"
          ],
          "content": "# .repo/AGENT.md\n\n**All agent rules are in:** `.repo/agents/rules.json`\n\n**Read that file for complete rules, workflows, and policies.**\n\n---\n\n## Quick Start (Reading Order)\n\n**Canonical reading order (per AGENTS.json):**\n\n1. Read `.repo/tasks/TODO.md` - Current task (MUST READ FIRST)\n2. Read `.repo/repo.manifest.yaml` - Commands (BEFORE ANY COMMAND)\n3. Read `.repo/agents/QUICK_REFERENCE.md` - Rules (START HERE for human-readable)\n4. Follow three-pass workflow from `AGENTS.json`\n\n**Alternative:** If you prefer machine-readable format, use `.repo/agents/rules.json` instead of step 3.\n\n---\n\n**For full policy context:** See `.repo/policy/CONSTITUTION.md` and `.repo/policy/PRINCIPLES.md`\n\n**Note:** This is a single-agent system. You are the only agent working on tasks.\n"
        }
      ]
    },
    "task_management": {
      "description": "Task management files",
      "files": [
        {
          "path": ".repo/tasks/TODO.md",
          "type": "Markdown",
          "lines": 86,
          "purpose": "Current active task (single task only)",
          "key_contents": [
            "Workflow instructions",
            "Task completion process",
            "Task format reference",
            "Active task section"
          ],
          "dependencies": [
            "BACKLOG.md",
            "ARCHIVE.md"
          ],
          "used_by": [
            "Agents as FIRST file to read (per AGENTS.json)"
          ],
          "workflow": "When task completes → archive → promote from BACKLOG",
          "content": "# 🎯 Current Task\n\n> **Single Active Task** — Only ONE task should be in this file at any time.\n\n**Agent Instructions:** This is your current task. Read this file FIRST.\n\n**Reading order (canonical per AGENTS.json):**\n1. This file (`.repo/tasks/TODO.md`) - Current task - **MUST READ FIRST**\n2. `.repo/repo.manifest.yaml` - Commands - **BEFORE ANY COMMAND**\n3. `.repo/agents/QUICK_REFERENCE.md` - Rules - **START HERE**\n4. Conditional: Policy docs as needed (security, boundaries, etc.)\n\n---\n\n## Your Current Task\n\n**Do this:**\n1. Read task below\n2. Follow three-pass workflow from `AGENTS.json`:\n   - Plan: List actions, risks, files, UNKNOWNs\n   - Change: Apply edits, include filepaths\n   - Verify: Run tests, show evidence, update logs\n3. Mark criteria `[x]` when done\n4. Archive when all criteria met\n\n---\n\n## Workflow Instructions\n\n### When Task is Completed:\n1. Mark the task checkbox as complete: `- [x]`\n2. Add completion date: `Completed: YYYY-MM-DD`\n3. Move the entire task block to `ARCHIVE.md` (prepend to top)\n4. Move the highest priority task from `BACKLOG.md` to this file\n5. Update the task status to `In Progress`\n\n### Task Format Reference:\n```markdown\n### [TASK-XXX] Task Title\n- **Priority:** P0 | P1 | P2 | P3\n- **Status:** In Progress\n- **Created:** YYYY-MM-DD\n- **Context:** Brief description of why this task matters\n\n#### Acceptance Criteria\n- [ ] Criterion 1\n- [ ] Criterion 2\n\n#### Notes\n- Any relevant context or links\n```\n\n---\n\n## Active Task\n\n> **Welcome!** 👋 If this section is empty, you need to promote a task from the backlog:\n>\n> 1. Read `.repo/tasks/BACKLOG.md` to see available tasks\n> 2. Find the highest priority task (P0 → P1 → P2 → P3)\n> 3. Copy the task block from `BACKLOG.md` to this file\n> 4. Update status from `Pending` to `In Progress`\n> 5. Remove the task from `BACKLOG.md`\n>\n> **Then:** Follow the three-pass workflow from `AGENTS.json` to complete the task.\n\n---\n\n### [TASK-001] Refine AGENTS.md to Be Concise & Effective\n- **Priority:** P0\n- **Status:** In Progress\n- **Created:** 2026-01-23\n- **Context:** Current AGENTS.md is 22 lines. Best practice is 50-100 lines that are highly specific and example-driven, NOT verbose documentation.\n\n#### Acceptance Criteria\n- [ ] Include all six core areas: Commands, Testing, Project Structure, Code Style, Git Workflow, Boundaries\n- [ ] Add specific tech stack with versions (Django 4.2 + Python 3.11 + React 18 + TypeScript)\n- [ ] Include 1-2 code examples (showing patterns, not explaining them)\n- [ ] Document clear boundaries (what agents must NEVER do)\n- [ ] Keep total length under 100 lines\n\n#### Notes\n- \"One real code snippet beats three paragraphs\" — GitHub research\n- Tools: Cursor, Codex mobile, Claude mobile, GitHub Copilot mobile\n- Reference: https://agents.md (official spec)\n"
        },
        {
          "path": ".repo/tasks/BACKLOG.md",
          "type": "Markdown",
          "lines": 225,
          "purpose": "Prioritized queue of pending tasks (P0 → P3)",
          "key_contents": [
            "Workflow instructions (adding, promoting)",
            "Task format template",
            "Priority legend (P0-P3 with SLA)",
            "Tasks organized by priority"
          ],
          "dependencies": [
            "TODO.md",
            "archive-task.py",
            "promote-task.sh"
          ],
          "used_by": [
            "Agents promoting tasks",
            "archive-task.py"
          ],
          "workflow": "Top task promoted to TODO.md when TODO is empty",
          "content": "# 📋 Task Backlog\n\n> **Prioritized Queue** — All open tasks ordered by priority (P0 highest → P3 lowest).\n\n---\n\n## Workflow Instructions\n\n### Adding New Tasks:\n1. Use the standard task format (see template below)\n2. Assign appropriate priority: P0 (Critical) | P1 (High) | P2 (Medium) | P3 (Low)\n3. Insert task in correct priority order (P0 tasks at top)\n4. Include clear acceptance criteria\n\n### Promoting Tasks:\n1. When `TODO.md` is empty, move the TOP task from this file to `TODO.md`\n2. Update status from `Pending` to `In Progress`\n3. Remove the task from this file\n\n### Task Format Template:\n```markdown\n### [TASK-XXX] Task Title\n- **Priority:** P0 | P1 | P2 | P3\n- **Status:** Pending\n- **Created:** YYYY-MM-DD\n- **Context:** Brief description of why this task matters\n\n#### Acceptance Criteria\n- [ ] Criterion 1\n- [ ] Criterion 2\n\n#### Notes\n- Any relevant context or links\n```\n\n---\n\n## Priority Legend\n| Priority | Meaning | SLA |\n|----------|---------|-----|\n| **P0** | Critical / Blocking | Immediate |\n| **P1** | High / Important | This week |\n| **P2** | Medium / Should do | This month |\n| **P3** | Low / Nice to have | When possible |\n\n---\n\n## P0 — Critical\n\n### [TASK-002] Create .env.example File\n- **Priority:** P0\n- **Status:** Pending\n- **Created:** 2026-01-23\n- **Context:** Code references `.env.example` but file doesn't exist. Blocks new environment setup.\n\n#### Acceptance Criteria\n- [ ] Document all required environment variables from `env_validator.py`\n- [ ] Include comments explaining each variable\n- [ ] Add placeholder values (never real secrets)\n- [ ] Reference in README.md and docs/getting-started/onboarding.md\n\n#### Notes\n- Required vars: DJANGO_SECRET_KEY, POSTGRES_*, AWS_*, STRIPE_*, etc.\n- Production vars differ from development vars\n\n---\n\n### [TASK-003] Fix Duplicate Content in CI Workflow\n- **Priority:** P0\n- **Status:** Pending\n- **Created:** 2026-01-23\n- **Context:** `.github/workflows/ci.yml` has two conflicting workflow definitions causing confusion.\n\n#### Acceptance Criteria\n- [ ] Remove duplicate workflow definition\n- [ ] Ensure single coherent CI pipeline\n- [ ] Verify all jobs run correctly\n- [ ] Test on a branch before merging\n\n#### Notes\n- File currently has 403 lines with overlapping `name: CI` and `name: CI/CD Pipeline`\n\n---\n\n## P1 — High\n\n### [TASK-004] Create .github/copilot-instructions.md\n- **Priority:** P1\n- **Status:** Pending\n- **Created:** 2026-01-23\n- **Context:** Context engineering file for GitHub Copilot and VS Code AI features.\n\n#### Acceptance Criteria\n- [ ] Document product vision and architecture principles\n- [ ] Include contribution guidelines for AI\n- [ ] Reference supporting docs (ARCHITECTURE.md, PRODUCT.md)\n- [ ] Test with Copilot to verify context is picked up\n\n#### Notes\n- Part of the VS Code context engineering workflow standard\n\n---\n\n### [TASK-005] Create PRODUCT.md\n- **Priority:** P1\n- **Status:** Pending\n- **Created:** 2026-01-23\n- **Context:** Product vision document giving AI context about WHY features exist.\n\n#### Acceptance Criteria\n- [ ] Define UBOS product vision and mission\n- [ ] Document target users (service firms)\n- [ ] List key features and their business value\n- [ ] Include product roadmap priorities\n\n#### Notes\n- AI agents need product context to make good decisions\n\n---\n\n### [TASK-006] Expand docs/ARCHITECTURE.md\n- **Priority:** P1\n- **Status:** Pending\n- **Created:** 2026-01-23\n- **Context:** Current file is 14 lines. Needs comprehensive system documentation.\n\n#### Acceptance Criteria\n- [ ] Add Mermaid diagrams for system architecture\n- [ ] Document module ownership and boundaries\n- [ ] Explain data flow and integration patterns\n- [ ] Include decision rationale for key choices\n\n#### Notes\n- Critical for AI to understand system structure\n\n---\n\n## P2 — Medium\n\n### [TASK-007] Create docs/adr/ Folder with ADR Template\n- **Priority:** P2\n- **Status:** Pending\n- **Created:** 2026-01-23\n- **Context:** Architecture Decision Records document WHY decisions were made.\n\n#### Acceptance Criteria\n- [ ] Create `docs/adr/` directory\n- [ ] Add ADR template (ADR-000-template.md)\n- [ ] Create first ADR for multi-tenancy model\n- [ ] Document ADR process in docs/architecture/decisions/\n\n#### Notes\n- ADRs help AI understand historical context\n\n---\n\n### [TASK-008] Enable OpenAPI Drift Detection in CI\n- **Priority:** P2\n- **Status:** Pending\n- **Created:** 2026-01-23\n- **Context:** OpenAPI check job is disabled (`if: false`) in CI workflow.\n\n#### Acceptance Criteria\n- [ ] Fix blocking issues preventing OpenAPI generation\n- [ ] Enable the `openapi-check` job\n- [ ] Ensure schema drift fails CI\n- [ ] Document OpenAPI workflow in CONTRIBUTING.md\n\n#### Notes\n- Committed OpenAPI artifact is single source of truth for API\n\n---\n\n### [TASK-009] Add Worker Runtime for Job Queue\n- **Priority:** P2\n- **Status:** Pending\n- **Created:** 2026-01-23\n- **Context:** Job queue models exist but no worker process to execute them.\n\n#### Acceptance Criteria\n- [ ] Create management command or worker process\n- [ ] Add worker service to docker-compose.yml\n- [ ] Document worker scaling strategy\n- [ ] Add health checks for worker\n\n#### Notes\n- Per ANALYSIS.md: jobs modeled in DB but can't run\n- backend/modules/jobs/models.py defines JobQueue/DLQ\n\n---\n\n## P3 — Low\n\n### [TASK-010] Add Observability Stack (OpenTelemetry/Prometheus)\n- **Priority:** P3\n- **Status:** Pending\n- **Created:** 2026-01-23\n- **Context:** Logging and Sentry exist but no metrics/tracing.\n\n#### Acceptance Criteria\n- [ ] Add OpenTelemetry instrumentation\n- [ ] Configure Prometheus metrics endpoint\n- [ ] Create basic Grafana dashboards-as-code\n- [ ] Document observability in RUNBOOK.md\n\n#### Notes\n- Per ANALYSIS.md: observability incomplete\n\n---\n\n### [TASK-011] Add SBOM Generation to CI\n- **Priority:** P3\n- **Status:** Pending\n- **Created:** 2026-01-23\n- **Context:** Supply chain security best practice.\n\n#### Acceptance Criteria\n- [ ] Add SBOM generation step to CI\n- [ ] Choose format (SPDX or CycloneDX)\n- [ ] Store SBOM artifact with releases\n- [ ] Document in SECURITY.md\n\n#### Notes\n- Required for enterprise security compliance\n"
        },
        {
          "path": ".repo/tasks/ARCHIVE.md",
          "type": "Markdown",
          "lines": 74,
          "purpose": "Historical record of completed tasks",
          "key_contents": [
            "Workflow instructions (archiving)",
            "Archive format",
            "Statistics (total, by priority)",
            "Completed tasks (prepended, newest first)"
          ],
          "dependencies": [
            "archive-task.py"
          ],
          "used_by": [
            "Agents for historical reference",
            "archive-task.py"
          ],
          "workflow": "Tasks moved here from TODO.md when complete",
          "content": "# ✅ Completed Tasks Archive\n\n> **Historical Record** — All completed tasks with outcomes and completion dates.\n\n---\n\n## Workflow Instructions\n\n### Archiving Completed Tasks:\n1. Copy the completed task from `TODO.md` to the TOP of the archive (below this header)\n2. Update status to `Completed`\n3. Add completion date: `Completed: YYYY-MM-DD`\n4. Optionally add outcome notes or lessons learned\n\n### Archive Format:\n```markdown\n### [TASK-XXX] Task Title ✓\n- **Priority:** P0 | P1 | P2 | P3\n- **Status:** Completed\n- **Created:** YYYY-MM-DD\n- **Completed:** YYYY-MM-DD\n- **Context:** Brief description of why this task mattered\n\n#### Acceptance Criteria\n- [x] Criterion 1\n- [x] Criterion 2\n\n#### Outcome\n- What was delivered\n- Any follow-up tasks created\n- Lessons learned (optional)\n```\n\n---\n\n## Statistics\n| Metric | Count |\n|--------|-------|\n| Total Completed | 0 |\n| P0 Completed | 0 |\n| P1 Completed | 0 |\n| P2 Completed | 0 |\n| P3 Completed | 0 |\n\n*Update statistics when archiving tasks.*\n\n---\n\n## Completed Tasks\n\n*No tasks completed yet. This section will populate as tasks are moved from TODO.md.*\n\n<!--\nExample archived task:\n\n### [TASK-000] Example Completed Task ✓\n- **Priority:** P1\n- **Status:** Completed\n- **Created:** 2026-01-20\n- **Completed:** 2026-01-23\n- **Context:** This was an example task to demonstrate the format.\n\n#### Acceptance Criteria\n- [x] First criterion was met\n- [x] Second criterion was met\n- [x] Third criterion was met\n\n#### Outcome\n- Successfully delivered the feature\n- Created follow-up task TASK-015 for enhancements\n- Learned that X approach works better than Y\n\n-->\n"
        },
        {
          "path": ".repo/tasks/README.md",
          "type": "Markdown",
          "purpose": "Task management workflow documentation",
          "used_by": [
            "Agents managing tasks (first time)"
          ],
          "content": "# 🤖 Agent Task Management System\n\n> **Kanban-style task flow for AI-orchestrated development.**\n\n---\n\n## Overview\n\nThis folder implements a simple, effective task management workflow designed for AI agents and human oversight:\n\n| File | Purpose | Rule |\n|------|---------|------|\n| `TODO.md` | Current active task | **Only ONE task at a time** |\n| `BACKLOG.md` | Prioritized queue | Ordered P0 → P3 |\n| `ARCHIVE.md` | Completed tasks | Historical record |\n\n---\n\n## 🔄 Workflow Cycle\n\n```\n┌─────────────┐     ┌─────────────┐     ┌─────────────┐\n│  BACKLOG    │────▶│    TODO     │────▶│   ARCHIVE   │\n│  (Queue)    │     │  (Active)   │     │  (Done)     │\n└─────────────┘     └─────────────┘     └─────────────┘\n     ▲                    │                    │\n     │                    │                    │\n     └────────────────────┴────────────────────┘\n              (New tasks added to backlog)\n```\n\n### Step-by-Step Process\n\n1. **Start Work**: Pick up the task in `TODO.md`\n2. **Complete Work**: Mark all acceptance criteria as done\n3. **Archive**: Move completed task to top of `ARCHIVE.md`\n4. **Promote**: Move highest priority task from `BACKLOG.md` to `TODO.md`\n5. **Repeat**\n\n---\n\n## 📋 Task Format (Consistent Across All Files)\n\n```markdown\n### [TASK-XXX] Task Title\n- **Priority:** P0 | P1 | P2 | P3\n- **Status:** Pending | In Progress | Completed\n- **Created:** YYYY-MM-DD\n- **Completed:** YYYY-MM-DD (only in ARCHIVE.md)\n- **Context:** Brief description of why this task matters\n\n#### Acceptance Criteria\n- [ ] Specific, measurable criterion 1\n- [ ] Specific, measurable criterion 2\n\n#### Notes\n- Relevant context, links, or references\n```\n\n---\n\n## 🎯 Priority Levels\n\n| Level | Name | Meaning | Expected Turnaround |\n|-------|------|---------|---------------------|\n| **P0** | Critical | Blocking issues, security, broken CI | Immediate |\n| **P1** | High | Important features, significant improvements | This week |\n| **P2** | Medium | Standard features, non-urgent improvements | This month |\n| **P3** | Low | Nice-to-haves, polish, minor enhancements | When possible |\n\n---\n\n## ✅ Acceptance Criteria Best Practices\n\nGood acceptance criteria are:\n- **Specific**: Clear, unambiguous requirements\n- **Measurable**: Can be objectively verified as done/not done\n- **Achievable**: Reasonable scope for a single task\n- **Relevant**: Directly contributes to task goal\n- **Testable**: Can be validated through testing or review\n\n**Examples:**\n\n❌ Bad: \"Make the code better\"\n✅ Good: \"Reduce function complexity to under 10 cyclomatic complexity\"\n\n❌ Bad: \"Add tests\"\n✅ Good: \"Add unit tests achieving 80%+ coverage for `auth/` module\"\n\n❌ Bad: \"Fix the bug\"\n✅ Good: \"Prevent null pointer exception when user.email is undefined\"\n\n---\n\n## 🤖 Agent Instructions\n\n### For AI Coding Agents:\n\n1. **Before starting work**: Read `TODO.md` to understand the current task\n2. **During work**: Reference acceptance criteria as your checklist\n3. **After completing**:\n   - Mark criteria as `[x]` complete\n   - Notify human to review and archive\n   - Or if autonomous: follow archive workflow\n\n### For Creating New Tasks:\n\n1. Add to `BACKLOG.md` in correct priority position\n2. Use sequential task numbers: `[TASK-XXX]`\n3. Include clear context explaining WHY the task matters\n4. Write specific, testable acceptance criteria\n\n---\n\n## 📊 Tracking Progress\n\nUpdate the statistics table in `ARCHIVE.md` when completing tasks:\n\n```markdown\n## Statistics\n| Metric | Count |\n|--------|-------|\n| Total Completed | X |\n| P0 Completed | X |\n| P1 Completed | X |\n| P2 Completed | X |\n| P3 Completed | X |\n```\n\n---\n\n## 🔗 Related Files\n\n- `/AGENTS.md` — Main agent instructions for the repository\n- `docs/development/README.md` — Development workflow documentation\n- `docs/` — Documentation directory\n"
        },
        {
          "path": ".repo/tasks/REMAINING_TASKS.md",
          "type": "Markdown",
          "lines": 300,
          "purpose": "Implementation status tracking",
          "used_by": [
            "Humans tracking implementation progress"
          ],
          "content": "# Remaining Implementation Tasks\n\n**Date:** 2026-01-23\n**Based on:** `.repo/CRITICAL_ANALYSIS_FAILURES.md` and `.repo/IMPLEMENTATION_PROGRESS.md`\n\n---\n\n## High Priority Tasks\n\n### 1. Logging Implementation\n**Status:** COMPLETED\n**Priority:** HIGH\n**Files:** `.repo/automation/scripts/agent-logger.js`, `.agent-logs/`, `.repo/agents/QUICK_REFERENCE.md`\n\n**Tasks:**\n- [x] Create logging SDK/library (Node.js or Python)\n  - [x] Design log entry structure (timestamp, agent, action, file, duration, success, context)\n  - [x] Implement log writer function\n  - [x] Add log rotation/cleanup\n- [x] Add logging hooks to agent workflow\n  - [x] Document how agents call logging functions\n  - [x] Add logging to Pass 0, 1, 2, 3 of workflow\n- [x] Create log collector/aggregator\n  - [x] Aggregate logs by day/metric\n  - [x] Generate metrics (success rate, duration, error types)\n- [x] Add logging to governance-verify\n  - [x] Log verification runs\n  - [x] Track verification failures\n\n**Acceptance Criteria:**\n- [x] Agents can call logging functions\n- [x] Logs are written to `.agent-logs/interactions/`\n- [x] Metrics are generated in `.agent-logs/metrics/`\n- [x] Errors are logged to `.agent-logs/errors/`\n\n**Completed:** 2026-01-23\n\n---\n\n### 2. Validation Schema Implementation\n**Status:** COMPLETED\n**Priority:** HIGH\n**Files:** `.repo/automation/scripts/validate-agent-context.js`, `.repo/templates/AGENT_CONTEXT_SCHEMA.json`, `.repo/automation/scripts/package.json`\n\n**Tasks:**\n- [x] Install/use JSON schema validator (ajv or similar)\n- [x] Update `validate-agent-context.js` to use schema\n  - [x] Load schema from `.repo/templates/AGENT_CONTEXT_SCHEMA.json`\n  - [x] Validate all required fields\n  - [x] Validate field types and formats\n- [x] Add file path validation\n  - [x] Check if referenced files exist\n  - [x] Check if patterns match actual code\n- [x] Add boundary validation\n  - [x] Verify boundaries are correctly defined\n  - [x] Check boundary rules are valid\n- [x] Add link validation\n  - [x] Check if links are valid\n  - [x] Verify referenced documents exist\n\n**Acceptance Criteria:**\n- [x] Validation uses JSON schema\n- [x] All required fields are validated\n- [x] File paths are checked\n- [x] Invalid context files are rejected with clear errors\n\n**Completed:** 2026-01-23\n\n---\n\n## Medium Priority Tasks\n\n### 3. Task Packet Workflow Clarification\n**Status:** COMPLETED\n**Priority:** MEDIUM\n**Files:** `.repo/agents/QUICK_REFERENCE.md`, `.repo/templates/examples/`, `.repo/automation/scripts/check-artifacts-by-change-type.js`\n\n**Tasks:**\n- [x] Add task packet creation to Pass 1 workflow\n  - [x] Document when to create (for feature/api_change/cross_module)\n  - [x] Add step to workflow documentation\n- [x] Document where to store task packets\n  - [x] Clarify: TODO.md vs separate file (.repo/tasks/packets/)\n  - [x] Add examples\n- [x] Add examples for each change type\n  - [x] Feature task packet example (existing)\n  - [x] API change task packet example\n  - [x] Cross-module task packet example\n- [x] Add validation to governance-verify\n  - [x] Check task packet exists for required change types\n\n**Acceptance Criteria:**\n- [x] Workflow clearly states when to create task packets\n- [x] Storage location is documented\n- [x] Examples exist for all change types\n- [x] Validation checks task packets\n\n**Completed:** 2026-01-23\n\n---\n\n### 4. Boundary Enforcement\n**Status:** COMPLETED\n**Priority:** MEDIUM\n**Files:** `.repo/automation/scripts/check-boundaries.js`, `.repo/agents/QUICK_REFERENCE.md`, `.repo/automation/scripts/governance-verify.js`\n\n**Tasks:**\n- [x] Integrate boundary checking into agent workflow\n  - [x] Add boundary check step to Pass 1 (Plan)\n  - [x] Document how to check boundaries\n- [x] Add automated boundary checking\n  - [x] Use import-linter or similar tool\n  - [x] Create boundary checker script\n- [x] Add boundary checks to governance-verify\n  - [x] Check for boundary violations\n  - [x] Fail hard gates on violations\n- [x] Add to CI pipeline\n  - [x] CI already runs boundary checks (existing)\n  - [x] Block PRs with violations (enforced)\n\n**Acceptance Criteria:**\n- [x] Boundary checking is automated\n- [x] Violations are caught before PR\n- [x] CI blocks PRs with violations\n- [x] Clear error messages for violations\n\n**Completed:** 2026-01-23\n\n---\n\n### 5. Testing Guidance\n**Status:** COMPLETED\n**Priority:** MEDIUM\n**Files:** `backend/modules/clients/.AGENT.md`, `frontend/src/components/.AGENT.md`, `.repo/policy/QUALITY_GATES.md`, `.repo/templates/examples/`\n\n**Tasks:**\n- [x] Add test patterns to folder-level `.AGENT.md` files\n  - [x] Backend test patterns (pytest)\n  - [x] Frontend test patterns (vitest)\n- [x] Create test examples for common patterns\n  - [x] Django viewset tests\n  - [x] React component tests\n  - [x] API integration tests\n- [x] Document test coverage requirements\n  - [x] Minimum coverage thresholds\n  - [x] Coverage by change type\n- [x] Add test validation hints to quality gates\n  - [x] Check test files exist\n  - [x] Verify coverage doesn't regress\n\n**Acceptance Criteria:**\n- [x] Test patterns documented in folder guides\n- [x] Examples exist for common patterns\n- [x] Coverage requirements documented\n- [x] Quality gates check tests\n\n**Completed:** 2026-01-23\n\n---\n\n## Low Priority Tasks\n\n### 6. Pattern Verification\n**Status:** COMPLETED\n**Priority:** LOW\n**Files:** `.repo/automation/scripts/pattern-verification.js`\n\n**Tasks:**\n- [x] Extract patterns from actual codebase\n  - [x] Basic verification script created\n  - [x] Checks pattern files exist and are referenced\n- [x] Verify existing pattern files match code\n  - [x] Script checks pattern files are properly configured\n  - [x] Validates references in .AGENT.md and .agent-context.json\n- [x] Create automated pattern verification script\n  - [x] Basic verification implemented\n  - [x] Checks for pattern file completeness\n- [x] Add pattern validation (advisory)\n  - [x] Script can be run manually or in CI\n  - [x] Warns on pattern file issues\n\n**Acceptance Criteria:**\n- [x] Pattern verification script exists\n- [x] Basic verification works\n- [x] Can be integrated into CI\n\n**Note:** Full pattern extraction from code would require sophisticated parsing. Basic verification ensures pattern files exist and are referenced correctly.\n\n**Completed:** 2026-01-23\n\n---\n\n### 7. Context File Maintenance\n**Status:** COMPLETED\n**Priority:** LOW\n**Files:** `.agent-context.json` files, `.repo/automation/scripts/check-stale-context.js`, `.repo/automation/scripts/update-context-verified.js`\n\n**Tasks:**\n- [x] Add `last_verified` date field to context files\n  - [x] Update schema (AGENT_CONTEXT_SCHEMA.json)\n  - [x] Script to add to existing files\n- [x] Create script to check for stale context files\n  - [x] Check last_verified dates\n  - [x] Flag outdated files (> 30 days)\n- [x] Add alerts/warnings when context files are outdated\n  - [x] Added to governance-verify\n  - [x] Warns if > 30 days old\n- [x] Document update workflow\n  - [x] Scripts documented in automation README\n  - [x] Troubleshooting guide created\n\n**Acceptance Criteria:**\n- [x] Context files have last_verified dates (schema updated)\n- [x] Stale files are detected\n- [x] Update workflow is documented\n\n**Completed:** 2026-01-23\n\n---\n\n### 8. Consolidate Entry Points\n**Status:** COMPLETED\n**Priority:** LOW\n**Files:** `AGENTS.json`, `.repo/AGENT.md`, `.repo/agents/QUICK_REFERENCE.md`, `.repo/agents/AGENTS.md`\n\n**Tasks:**\n- [x] Review all entry points for conflicts\n  - [x] Verified: All point to same canonical sources\n  - [x] No conflicts found - all consistent\n- [x] Ensure all reference single canonical source\n  - [x] `AGENTS.json` / `rules.json` is canonical for machine-readable\n  - [x] `QUICK_REFERENCE.md` is canonical for human-readable\n  - [x] `.repo/AGENT.md` is simple entry point referencing both\n- [x] Update cross-references to be consistent\n  - [x] All files reference correct canonical sources\n  - [x] Clear hierarchy established\n\n**Acceptance Criteria:**\n- [x] No conflicting information (verified)\n- [x] Clear canonical sources (documented)\n- [x] Consistent cross-references (all point to same sources)\n\n**Completed:** 2026-01-23\n\n---\n\n### 9. Failure Recovery Mechanisms\n**Status:** COMPLETED\n**Priority:** LOW\n**Files:** `.repo/automation/scripts/`, `.repo/docs/TROUBLESHOOTING.md`\n\n**Tasks:**\n- [x] Add error handling to scripts\n  - [x] Logging SDK has graceful degradation\n  - [x] Validation scripts provide helpful error messages\n- [x] Add fallbacks for logging failures\n  - [x] Graceful degradation if logging fails\n  - [x] Workflow continues if logging unavailable\n- [x] Add graceful degradation for validation failures\n  - [x] Warnings for non-critical issues\n  - [x] Clear error messages with troubleshooting links\n- [x] Document what to do when scripts fail\n  - [x] Comprehensive troubleshooting guide created\n  - [x] Manual recovery steps documented\n\n**Acceptance Criteria:**\n- [x] Scripts handle errors gracefully\n- [x] Workflow continues with warnings\n- [x] Recovery procedures documented\n\n**Completed:** 2026-01-23\n\n---\n\n## Summary\n\n**Total Tasks:** 9\n**High Priority:** 2 ✅ COMPLETED\n**Medium Priority:** 3 ✅ COMPLETED\n**Low Priority:** 4 ✅ COMPLETED\n\n**Status:** ALL TASKS COMPLETED (2026-01-23)\n\n**Completed Work:**\n1. ✅ Logging implementation (SDK, hooks, aggregator, governance integration)\n2. ✅ Validation schema implementation (JSON schema, file paths, boundaries, links)\n3. ✅ Task packet workflow clarification (documentation, examples, validation)\n4. ✅ Boundary enforcement (checker script, workflow integration, CI)\n5. ✅ Testing guidance (patterns, examples, coverage requirements)\n6. ✅ Pattern verification (basic verification script)\n7. ✅ Context file maintenance (last_verified dates, stale detection, update scripts)\n8. ✅ Consolidate entry points (verified consistency, clear hierarchy)\n9. ✅ Failure recovery mechanisms (error handling, troubleshooting guide)\n\n**All acceptance criteria met for all tasks.**\n\n---\n\n**Note:** These tasks are based on the critical analysis. Some may need adjustment based on real-world usage and feedback.\n"
        },
        {
          "path": ".repo/tasks/IMPLEMENTATION_COMPLETE.md",
          "type": "Markdown",
          "purpose": "Completed implementation tasks",
          "used_by": [
            "Historical reference"
          ],
          "content": "# Implementation Complete - All Tasks Finished\n\n**Date:** 2026-01-23\n**Status:** ✅ ALL TASKS COMPLETED\n\n---\n\n## Executive Summary\n\nAll 9 tasks from `.repo/tasks/REMAINING_TASKS.md` have been successfully completed. The agentic system now has:\n\n- ✅ Complete logging infrastructure\n- ✅ Enhanced validation with JSON schema\n- ✅ Clear task packet workflow\n- ✅ Automated boundary enforcement\n- ✅ Comprehensive testing guidance\n- ✅ Pattern verification tools\n- ✅ Context file maintenance\n- ✅ Consolidated entry points\n- ✅ Failure recovery mechanisms\n\n---\n\n## Completed Tasks\n\n### High Priority (2/2) ✅\n\n#### 1. Logging Implementation\n- **Files Created:**\n  - `.repo/automation/scripts/agent-logger.js` - Logging SDK\n  - `.repo/automation/scripts/package.json` - Dependencies\n- **Files Modified:**\n  - `.repo/agents/QUICK_REFERENCE.md` - Added logging workflow\n  - `.repo/automation/scripts/governance-verify.js` - Integrated logging\n  - `.repo/automation/README.md` - Documented logging\n- **Features:**\n  - Log interaction tracking (JSONL format)\n  - Error logging\n  - Daily metrics aggregation\n  - Log rotation/cleanup\n  - Graceful degradation on failures\n\n#### 2. Validation Schema Implementation\n- **Files Modified:**\n  - `.repo/automation/scripts/validate-agent-context.js` - Enhanced validation\n  - `.repo/automation/scripts/package.json` - Added ajv dependency\n- **Features:**\n  - JSON schema validation (ajv)\n  - File path validation (`--check-files`)\n  - Boundary validation (`--check-boundaries`)\n  - Link validation (`--check-links`)\n  - Graceful fallback if ajv not installed\n\n### Medium Priority (3/3) ✅\n\n#### 3. Task Packet Workflow Clarification\n- **Files Created:**\n  - `.repo/templates/examples/example_task_packet_api_change.json`\n  - `.repo/templates/examples/example_task_packet_cross_module.json`\n- **Files Modified:**\n  - `.repo/agents/QUICK_REFERENCE.md` - Added task packet workflow\n  - `.repo/automation/scripts/check-artifacts-by-change-type.js` - Enhanced validation\n  - `.repo/templates/examples/README.md` - Updated with new examples\n- **Features:**\n  - Clear workflow documentation\n  - Examples for all change types\n  - Storage location documented\n  - Validation integrated\n\n#### 4. Boundary Enforcement\n- **Files Created:**\n  - `.repo/automation/scripts/check-boundaries.js` - Boundary checker\n- **Files Modified:**\n  - `.repo/agents/QUICK_REFERENCE.md` - Added boundary checking workflow\n  - `.repo/automation/scripts/governance-verify.js` - Integrated boundary checks\n- **Features:**\n  - Automated boundary checking\n  - Integration with import-linter\n  - Hard gate enforcement\n  - Clear error messages\n\n#### 5. Testing Guidance\n- **Files Created:**\n  - `.repo/templates/examples/example_test_viewset.py`\n  - `.repo/templates/examples/example_test_component.tsx`\n  - `.repo/templates/examples/example_test_api_integration.py`\n- **Files Modified:**\n  - `backend/modules/clients/.AGENT.md` - Added test patterns\n  - `frontend/src/components/.AGENT.md` - Added test patterns\n  - `.repo/policy/QUALITY_GATES.md` - Added test requirements\n  - `.repo/templates/examples/README.md` - Updated with test examples\n- **Features:**\n  - Test patterns in folder guides\n  - Examples for common patterns\n  - Coverage requirements documented\n  - Quality gate integration\n\n### Low Priority (4/4) ✅\n\n#### 6. Pattern Verification\n- **Files Created:**\n  - `.repo/automation/scripts/pattern-verification.js` - Pattern verifier\n- **Features:**\n  - Checks pattern files exist\n  - Validates references in .AGENT.md\n  - Validates patterns in .agent-context.json\n  - Advisory warnings\n\n#### 7. Context File Maintenance\n- **Files Created:**\n  - `.repo/automation/scripts/check-stale-context.js` - Stale detector\n  - `.repo/automation/scripts/update-context-verified.js` - Updater\n- **Files Modified:**\n  - `.repo/templates/AGENT_CONTEXT_SCHEMA.json` - Added last_verified field\n  - `.repo/automation/scripts/governance-verify.js` - Added stale check\n- **Features:**\n  - last_verified date tracking\n  - Stale file detection (> 30 days)\n  - Update scripts\n  - Governance integration\n\n#### 8. Consolidate Entry Points\n- **Status:** Verified consistency\n- **Findings:**\n  - All entry points reference same canonical sources\n  - No conflicts found\n  - Clear hierarchy established\n  - AGENTS.json/rules.json = machine-readable canonical\n  - QUICK_REFERENCE.md = human-readable canonical\n\n#### 9. Failure Recovery Mechanisms\n- **Files Created:**\n  - `.repo/docs/TROUBLESHOOTING.md` - Comprehensive troubleshooting guide\n- **Files Modified:**\n  - `.repo/automation/scripts/agent-logger.js` - Graceful degradation\n  - `.repo/automation/scripts/validate-agent-context.js` - Better error messages\n- **Features:**\n  - Error handling in all scripts\n  - Graceful degradation\n  - Troubleshooting guide\n  - Recovery procedures\n\n---\n\n## Statistics\n\n**Total Files Created:** 12\n**Total Files Modified:** 15\n**Total Scripts Created:** 6\n**Total Examples Created:** 5\n**Total Documentation Pages:** 1\n\n---\n\n## Integration Points\n\nAll implementations are integrated into:\n\n1. **Agent Workflow** - Logging, boundary checking, task packets in Pass 1\n2. **Governance Verification** - Logging, boundary checks, stale context detection\n3. **Quality Gates** - Test requirements, coverage thresholds\n4. **Documentation** - All workflows documented in QUICK_REFERENCE.md\n\n---\n\n## Next Steps for Users\n\n1. **Install Dependencies:**\n   ```bash\n   cd .repo/automation/scripts\n   npm install\n   ```\n\n2. **Update Context Files:**\n   ```bash\n   node .repo/automation/scripts/update-context-verified.js --all\n   ```\n\n3. **Test Scripts:**\n   - Test logging: `node agent-logger.js metrics`\n   - Test validation: `node validate-agent-context.js <file> --check-files`\n   - Test boundaries: `node check-boundaries.js`\n   - Test stale detection: `node check-stale-context.js`\n\n4. **CI Integration (Optional):**\n   - Add pattern verification to CI\n   - Add stale context check to CI (advisory)\n\n---\n\n## Verification\n\nAll acceptance criteria met for all 9 tasks. System is ready for production use.\n\n---\n\n**Implementation Date:** 2026-01-23\n**All Tasks Status:** ✅ COMPLETE\n"
        }
      ]
    },
    "templates_schemas": {
      "description": "Templates and schemas",
      "files": [
        {
          "path": ".repo/templates/PR_TEMPLATE.md",
          "type": "Markdown",
          "lines": 27,
          "purpose": "PR description template with change type declaration",
          "key_contents": [
            "JSON structure for PR metadata",
            "Change type decision tree",
            "Required fields: title, change_type, task_packet, changes, evidence, verification_commands_run, hitl, waivers, notes"
          ],
          "used_by": [
            "Agents creating PRs"
          ],
          "referenced_by": [
            "pr-review.md checklist"
          ],
          "content": "# /.repo/templates/PR_TEMPLATE.md\n\n**Required:** All PRs must declare a change type. See `.repo/agents/QUICK_REFERENCE.md` for change type determination.\n\n```json\n{\n  \"title\": \"\",\n  \"change_type\": \"feature | api_change | security | cross_module | non_doc_change\",\n  \"task_packet\": \"\",\n  \"changes\": [],\n  \"evidence\": [],\n  \"verification_commands_run\": [],\n  \"hitl\": [],\n  \"waivers\": [],\n  \"notes\": \"Strict structure. No secrets.\"\n}\n```\n\n**Change Type Decision Tree:**\n- **security**: Security/auth/money/external systems changes\n- **api_change**: API contract/endpoint changes (requires ADR + OpenAPI update)\n- **cross_module**: Crosses module/feature boundaries (requires ADR)\n- **feature**: New functionality/features\n- **non_doc_change**: Bug fixes, refactoring, config changes (not doc-only)\n\n**See:** `.repo/agents/QUICK_REFERENCE.md` section \"🎯 Change Type Determination\" for full decision tree.\n"
        },
        {
          "path": ".repo/templates/ADR_TEMPLATE.md",
          "type": "Markdown",
          "lines": 14,
          "purpose": "Architecture Decision Record template",
          "key_contents": [
            "JSON structure: context, decision_drivers, options, decision, consequences, modules, commands, migration, boundary_impact, hitl"
          ],
          "used_by": [
            "Agents creating ADRs (cross-module, api_change)"
          ],
          "referenced_by": [
            "BOUNDARIES.md",
            "QUALITY_GATES.md"
          ],
          "content": "# /.repo/templates/ADR_TEMPLATE.md\n{\n  \"context\": \"\",\n  \"decision_drivers\": [],\n  \"options\": [],\n  \"decision\": \"\",\n  \"consequences\": [],\n  \"modules\": [],\n  \"commands\": [],\n  \"migration\": [],\n  \"boundary_impact\": \"\",\n  \"hitl\": []\n}\n"
        },
        {
          "path": ".repo/templates/WAIVER_TEMPLATE.md",
          "type": "Markdown",
          "purpose": "Waiver template for waiverable gate failures",
          "used_by": [
            "Agents creating waivers"
          ],
          "referenced_by": [
            "QUALITY_GATES.md",
            "create-waiver.sh"
          ],
          "content": "# /.repo/templates/WAIVER_TEMPLATE.md\n{\n  \"waives\": \"\",\n  \"why\": \"\",\n  \"scope\": \"\",\n  \"owner\": \"\",\n  \"expiration\": \"\",\n  \"remediation_plan\": \"\",\n  \"link\": \"\",\n  \"notes\": \"Auto-generated waivers allowed for gate failures only.\"\n}\n"
        },
        {
          "path": ".repo/templates/AGENT_CONTEXT_SCHEMA.json",
          "type": "JSON Schema",
          "lines": 188,
          "purpose": "Schema for .agent-context.json files",
          "key_contents": [
            "Schema version, type, folder structure",
            "agent_rules (can_do, cannot_do, requires_hitl)",
            "patterns (code patterns)",
            "boundaries (can_import_from, cannot_import_from, cross_module_requires_adr)",
            "quick_links (guide, index, policy, best_practices)",
            "common_tasks (task definitions with steps and files)",
            "metrics (files_count, last_modified, last_verified, test_coverage)"
          ],
          "used_by": [
            "validate-agent-context.js",
            "all .agent-context.json files"
          ],
          "referenced_by": [
            "All .agent-context.json files ($schema field)"
          ],
          "content": "{\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"title\": \"Agent Context Schema\",\n  \"description\": \"Schema for folder-level agent context files (.agent-context.json)\",\n  \"type\": \"object\",\n  \"required\": [\"version\", \"type\", \"folder\"],\n  \"properties\": {\n    \"$schema\": {\n      \"type\": \"string\",\n      \"description\": \"JSON schema reference\"\n    },\n    \"version\": {\n      \"type\": \"string\",\n      \"pattern\": \"^\\\\d+\\\\.\\\\d+\\\\.\\\\d+$\",\n      \"description\": \"Schema version (semver)\"\n    },\n    \"type\": {\n      \"type\": \"string\",\n      \"enum\": [\"folder_context\"],\n      \"description\": \"Type of context file\"\n    },\n    \"folder\": {\n      \"type\": \"object\",\n      \"required\": [\"path\", \"purpose\"],\n      \"properties\": {\n        \"path\": {\n          \"type\": \"string\",\n          \"description\": \"Relative path to folder from repo root\"\n        },\n        \"purpose\": {\n          \"type\": \"string\",\n          \"description\": \"Brief description of folder purpose\"\n        },\n        \"layer\": {\n          \"type\": \"string\",\n          \"enum\": [\"platform\", \"domain\", \"api\", \"ui\", \"test\", \"docs\", \"config\"],\n          \"description\": \"Architectural layer\"\n        },\n        \"depends_on\": {\n          \"type\": \"array\",\n          \"items\": {\n            \"type\": \"string\"\n          },\n          \"description\": \"Folders this folder depends on\"\n        },\n        \"used_by\": {\n          \"type\": \"array\",\n          \"items\": {\n            \"type\": \"string\"\n          },\n          \"description\": \"Folders that use this folder\"\n        }\n      }\n    },\n    \"agent_rules\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"can_do\": {\n          \"type\": \"array\",\n          \"items\": {\n            \"type\": \"string\"\n          },\n          \"description\": \"List of actions agents can perform in this folder\"\n        },\n        \"cannot_do\": {\n          \"type\": \"array\",\n          \"items\": {\n            \"type\": \"string\"\n          },\n          \"description\": \"List of actions agents cannot perform in this folder\"\n        },\n        \"requires_hitl\": {\n          \"type\": \"array\",\n          \"items\": {\n            \"type\": \"string\"\n          },\n          \"description\": \"Actions that require HITL approval\"\n        }\n      }\n    },\n    \"patterns\": {\n      \"type\": \"object\",\n      \"description\": \"Code patterns for this folder\",\n      \"additionalProperties\": {\n        \"type\": \"string\",\n        \"description\": \"Code example for pattern\"\n      }\n    },\n    \"boundaries\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"can_import_from\": {\n          \"type\": \"array\",\n          \"items\": {\n            \"type\": \"string\"\n          },\n          \"description\": \"Folders this folder can import from\"\n        },\n        \"cannot_import_from\": {\n          \"type\": \"array\",\n          \"items\": {\n            \"type\": \"string\"\n          },\n          \"description\": \"Folders this folder cannot import from\"\n        },\n        \"cross_module_requires_adr\": {\n          \"type\": \"boolean\",\n          \"description\": \"Whether cross-module imports require ADR\"\n        }\n      }\n    },\n    \"quick_links\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"guide\": {\n          \"type\": \"string\",\n          \"description\": \"Path to .AGENT.md file\"\n        },\n        \"index\": {\n          \"type\": \"string\",\n          \"description\": \"Path to INDEX.md file\"\n        },\n        \"policy\": {\n          \"type\": \"string\",\n          \"description\": \"Path to relevant policy file\"\n        },\n        \"best_practices\": {\n          \"type\": \"string\",\n          \"description\": \"Path to best practices file\"\n        }\n      }\n    },\n    \"common_tasks\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"object\",\n        \"required\": [\"task\", \"steps\"],\n        \"properties\": {\n          \"task\": {\n            \"type\": \"string\",\n            \"description\": \"Name of common task\"\n          },\n          \"steps\": {\n            \"type\": \"array\",\n            \"items\": {\n              \"type\": \"string\"\n            },\n            \"description\": \"Step-by-step instructions\"\n          },\n          \"files\": {\n            \"type\": \"array\",\n            \"items\": {\n              \"type\": \"string\"\n            },\n            \"description\": \"Files typically modified for this task\"\n          }\n        }\n      },\n      \"description\": \"Common tasks agents perform in this folder\"\n    },\n    \"metrics\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"files_count\": {\n          \"type\": \"integer\",\n          \"description\": \"Number of files in folder\"\n        },\n        \"last_modified\": {\n          \"type\": \"string\",\n          \"format\": \"date\",\n          \"description\": \"Last modification date\"\n        },\n        \"last_verified\": {\n          \"type\": \"string\",\n          \"format\": \"date\",\n          \"description\": \"Date when context file was last verified against actual code (YYYY-MM-DD)\"\n        },\n        \"test_coverage\": {\n          \"type\": \"number\",\n          \"minimum\": 0,\n          \"maximum\": 1,\n          \"description\": \"Test coverage ratio (0-1)\"\n        }\n      }\n    }\n  }\n}\n"
        },
        {
          "path": ".repo/templates/AGENT_TRACE_SCHEMA.json",
          "type": "JSON Schema",
          "lines": 14,
          "purpose": "Schema for trace logs",
          "key_contents": [
            "Required fields: intent, files, commands, evidence, hitl, unknowns"
          ],
          "used_by": [
            "validate-agent-trace.js",
            "generate-trace-log.sh"
          ],
          "referenced_by": [
            "QUALITY_GATES.md (hard gate: trace log validation)"
          ],
          "content": "{\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"type\": \"object\",\n  \"required\": [\"intent\", \"files\", \"commands\", \"evidence\", \"hitl\", \"unknowns\"],\n  \"properties\": {\n    \"intent\": { \"type\": \"string\" },\n    \"files\": { \"type\": \"array\", \"items\": { \"type\": \"string\" } },\n    \"commands\": { \"type\": \"array\", \"items\": { \"type\": \"string\" } },\n    \"evidence\": { \"type\": \"array\", \"items\": { \"type\": \"string\" } },\n    \"hitl\": { \"type\": \"array\", \"items\": { \"type\": \"string\" } },\n    \"unknowns\": { \"type\": \"array\", \"items\": { \"type\": \"string\" } }\n  }\n}\n"
        },
        {
          "path": ".repo/templates/AGENT_LOG_TEMPLATE.md",
          "type": "Markdown",
          "purpose": "Agent log template",
          "used_by": [
            "Agents creating agent logs (non_doc_change)"
          ],
          "content": "# /.repo/templates/AGENT_LOG_TEMPLATE.md\n{\n  \"intent\": \"\",\n  \"plan\": [],\n  \"actions\": [],\n  \"evidence\": [],\n  \"decisions\": [],\n  \"risks\": [],\n  \"follow_ups\": [],\n  \"reasoning_summary\": \"\",\n  \"notes\": \"No secrets. No private data. No raw chain-of-thought.\"\n}\n"
        },
        {
          "path": ".repo/templates/AGENT_PATTERNS_TEMPLATE.md",
          "type": "Markdown",
          "purpose": "Code patterns template",
          "used_by": [
            "Agents documenting patterns"
          ],
          "content": "# Code Patterns - {Folder Name}\n\n**Folder:** `{folder_path}`\n\nThis document contains common code patterns for this folder. Use these patterns to maintain consistency.\n\n## Model Pattern\n\n```python\n# Example model pattern\n{model_pattern}\n```\n\n## Viewset Pattern\n\n```python\n# Example viewset pattern\n{viewset_pattern}\n```\n\n## Serializer Pattern\n\n```python\n# Example serializer pattern\n{serializer_pattern}\n```\n\n## Test Pattern\n\n```python\n# Example test pattern\n{test_pattern}\n```\n\n## Anti-Patterns (Don't Do This)\n\n```python\n# ❌ Bad: Don't do this\n{bad_pattern}\n\n# ✅ Good: Do this instead\n{good_pattern}\n```\n\n---\n\n**Note:** These patterns are examples. Always check existing code in this folder for the most current patterns.\n"
        },
        {
          "path": ".repo/templates/AGENT_QUICK_REFERENCE_TEMPLATE.md",
          "type": "Markdown",
          "purpose": "Template for creating folder-level .AGENT.md files",
          "used_by": [
            "Agents creating folder guides"
          ],
          "content": "# {Folder Name} - Agent Quick Reference\n\n**Folder:** `{folder_path}`\n**Purpose:** {purpose}\n**Layer:** {layer}\n\n## Quick Rules\n\n✅ **Can Do:**\n{can_do_list}\n\n❌ **Cannot Do:**\n{cannot_do_list}\n\n⚠️ **Requires HITL:**\n{requires_hitl_list}\n\n## Patterns\n\n{pattern_examples}\n\n## Boundaries\n\n**Can Import From:**\n{can_import_list}\n\n**Cannot Import From:**\n{cannot_import_list}\n\n**Used By:**\n{used_by_list}\n\n## Common Tasks\n\n{common_tasks_list}\n\n## Links\n\n- Full guide: `{guide_path}`\n- Policy: `{policy_path}`\n- JSON context: `.agent-context.json`\n- Index: `{index_path}`\n\n---\n\n**Note:** This is a token-optimized quick reference. For full documentation, see the linked files above.\n"
        },
        {
          "path": ".repo/templates/RFC_TEMPLATE.md",
          "type": "Markdown",
          "purpose": "Request for Comments template",
          "used_by": [
            "Agents creating RFCs"
          ],
          "content": "# /.repo/templates/RFC_TEMPLATE.md\n{\n  \"title\": \"\",\n  \"problem\": \"\",\n  \"proposed_solution\": \"\",\n  \"alternatives\": [],\n  \"impact\": [],\n  \"risks\": [],\n  \"notes\": \"\"\n}\n"
        },
        {
          "path": ".repo/templates/RUNBOOK_TEMPLATE.md",
          "type": "Markdown",
          "purpose": "Runbook template",
          "used_by": [
            "Agents creating runbooks"
          ],
          "content": "# /.repo/templates/RUNBOOK_TEMPLATE.md\n{\n  \"title\": \"\",\n  \"summary\": \"\",\n  \"steps\": [],\n  \"rollback\": \"\",\n  \"verification\": [],\n  \"notes\": \"\"\n}\n"
        },
        {
          "path": ".repo/templates/examples/example_task_packet.json",
          "type": "JSON",
          "purpose": "Example task packet for feature changes",
          "used_by": [
            "Agents as reference when creating task packets"
          ],
          "content": "{\n  \"goal\": \"Add JWT-based authentication endpoint to API\",\n  \"non_goals\": [\n    \"Password reset flow (separate task)\",\n    \"OAuth integration (future work)\",\n    \"Multi-factor authentication (future work)\"\n  ],\n  \"acceptance_criteria\": [\n    \"POST /api/auth/login returns JWT access and refresh tokens\",\n    \"POST /api/auth/refresh accepts refresh token and returns new access token\",\n    \"JWT tokens expire after 15 minutes (access) and 7 days (refresh)\",\n    \"All endpoints require authentication via JWT in Authorization header\",\n    \"Test coverage >= 80% for auth module\",\n    \"OpenAPI schema updated with new endpoints\"\n  ],\n  \"approach\": \"Use djangorestframework-simplejwt library. Create auth views, serializers, and URL routing. Add JWT authentication class to DRF settings. Write comprehensive tests.\",\n  \"files_touched\": [\n    \"backend/api/auth/views.py\",\n    \"backend/api/auth/serializers.py\",\n    \"backend/api/auth/urls.py\",\n    \"backend/config/settings.py\",\n    \"tests/api/auth/test_auth.py\",\n    \"backend/openapi.yaml\"\n  ],\n  \"verification_plan\": [\n    \"Run unit tests: pytest tests/api/auth/\",\n    \"Run integration tests: pytest tests/integration/test_auth_flow.py\",\n    \"Check linting: make lint\",\n    \"Verify OpenAPI schema: make -C backend openapi\",\n    \"Manual test: Use Postman/curl to test login and token refresh endpoints\"\n  ],\n  \"risks\": [\n    \"Security: JWT implementation must follow best practices (HITL required)\",\n    \"Breaking change: Existing API clients may need updates\",\n    \"Token storage: Refresh tokens must be stored securely\"\n  ],\n  \"rollback_plan\": \"Revert commits. Remove JWT settings from config. Restore previous authentication method. Update OpenAPI schema.\",\n  \"hitl_requirements\": [\n    \"HITL-0001: Security review for JWT implementation (Category: Risk)\"\n  ],\n  \"notes\": \"This task implements authentication as part of TASK-045. Related to security baseline triggers 1 (auth/login) and 9 (cryptography).\"\n}\n"
        },
        {
          "path": ".repo/templates/examples/example_task_packet_api_change.json",
          "type": "JSON",
          "purpose": "Example task packet for API changes",
          "used_by": [
            "Agents creating API change task packets"
          ],
          "content": "{\n  \"goal\": \"Update Client API to support bulk operations\",\n  \"non_goals\": [\n    \"Adding new client fields (separate task)\",\n    \"Changing authentication (no auth changes)\",\n    \"Frontend changes (backend API only)\"\n  ],\n  \"acceptance_criteria\": [\n    \"POST /api/clients/bulk-create accepts array of client objects\",\n    \"POST /api/clients/bulk-update accepts array of client updates\",\n    \"Bulk operations are transactional (all or nothing)\",\n    \"OpenAPI schema updated with new endpoints\",\n    \"Backward compatibility maintained for single-client endpoints\",\n    \"Test coverage >= 85% for bulk operations\",\n    \"ADR created for API contract change\"\n  ],\n  \"approach\": \"Add bulk endpoints to ClientViewSet. Use Django transactions for atomicity. Create serializers for bulk operations. Update OpenAPI schema. Write comprehensive tests including edge cases.\",\n  \"files_touched\": [\n    \"backend/api/clients/views.py\",\n    \"backend/api/clients/serializers.py\",\n    \"backend/api/clients/urls.py\",\n    \"backend/openapi.yaml\",\n    \"tests/api/clients/test_bulk_operations.py\",\n    \"docs/adr/ADR-0042-bulk-client-operations.md\"\n  ],\n  \"verification_plan\": [\n    \"Run unit tests: pytest tests/api/clients/test_bulk_operations.py\",\n    \"Run integration tests: pytest tests/integration/test_client_bulk_flow.py\",\n    \"Check linting: make lint\",\n    \"Verify OpenAPI schema: make -C backend openapi\",\n    \"Test backward compatibility: Verify single-client endpoints still work\",\n    \"Manual test: Use Postman/curl to test bulk endpoints\"\n  ],\n  \"risks\": [\n    \"Breaking change: API contract change requires ADR (Principle 23)\",\n    \"Performance: Bulk operations may be slow for large datasets\",\n    \"Transaction size: Large bulk operations may hit database limits\"\n  ],\n  \"rollback_plan\": \"Revert commits. Remove bulk endpoints. Restore previous API version. Update OpenAPI schema. Remove ADR if not merged.\",\n  \"hitl_requirements\": [],\n  \"notes\": \"This is an API change (change_type: api_change). Requires ADR per Principle 23 (cross-boundary API contract change). Related to TASK-078.\"\n}\n"
        },
        {
          "path": ".repo/templates/examples/example_task_packet_cross_module.json",
          "type": "JSON",
          "purpose": "Example task packet for cross-module changes",
          "used_by": [
            "Agents creating cross-module task packets"
          ],
          "content": "{\n  \"goal\": \"Add project time tracking integration with finance module\",\n  \"non_goals\": [\n    \"Creating new finance features (only integration)\",\n    \"Changing project module structure (only adding integration)\",\n    \"UI changes (backend integration only)\"\n  ],\n  \"acceptance_criteria\": [\n    \"TimeEntry from projects module can be linked to finance InvoiceLineItem\",\n    \"Time entries are automatically included in invoice generation\",\n    \"Integration respects firm-scoping (multi-tenancy)\",\n    \"No circular dependencies between modules\",\n    \"Test coverage >= 80% for integration code\",\n    \"ADR created for cross-module integration\"\n  ],\n  \"approach\": \"Create integration layer in projects module. Add foreign key relationship to finance InvoiceLineItem. Use signals or service layer for automatic linking. Ensure firm-scoping is maintained. Write integration tests. Create ADR documenting the cross-module dependency.\",\n  \"files_touched\": [\n    \"backend/modules/projects/models.py\",\n    \"backend/modules/projects/services.py\",\n    \"backend/modules/finance/models.py\",\n    \"backend/modules/finance/services.py\",\n    \"tests/integration/test_projects_finance_integration.py\",\n    \"docs/adr/ADR-0043-projects-finance-integration.md\"\n  ],\n  \"verification_plan\": [\n    \"Run unit tests: pytest tests/modules/projects/\",\n    \"Run unit tests: pytest tests/modules/finance/\",\n    \"Run integration tests: pytest tests/integration/test_projects_finance_integration.py\",\n    \"Check boundary violations: lint-imports --config .importlinter\",\n    \"Verify firm-scoping: Test with multiple firms\",\n    \"Check linting: make lint\",\n    \"Manual test: Create time entry, verify it appears in invoice generation\"\n  ],\n  \"risks\": [\n    \"Cross-module dependency: Requires ADR (Principle 23, BOUNDARIES.md)\",\n    \"Circular dependency risk: Must ensure clean module boundaries\",\n    \"Firm-scoping: Integration must respect multi-tenancy\",\n    \"Breaking change: May affect existing invoice generation\"\n  ],\n  \"rollback_plan\": \"Revert commits. Remove integration code. Restore previous module boundaries. Remove ADR if not merged. Verify no circular dependencies remain.\",\n  \"hitl_requirements\": [],\n  \"notes\": \"This is a cross-module change (change_type: cross_module). Requires ADR per Principle 23 and BOUNDARIES.md. Must verify no boundary violations. Related to TASK-089.\"\n}\n"
        },
        {
          "path": ".repo/templates/examples/example_trace_log.json",
          "type": "JSON",
          "purpose": "Example trace log",
          "used_by": [
            "Agents creating trace logs"
          ],
          "content": "{\n  \"intent\": \"Add user authentication endpoint with JWT tokens\",\n  \"files\": [\n    \"backend/api/auth/views.py\",\n    \"backend/api/auth/serializers.py\",\n    \"backend/api/auth/urls.py\",\n    \"tests/api/auth/test_auth.py\"\n  ],\n  \"commands\": [\n    \"make lint\",\n    \"make test\",\n    \"make -C backend openapi\"\n  ],\n  \"evidence\": [\n    \"All tests pass: tests/api/auth/test_auth.py (12 tests, 0 failures)\",\n    \"Linting passes: ruff check backend/api/auth/\",\n    \"OpenAPI schema updated: backend/openapi.yaml\",\n    \"Type checking passes: mypy backend/api/auth/\"\n  ],\n  \"hitl\": [\n    \"HITL-0001: Security review for JWT implementation (Category: Risk, Status: Completed)\"\n  ],\n  \"unknowns\": []\n}\n"
        },
        {
          "path": ".repo/templates/examples/example_hitl_item.md",
          "type": "Markdown",
          "purpose": "Example HITL item",
          "used_by": [
            "Agents creating HITL items"
          ],
          "content": "# HITL-0001: Security Review for JWT Authentication Implementation\n\n**Category:** Risk\n**Required For:** Security, API Contract Change\n**Owner:** [Human Name]\n**Reviewer:** [Human Name]\n**Status:** Completed\n**Date Required:** 2026-01-23\n**Date Completed:** 2026-01-24\n\n## Summary\n\nSecurity review required for new JWT-based authentication endpoint. This change affects login security (trigger ID: 1) and involves cryptography/security controls (trigger ID: 9).\n\n## Required Human Action Steps\n\n1. Review JWT implementation in `backend/api/auth/views.py` for security best practices\n2. Verify token expiration and refresh logic\n3. Confirm no secrets are exposed in code or logs\n4. Review test coverage for security scenarios\n5. Approve or request changes\n\n## Evidence of Completion\n\n- Security review completed: 2026-01-24\n- Reviewer notes: \"JWT implementation follows OWASP guidelines. Token expiration set to 15 minutes. Refresh tokens stored securely. Tests cover token validation and expiration scenarios.\"\n- Related files:\n  - `backend/api/auth/views.py` (JWT implementation)\n  - `tests/api/auth/test_auth.py` (security test coverage)\n  - `backend/config/settings.py` (JWT configuration)\n\n## Related Artifacts\n\n- **PR:** #123 (Add JWT authentication endpoint)\n- **Task Packet:** `agents/tasks/ARCHIVE.md` (TASK-045)\n- **ADR:** N/A (no cross-module dependencies)\n- **Waiver:** N/A\n\n## Notes\n\nThis HITL item was automatically created due to security review trigger (IDs: 1, 9). Implementation follows Django REST Framework JWT best practices.\n"
        },
        {
          "path": ".repo/templates/examples/example_waiver.md",
          "type": "Markdown",
          "purpose": "Example waiver",
          "used_by": [
            "Agents creating waivers"
          ],
          "content": "# Waiver: WVR-0001\n\n**Waives:** Coverage target for `backend/api/auth/` module\n**Why:** New module with initial implementation. Coverage is 65% (target is 80%). Tests are comprehensive for critical paths (authentication, token validation, error handling). Non-critical helper functions will be covered in follow-up task.\n**Scope:** `backend/api/auth/` module only\n**Owner:** [Human Name]\n**Expiration:** 2026-02-23 (30 days)\n**Remediation Plan:**\n- Task created: TASK-046 (Increase auth module test coverage to 80%)\n- Target completion: 2026-02-15\n- Will add tests for edge cases and helper functions\n\n**Link:** PR #123\n\n## Notes\n\nAuto-generated waiver for coverage gate failure. Coverage will be improved incrementally per gradual ratchet strategy (see `.repo/policy/QUALITY_GATES.md`).\n"
        },
        {
          "path": ".repo/templates/examples/example_test_viewset.py",
          "type": "Python",
          "purpose": "Example Django ViewSet test",
          "used_by": [
            "Agents creating backend tests"
          ],
          "content": "\"\"\"\nExample: Django ViewSet Test Pattern\nFile: tests/api/clients/test_client_viewset.py\n\"\"\"\nimport pytest\nfrom rest_framework.test import APIClient\nfrom rest_framework import status\nfrom modules.firm.models import Firm\nfrom modules.clients.models import Client\nfrom django.contrib.auth import get_user_model\n\nUser = get_user_model()\n\n\n@pytest.fixture\ndef firm():\n    \"\"\"Create a test firm.\"\"\"\n    return Firm.objects.create(name='Test Firm', slug='test-firm')\n\n\n@pytest.fixture\ndef user(firm):\n    \"\"\"Create a test user associated with firm.\"\"\"\n    user = User.objects.create_user(\n        username='testuser',\n        email='test@example.com',\n        password='testpass123'\n    )\n    user.firm = firm\n    user.save()\n    return user\n\n\n@pytest.fixture\ndef api_client(user, firm):\n    \"\"\"Create authenticated API client with firm context.\"\"\"\n    client = APIClient()\n    client.force_authenticate(user=user)\n    # Set firm on request (FirmScopedMixin uses request.firm)\n    client.force_authenticate(firm=firm)\n    return client\n\n\n@pytest.fixture\ndef client(firm):\n    \"\"\"Create a test client.\"\"\"\n    return Client.objects.create(firm=firm, name='Test Client')\n\n\n@pytest.mark.django_db\nclass TestClientViewSet:\n    \"\"\"Test suite for ClientViewSet.\"\"\"\n\n    def test_list_clients(self, api_client, firm, client):\n        \"\"\"Test listing clients (firm-scoped).\"\"\"\n        response = api_client.get('/api/clients/')\n        assert response.status_code == status.HTTP_200_OK\n        assert len(response.data['results']) == 1\n        assert response.data['results'][0]['name'] == 'Test Client'\n\n    def test_create_client(self, api_client, firm):\n        \"\"\"Test creating a new client.\"\"\"\n        data = {'name': 'New Client', 'firm': firm.id}\n        response = api_client.post('/api/clients/', data, format='json')\n        assert response.status_code == status.HTTP_201_CREATED\n        assert response.data['name'] == 'New Client'\n        assert Client.objects.filter(firm=firm, name='New Client').exists()\n\n    def test_retrieve_client(self, api_client, client):\n        \"\"\"Test retrieving a single client.\"\"\"\n        response = api_client.get(f'/api/clients/{client.id}/')\n        assert response.status_code == status.HTTP_200_OK\n        assert response.data['name'] == 'Test Client'\n\n    def test_update_client(self, api_client, client):\n        \"\"\"Test updating a client.\"\"\"\n        data = {'name': 'Updated Client'}\n        response = api_client.patch(f'/api/clients/{client.id}/', data, format='json')\n        assert response.status_code == status.HTTP_200_OK\n        assert response.data['name'] == 'Updated Client'\n        client.refresh_from_db()\n        assert client.name == 'Updated Client'\n\n    def test_delete_client(self, api_client, client):\n        \"\"\"Test deleting a client.\"\"\"\n        response = api_client.delete(f'/api/clients/{client.id}/')\n        assert response.status_code == status.HTTP_204_NO_CONTENT\n        assert not Client.objects.filter(id=client.id).exists()\n\n    def test_firm_scoping(self, api_client, firm):\n        \"\"\"Test that clients are scoped to firm.\"\"\"\n        # Create client in different firm\n        other_firm = Firm.objects.create(name='Other Firm', slug='other-firm')\n        Client.objects.create(firm=other_firm, name='Other Client')\n\n        # Create client in current firm\n        Client.objects.create(firm=firm, name='My Client')\n\n        # List should only return clients from current firm\n        response = api_client.get('/api/clients/')\n        assert response.status_code == status.HTTP_200_OK\n        assert len(response.data['results']) == 1\n        assert response.data['results'][0]['name'] == 'My Client'\n\n    def test_unauthenticated_access(self, client):\n        \"\"\"Test that unauthenticated requests are rejected.\"\"\"\n        client = APIClient()\n        response = client.get('/api/clients/')\n        assert response.status_code == status.HTTP_401_UNAUTHORIZED\n"
        },
        {
          "path": ".repo/templates/examples/example_test_component.tsx",
          "type": "TypeScript/React",
          "purpose": "Example React component test",
          "used_by": [
            "Agents creating frontend tests"
          ],
          "content": "/**\n * Example: React Component Test Pattern\n * File: frontend/tests/components/ClientList.test.tsx\n */\nimport { describe, it, expect, vi } from 'vitest';\nimport { render, screen, waitFor } from '@testing-library/react';\nimport userEvent from '@testing-library/user-event';\nimport { QueryClient, QueryClientProvider } from '@tanstack/react-query';\nimport { ClientList } from '../../src/components/ClientList';\nimport * as apiClient from '../../src/api/clients';\n\n// Mock API client\nvi.mock('../../src/api/clients', () => ({\n  fetchClients: vi.fn(),\n}));\n\nconst queryClient = new QueryClient({\n  defaultOptions: {\n    queries: { retry: false },\n    mutations: { retry: false },\n  },\n});\n\nconst wrapper = ({ children }: { children: React.ReactNode }) => (\n  <QueryClientProvider client={queryClient}>{children}</QueryClientProvider>\n);\n\ndescribe('ClientList', () => {\n  beforeEach(() => {\n    vi.clearAllMocks();\n  });\n\n  it('renders loading state', () => {\n    vi.mocked(apiClient.fetchClients).mockImplementation(\n      () => new Promise(() => {}) // Never resolves\n    );\n\n    render(<ClientList />, { wrapper });\n    expect(screen.getByText(/loading/i)).toBeInTheDocument();\n  });\n\n  it('renders client list', async () => {\n    const mockClients = [\n      { id: 1, name: 'Client 1' },\n      { id: 2, name: 'Client 2' },\n    ];\n\n    vi.mocked(apiClient.fetchClients).mockResolvedValue(mockClients);\n\n    render(<ClientList />, { wrapper });\n\n    await waitFor(() => {\n      expect(screen.getByText('Client 1')).toBeInTheDocument();\n      expect(screen.getByText('Client 2')).toBeInTheDocument();\n    });\n  });\n\n  it('handles error state', async () => {\n    vi.mocked(apiClient.fetchClients).mockRejectedValue(\n      new Error('Failed to fetch')\n    );\n\n    render(<ClientList />, { wrapper });\n\n    await waitFor(() => {\n      expect(screen.getByText(/error/i)).toBeInTheDocument();\n    });\n  });\n\n  it('handles user interaction', async () => {\n    const user = userEvent.setup();\n    const mockClients = [{ id: 1, name: 'Client 1' }];\n    vi.mocked(apiClient.fetchClients).mockResolvedValue(mockClients);\n\n    render(<ClientList />, { wrapper });\n\n    await waitFor(() => {\n      expect(screen.getByText('Client 1')).toBeInTheDocument();\n    });\n\n    const button = screen.getByRole('button', { name: /delete/i });\n    await user.click(button);\n\n    await waitFor(() => {\n      expect(screen.queryByText('Client 1')).not.toBeInTheDocument();\n    });\n  });\n\n  it('handles empty state', async () => {\n    vi.mocked(apiClient.fetchClients).mockResolvedValue([]);\n\n    render(<ClientList />, { wrapper });\n\n    await waitFor(() => {\n      expect(screen.getByText(/no clients/i)).toBeInTheDocument();\n    });\n  });\n});\n"
        },
        {
          "path": ".repo/templates/examples/example_test_api_integration.py",
          "type": "Python",
          "purpose": "Example API integration test",
          "used_by": [
            "Agents creating integration tests"
          ],
          "content": "\"\"\"\nExample: API Integration Test Pattern\nFile: tests/integration/test_client_api_flow.py\n\"\"\"\nimport pytest\nfrom rest_framework.test import APIClient\nfrom rest_framework import status\nfrom modules.firm.models import Firm\nfrom modules.clients.models import Client\nfrom django.contrib.auth import get_user_model\n\nUser = get_user_model()\n\n\n@pytest.fixture\ndef firm():\n    \"\"\"Create a test firm.\"\"\"\n    return Firm.objects.create(name='Test Firm', slug='test-firm')\n\n\n@pytest.fixture\ndef user(firm):\n    \"\"\"Create a test user.\"\"\"\n    user = User.objects.create_user(\n        username='testuser',\n        email='test@example.com',\n        password='testpass123'\n    )\n    user.firm = firm\n    user.save()\n    return user\n\n\n@pytest.fixture\ndef api_client(user, firm):\n    \"\"\"Create authenticated API client.\"\"\"\n    client = APIClient()\n    client.force_authenticate(user=user)\n    client.force_authenticate(firm=firm)\n    return client\n\n\n@pytest.mark.django_db\nclass TestClientAPIFlow:\n    \"\"\"Integration tests for complete client API workflows.\"\"\"\n\n    def test_create_list_update_delete_flow(self, api_client, firm):\n        \"\"\"Test complete CRUD workflow.\"\"\"\n        # Create\n        create_data = {'name': 'New Client', 'firm': firm.id}\n        create_response = api_client.post('/api/clients/', create_data, format='json')\n        assert create_response.status_code == status.HTTP_201_CREATED\n        client_id = create_response.data['id']\n\n        # List\n        list_response = api_client.get('/api/clients/')\n        assert list_response.status_code == status.HTTP_200_OK\n        assert any(c['id'] == client_id for c in list_response.data['results'])\n\n        # Retrieve\n        get_response = api_client.get(f'/api/clients/{client_id}/')\n        assert get_response.status_code == status.HTTP_200_OK\n        assert get_response.data['name'] == 'New Client'\n\n        # Update\n        update_data = {'name': 'Updated Client'}\n        update_response = api_client.patch(\n            f'/api/clients/{client_id}/', update_data, format='json'\n        )\n        assert update_response.status_code == status.HTTP_200_OK\n        assert update_response.data['name'] == 'Updated Client'\n\n        # Delete\n        delete_response = api_client.delete(f'/api/clients/{client_id}/')\n        assert delete_response.status_code == status.HTTP_204_NO_CONTENT\n\n        # Verify deleted\n        get_response = api_client.get(f'/api/clients/{client_id}/')\n        assert get_response.status_code == status.HTTP_404_NOT_FOUND\n\n    def test_pagination(self, api_client, firm):\n        \"\"\"Test API pagination.\"\"\"\n        # Create multiple clients\n        for i in range(15):\n            Client.objects.create(firm=firm, name=f'Client {i}')\n\n        # First page\n        response = api_client.get('/api/clients/?page=1')\n        assert response.status_code == status.HTTP_200_OK\n        assert 'results' in response.data\n        assert 'count' in response.data\n        assert response.data['count'] == 15\n\n    def test_filtering(self, api_client, firm):\n        \"\"\"Test API filtering.\"\"\"\n        Client.objects.create(firm=firm, name='Active Client', status='active')\n        Client.objects.create(firm=firm, name='Inactive Client', status='inactive')\n\n        response = api_client.get('/api/clients/?status=active')\n        assert response.status_code == status.HTTP_200_OK\n        assert len(response.data['results']) == 1\n        assert response.data['results'][0]['name'] == 'Active Client'\n"
        },
        {
          "path": ".repo/templates/examples/README.md",
          "type": "Markdown",
          "purpose": "Documentation for example files",
          "used_by": [
            "Agents understanding examples"
          ],
          "content": "# Example Files\n\n**Directory**: `.repo/templates/examples/`\n\nThis directory contains example files demonstrating the expected format for governance artifacts.\n\n## Files\n\n### `example_trace_log.json`\n\nExample trace log following `.repo/templates/AGENT_TRACE_SCHEMA.json`.\n\n**Usage:** Reference when creating trace logs for changes.\n\n**Key fields:**\n- `intent`: What the change does\n- `files`: List of modified files (with paths)\n- `commands`: Commands run for verification\n- `evidence`: Proof of verification (test results, outputs)\n- `hitl`: Related HITL items\n- `unknowns`: UNKNOWN items (should be empty or resolved)\n\n### `example_hitl_item.md`\n\nExample HITL item file format.\n\n**Usage:** Reference when creating HITL items in `.repo/hitl/`.\n\n**Key sections:**\n- Category (Risk, External Integration, Clarification, etc.)\n- Status (Pending, In Progress, Completed, etc.)\n- Required Human Action Steps\n- Evidence of Completion\n- Related Artifacts (PR, ADR, Waiver, Task Packet)\n\n### `example_waiver.md`\n\nExample waiver format.\n\n**Usage:** Reference when creating waivers for policy exceptions.\n\n**Key fields:**\n- `Waives`: What policy/gate is being waived\n- `Why`: Justification\n- `Expiration`: When waiver expires\n- `Remediation Plan`: How to fix the issue\n\n### `example_task_packet.json`\n\nExample task packet format for **feature** changes.\n\n**Usage:** Reference when creating task packets for feature changes.\n\n**Key sections:**\n- `goal`: What the task accomplishes\n- `non_goals`: What's explicitly out of scope\n- `acceptance_criteria`: Measurable success criteria\n- `approach`: How the task will be completed\n- `files_touched`: List of files to be modified\n- `verification_plan`: How to verify completion\n- `risks`: Potential issues\n- `rollback_plan`: How to undo if needed\n- `hitl_requirements`: Required HITL items\n\n### `example_task_packet_api_change.json`\n\nExample task packet format for **API change** changes.\n\n**Usage:** Reference when creating task packets for API contract changes.\n\n**Key differences from feature:**\n- Must include OpenAPI schema updates\n- Requires ADR for API contract changes\n- Must maintain backward compatibility\n- Includes API-specific verification steps\n\n### `example_task_packet_cross_module.json`\n\nExample task packet format for **cross-module** changes.\n\n**Usage:** Reference when creating task packets for cross-module integrations.\n\n**Key differences from feature:**\n- Requires ADR (Principle 23, BOUNDARIES.md)\n- Must verify no boundary violations\n- Must respect firm-scoping (multi-tenancy)\n- Includes boundary checking in verification plan\n\n### `example_test_viewset.py`\n\nExample test pattern for Django ViewSet tests.\n\n**Usage:** Reference when writing tests for Django REST Framework viewsets.\n\n**Key patterns:**\n- Uses pytest fixtures for firm, user, api_client\n- Tests CRUD operations (list, create, retrieve, update, delete)\n- Tests firm-scoping (multi-tenancy)\n- Tests authentication/authorization\n\n### `example_test_component.tsx`\n\nExample test pattern for React component tests.\n\n**Usage:** Reference when writing tests for React components.\n\n**Key patterns:**\n- Uses Vitest and Testing Library\n- Mocks React Query hooks\n- Tests loading, success, error states\n- Tests user interactions\n\n### `example_test_api_integration.py`\n\nExample test pattern for API integration tests.\n\n**Usage:** Reference when writing integration tests for API workflows.\n\n**Key patterns:**\n- Tests complete workflows (create → list → update → delete)\n- Tests pagination and filtering\n- Tests firm-scoping across API calls\n\n## Related Documentation\n\n- `.repo/templates/AGENT_TRACE_SCHEMA.json` - Trace log schema\n- `.repo/policy/HITL.md` - HITL process\n- `.repo/agents/prompts/task_packet.md` - Task packet template\n- `.repo/templates/WAIVER_TEMPLATE.md` - Waiver template\n"
        }
      ]
    },
    "automation_scripts": {
      "description": "Node.js automation scripts",
      "files": [
        {
          "path": ".repo/automation/scripts/governance-verify.js",
          "type": "Node.js",
          "lines": 521,
          "purpose": "Governance verification script (Node.js version)",
          "key_functionality": [
            "Checks required policy files exist",
            "Validates manifest (no UNKNOWN placeholders)",
            "Checks HITL items status",
            "Validates repository structure",
            "Checks trace logs (if change type requires)",
            "Validates artifacts by change type",
            "Checks boundaries",
            "Validates context files",
            "Generates summary report"
          ],
          "dependencies": [
            "agent-logger.js (graceful fallback)"
          ],
          "used_by": [
            "CI workflows",
            "Makefile (check-governance target)"
          ],
          "exit_codes": {
            "0": "pass",
            "1": "hard failure",
            "2": "waiverable failure"
          },
          "content": "#!/usr/bin/env node\n// /.repo/automation/scripts/governance-verify.js\n// Governance verification script - checks compliance with governance framework\n// This is a Node.js version that can be used alongside or instead of the bash script\n\nconst fs = require('fs');\nconst path = require('path');\nconst { execSync } = require('child_process');\n\n// Load agent logger (graceful fallback if not available)\nlet logger;\ntry {\n  logger = require('./agent-logger.js');\n} catch (err) {\n  // Logger not available, continue without logging\n  logger = null;\n}\n\n// Colors\nconst RED = '\\x1b[31m';\nconst YELLOW = '\\x1b[33m';\nconst GREEN = '\\x1b[32m';\nconst RESET = '\\x1b[0m';\n\nlet errors = 0;\nlet warnings = 0;\nconst hardFailures = [];\n\nfunction logError(msg) {\n  console.error(`${RED}❌ ERROR: ${msg}${RESET}`);\n  errors++;\n  hardFailures.push(msg);\n}\n\nfunction logWarning(msg) {\n  console.warn(`${YELLOW}⚠️  WARNING: ${msg}${RESET}`);\n  warnings++;\n}\n\nfunction logInfo(msg) {\n  console.log(`${GREEN}ℹ️  INFO: ${msg}${RESET}`);\n}\n\nfunction logSuccess(msg) {\n  console.log(`${GREEN}✅ ${msg}${RESET}`);\n}\n\nfunction fileExists(filepath) {\n  try {\n    return fs.existsSync(filepath) && fs.statSync(filepath).isFile();\n  } catch {\n    return false;\n  }\n}\n\nfunction dirExists(dirpath) {\n  try {\n    return fs.existsSync(dirpath) && fs.statSync(dirpath).isDirectory();\n  } catch {\n    return false;\n  }\n}\n\nfunction runCommand(cmd, silent = false) {\n  try {\n    const result = execSync(cmd, {\n      encoding: 'utf8',\n      stdio: silent ? 'pipe' : 'inherit',\n      cwd: process.cwd()\n    });\n    return { success: true, output: result };\n  } catch (e) {\n    return { success: false, error: e.message };\n  }\n}\n\n// Check 1: Required policy files\nfunction checkPolicyFiles() {\n  logInfo('Checking required policy files...');\n  const requiredFiles = [\n    '.repo/policy/CONSTITUTION.md',\n    '.repo/policy/PRINCIPLES.md',\n    '.repo/policy/QUALITY_GATES.md',\n    '.repo/policy/SECURITY_BASELINE.md',\n    '.repo/policy/HITL.md',\n    '.repo/policy/BOUNDARIES.md'\n  ];\n\n  for (const file of requiredFiles) {\n    if (fileExists(file)) {\n      logSuccess(`Policy file exists: ${file}`);\n    } else {\n      logError(`Required policy file missing: ${file}`);\n    }\n  }\n}\n\n// Check 2: Manifest exists and no UNKNOWN\nfunction checkManifest() {\n  logInfo('Checking repository manifest...');\n  const manifestPath = '.repo/repo.manifest.yaml';\n\n  if (!fileExists(manifestPath)) {\n    logError(`Repository manifest missing: ${manifestPath}`);\n    return;\n  }\n\n  logSuccess(`Manifest exists: ${manifestPath}`);\n\n  const manifestContent = fs.readFileSync(manifestPath, 'utf8');\n  if (manifestContent.includes('<UNKNOWN>')) {\n    logError('Manifest contains <UNKNOWN> placeholders (must be resolved via HITL)');\n  }\n}\n\n// Check 3: HITL items status\nfunction checkHITLStatus() {\n  logInfo('Checking HITL items status...');\n  const hitlPath = '.repo/policy/HITL.md';\n\n  if (!fileExists(hitlPath)) {\n    logWarning(`HITL index file not found: ${hitlPath}`);\n    return;\n  }\n\n  const hitlContent = fs.readFileSync(hitlPath, 'utf8');\n\n  // Check for active non-completed HITL items\n  const activePattern = /\\|(HITL-\\d+)\\|.*\\|(Pending|In Progress|Blocked)\\|/g;\n  const blockingItems = [];\n  let match;\n\n  while ((match = activePattern.exec(hitlContent)) !== null) {\n    blockingItems.push(match[1]);\n  }\n\n  if (blockingItems.length > 0) {\n    logWarning(`Active HITL items found (not Completed): ${blockingItems.join(', ')}`);\n    logWarning('  → Check .repo/policy/HITL.md for details');\n    logWarning('  → PR merge may be blocked until HITL items are Completed');\n  } else {\n    logSuccess('No blocking HITL items found');\n  }\n\n  // Check HITL item files\n  const hitlDir = '.repo/hitl';\n  if (dirExists(hitlDir)) {\n    const hitlFiles = fs.readdirSync(hitlDir)\n      .filter(f => f.startsWith('HITL-') && f.endsWith('.md'));\n    if (hitlFiles.length > 0) {\n      logInfo(`Found ${hitlFiles.length} HITL item file(s) in .repo/hitl/`);\n    }\n  }\n}\n\n// Check 4: Repository structure\nfunction checkRepositoryStructure() {\n  logInfo('Checking repository structure...');\n  const requiredDirs = [\n    '.repo',\n    '.repo/policy',\n    '.repo/hitl'\n  ];\n\n  for (const dir of requiredDirs) {\n    if (dirExists(dir)) {\n      logSuccess(`Directory exists: ${dir}`);\n    } else {\n      logError(`Required directory missing: ${dir}`);\n    }\n  }\n}\n\n// Check 5: Trace log schema\nfunction checkTraceLogSchema() {\n  logInfo('Checking trace log schema...');\n  const schemaPath = '.repo/templates/AGENT_TRACE_SCHEMA.json';\n\n  if (!fileExists(schemaPath)) {\n    logWarning(`Trace log schema not found: ${schemaPath} (optional, but recommended)`);\n    return;\n  }\n\n  logSuccess(`Trace log schema exists: ${schemaPath}`);\n\n  try {\n    JSON.parse(fs.readFileSync(schemaPath, 'utf8'));\n    logSuccess('Trace log schema is valid JSON');\n  } catch (e) {\n    logError(`Trace log schema is not valid JSON: ${schemaPath}`);\n  }\n}\n\n// Check 6: Trace logs validation\nfunction checkTraceLogs() {\n  logInfo('Checking for trace logs in recent changes...');\n  const traceDir = '.repo/traces';\n\n  if (!dirExists(traceDir)) {\n    logWarning(`Trace log directory missing: ${traceDir} (create with: mkdir -p ${traceDir})`);\n    return;\n  }\n\n  logSuccess(`Trace log directory exists: ${traceDir}`);\n\n  // Check for trace log files\n  const traceFiles = fs.readdirSync(traceDir)\n    .filter(f => f.endsWith('.json'))\n    .map(f => path.join(traceDir, f));\n\n  if (traceFiles.length > 0) {\n    logInfo(`Found ${traceFiles.length} trace log file(s)`);\n\n    // Validate each trace log\n    const validator = path.resolve(__dirname, 'validate-agent-trace.js');\n    if (fileExists(validator)) {\n      for (const traceFile of traceFiles) {\n        const result = runCommand(`node \"${validator}\" \"${traceFile}\"`, true);\n        if (!result.success) {\n          logWarning(`Trace log validation failed: ${traceFile}`);\n        }\n      }\n    } else {\n      logWarning('Trace log validator not found, skipping validation');\n    }\n  }\n}\n\n// Check 7: ADR triggers\nfunction checkADRTriggers() {\n  logInfo('Checking for ADR triggers...');\n  const adrDetector = 'scripts/detect-adr-triggers.sh';\n\n  if (fileExists(adrDetector)) {\n    const result = runCommand(`bash \"${adrDetector}\"`, true);\n    if (!result.success) {\n      logWarning('ADR may be required (run: scripts/detect-adr-triggers.sh for details)');\n    } else {\n      logSuccess('No ADR triggers detected');\n    }\n  }\n}\n\n// Check 7b: Boundary violations\nfunction checkBoundaries() {\n  logInfo('Checking module boundaries...');\n  const boundaryChecker = path.resolve(__dirname, 'check-boundaries.js');\n  const lintImportsCmd = 'lint-imports --config .importlinter';\n\n  // Try Node.js script first, fall back to direct command\n  if (fileExists(boundaryChecker)) {\n    const result = runCommand(`node \"${boundaryChecker}\" --fail-on-violations`, true);\n    if (!result.success) {\n      logError('Boundary violations detected (hard gate failure)');\n      logError('Fix violations or create waiver per .repo/policy/BOUNDARIES.md');\n      logError('Run: lint-imports --config .importlinter for details');\n      hardFailures.push('Module boundary violations');\n    } else {\n      logSuccess('No boundary violations detected');\n    }\n  } else if (runCommand('which lint-imports 2>/dev/null || where lint-imports 2>/dev/null', true).success) {\n    // Try direct command if script not available\n    const result = runCommand(lintImportsCmd, true);\n    if (!result.success) {\n      logError('Boundary violations detected (hard gate failure)');\n      logError('Fix violations or create waiver per .repo/policy/BOUNDARIES.md');\n      hardFailures.push('Module boundary violations');\n    } else {\n      logSuccess('No boundary violations detected');\n    }\n  } else {\n    logWarning('Boundary checker not available (lint-imports not installed)');\n    logWarning('Install with: pip install import-linter==2.0');\n  }\n}\n\n// Check 8: Expired waivers\nfunction checkExpiredWaivers() {\n  logInfo('Checking for expired waivers...');\n  const waiverChecker = 'scripts/check-expired-waivers.sh';\n\n  if (fileExists(waiverChecker)) {\n    const result = runCommand(`bash \"${waiverChecker}\"`, true);\n    if (!result.success) {\n      logWarning('Expired waivers detected (run: scripts/check-expired-waivers.sh for details)');\n    } else {\n      logSuccess('No expired waivers found');\n    }\n  }\n}\n\n// Check 9: Task format validation\nfunction checkTaskFormat() {\n  logInfo('Checking task format...');\n  const taskValidator = 'scripts/validate-task-format.sh';\n\n  if (fileExists(taskValidator)) {\n    const taskFiles = ['.repo/tasks/TODO.md', '.repo/tasks/BACKLOG.md'];\n    for (const taskFile of taskFiles) {\n      if (fileExists(taskFile)) {\n        const result = runCommand(`bash \"${taskValidator}\" \"${taskFile}\"`, true);\n        if (!result.success) {\n          logWarning(`Task format issues in: ${taskFile}`);\n        } else {\n          logSuccess(`Task format valid: ${taskFile}`);\n        }\n      }\n    }\n  }\n}\n\n// Check 11: Required artifacts by change type\nfunction checkArtifactsByChangeType() {\n  logInfo('Checking required artifacts by change type...');\n  const artifactChecker = path.resolve(__dirname, 'check-artifacts-by-change-type.js');\n\n  if (!fileExists(artifactChecker)) {\n    logWarning('Artifact checker script not found, skipping artifact validation');\n    return;\n  }\n\n  // Try to get PR description from environment or git\n  let prDescription = '';\n  const prDescFile = process.env.PR_DESCRIPTION_FILE || '.pr-description.md';\n\n  if (fileExists(prDescFile)) {\n    prDescription = fs.readFileSync(prDescFile, 'utf8');\n  } else if (process.env.PR_DESCRIPTION) {\n    prDescription = process.env.PR_DESCRIPTION;\n  } else {\n    // Try to get from git commit message or PR\n    logInfo('No PR description found, artifact checking will be limited');\n    return;\n  }\n\n  // Get changed files\n  let changedFiles = [];\n  if (commandExists('git')) {\n    const gitResult = runCommand('git diff --name-only HEAD 2>/dev/null || git diff --name-only HEAD~1 HEAD 2>/dev/null || echo \"\"', true);\n    if (gitResult.success && gitResult.output) {\n      changedFiles = gitResult.output.trim().split('\\n').filter(f => f);\n    }\n  }\n\n  // Write PR description to temp file\n  const tempPrFile = path.join(process.cwd(), '.pr-description-temp.md');\n  fs.writeFileSync(tempPrFile, prDescription);\n\n  try {\n    const args = [tempPrFile, ...changedFiles];\n    const result = runCommand(`node \"${artifactChecker}\" ${args.map(a => `\"${a}\"`).join(' ')}`, false);\n\n    if (!result.success) {\n      logError('Required artifacts missing for declared change type');\n      logError('This is a HARD GATE failure - PR cannot be merged');\n      hardFailures.push('Missing required artifacts for change type');\n    } else {\n      logSuccess('All required artifacts present for change type');\n    }\n  } catch (e) {\n    logWarning(`Artifact checking failed: ${e.message}`);\n  } finally {\n    // Clean up temp file\n    if (fileExists(tempPrFile)) {\n      try {\n        fs.unlinkSync(tempPrFile);\n      } catch (e) {\n        // Ignore cleanup errors\n      }\n    }\n  }\n}\n\n// Check 10: Directories auto-creation\nfunction checkDirectories() {\n  logInfo('Checking required directories...');\n  const requiredDirs = ['.repo/logs', '.repo/traces'];\n\n  for (const dir of requiredDirs) {\n    if (!dirExists(dir)) {\n      logWarning(`Directory missing: ${dir} (should be auto-created by scripts)`);\n      // Try to create it\n      try {\n        fs.mkdirSync(dir, { recursive: true });\n        logSuccess(`Created directory: ${dir}`);\n      } catch (e) {\n        logWarning(`Could not create directory: ${dir}`);\n      }\n    } else {\n      logSuccess(`Directory exists: ${dir}`);\n    }\n  }\n}\n\n// Check 12: Stale context files\nfunction checkStaleContextFiles() {\n  logInfo('Checking for stale context files...');\n  const staleChecker = path.resolve(__dirname, 'check-stale-context.js');\n\n  if (fileExists(staleChecker)) {\n    const result = runCommand(`node \"${staleChecker}\" --warn-only`, true);\n    if (!result.success && result.output && result.output.includes('Stale context files')) {\n      logWarning('Some context files are stale (> 30 days old)');\n      logWarning('Update with: node .repo/automation/scripts/update-context-verified.js --all');\n    } else {\n      logSuccess('Context files are up to date');\n    }\n  } else {\n    logWarning('Stale context checker not found, skipping check');\n  }\n}\n\n// Main execution\nfunction main() {\n  const startTime = Date.now();\n  console.log('==========================================');\n  console.log('Governance Verification (Node.js)');\n  console.log('==========================================\\n');\n\n  // Log verification start\n  if (logger) {\n    logger.logInteraction({\n      agent: 'governance-verify',\n      action: 'verification_start',\n      success: true,\n      context: {\n        script: 'governance-verify.js',\n        timestamp: new Date().toISOString()\n      }\n    });\n  }\n\n  try {\n  checkPolicyFiles();\n  checkManifest();\n  checkHITLStatus();\n  checkRepositoryStructure();\n  checkTraceLogSchema();\n  checkTraceLogs();\n  checkADRTriggers();\n  checkBoundaries();\n  checkExpiredWaivers();\n  checkTaskFormat();\n  checkDirectories();\n  checkStaleContextFiles();\n  checkArtifactsByChangeType();\n  } catch (err) {\n    // Log verification error\n    if (logger) {\n      logger.logError({\n        agent: 'governance-verify',\n        action: 'verification_run',\n        error: err.message,\n        context: {\n          stack: err.stack\n        }\n      });\n    }\n    throw err;\n  }\n\n  const duration_ms = Date.now() - startTime;\n  const success = errors === 0;\n\n  // Summary\n  console.log('\\n==========================================');\n  console.log('Governance Verification Summary');\n  console.log('==========================================');\n  console.log(`Errors (hard failures): ${errors}`);\n  console.log(`Warnings (waiverable): ${warnings}\\n`);\n\n  // Log verification completion\n  if (logger) {\n    logger.logInteraction({\n      agent: 'governance-verify',\n      action: 'verification_complete',\n      duration_ms,\n      success,\n      context: {\n        errors,\n        warnings,\n        hard_failures: hardFailures.length\n      }\n    });\n\n    // Log failures if any\n    if (errors > 0 && logger) {\n      hardFailures.forEach(failure => {\n        logger.logError({\n          agent: 'governance-verify',\n          action: 'verification_failure',\n          error: failure,\n          context: {\n            total_errors: errors,\n            total_warnings: warnings\n          }\n        });\n      });\n    }\n  }\n\n  if (errors > 0) {\n    console.log('Hard failures (blocks merge):');\n    hardFailures.forEach(failure => console.log(`  - ${failure}`));\n    console.log('\\n❌ Governance verification FAILED (hard gate)');\n    process.exit(1);\n  } else if (warnings > 0) {\n    console.log('⚠️  Governance verification passed with warnings (may require waiver)');\n    process.exit(2);\n  } else {\n    console.log('✅ Governance verification PASSED');\n    process.exit(0);\n  }\n}\n\nif (require.main === module) {\n  main();\n}\n\nmodule.exports = { main };\n"
        },
        {
          "path": ".repo/automation/scripts/agent-logger.js",
          "type": "Node.js",
          "lines": 275,
          "purpose": "Agent interaction logging SDK",
          "key_functionality": [
            "logInteraction(entry): Logs agent actions (JSONL format)",
            "logError(entry): Logs errors",
            "generateMetrics(date): Generates daily metrics from logs",
            "Log rotation/cleanup",
            "Graceful degradation (continues if logging fails)"
          ],
          "log_locations": [
            ".agent-logs/interactions/YYYY-MM-DD.jsonl",
            ".agent-logs/errors/YYYY-MM-DD.jsonl",
            ".agent-logs/metrics/YYYY-MM-DD.json"
          ],
          "used_by": [
            "governance-verify.js",
            "agents (if integrated)"
          ],
          "dependencies": [
            "fs",
            "path (Node.js built-in)"
          ],
          "content": "#!/usr/bin/env node\n// /.repo/automation/scripts/agent-logger.js\n// Agent interaction logging SDK\n// Usage: const logger = require('./agent-logger.js');\n\nconst fs = require('fs');\nconst path = require('path');\n\n// Get repo root (assumes script is in .repo/automation/scripts/)\nconst REPO_ROOT = path.resolve(__dirname, '../../..');\nconst LOGS_DIR = path.join(REPO_ROOT, '.agent-logs');\nconst INTERACTIONS_DIR = path.join(LOGS_DIR, 'interactions');\nconst ERRORS_DIR = path.join(LOGS_DIR, 'errors');\nconst METRICS_DIR = path.join(LOGS_DIR, 'metrics');\n\n// Ensure directories exist\n[INTERACTIONS_DIR, ERRORS_DIR, METRICS_DIR].forEach(dir => {\n  if (!fs.existsSync(dir)) {\n    fs.mkdirSync(dir, { recursive: true });\n  }\n});\n\n/**\n * Log an agent interaction\n * @param {Object} entry - Log entry object\n * @param {string} entry.agent - Agent name (e.g., \"Auto\")\n * @param {string} entry.action - Action performed (e.g., \"read_file\", \"search_replace\")\n * @param {string} [entry.file] - File path (relative to repo root)\n * @param {number} [entry.duration_ms] - Duration in milliseconds\n * @param {boolean} entry.success - Whether action succeeded\n * @param {Object} [entry.context] - Additional context (task, folder, etc.)\n * @param {string} [entry.error] - Error message if failed\n */\nfunction logInteraction(entry) {\n  const timestamp = new Date().toISOString();\n  const logEntry = {\n    timestamp,\n    agent: entry.agent || 'Auto',\n    action: entry.action,\n    file: entry.file || null,\n    duration_ms: entry.duration_ms || null,\n    success: entry.success !== undefined ? entry.success : true,\n    context: entry.context || {},\n    ...(entry.error && { error: entry.error })\n  };\n\n  // Write to interactions log (JSONL format)\n  const today = new Date().toISOString().split('T')[0];\n  const logFile = path.join(INTERACTIONS_DIR, `${today}.jsonl`);\n\n  try {\n    fs.appendFileSync(logFile, JSON.stringify(logEntry) + '\\n', 'utf8');\n  } catch (err) {\n    // Graceful degradation: log to stderr but don't throw\n    // This ensures workflow continues even if logging fails\n    console.error(`[WARNING] Failed to write interaction log: ${err.message}`);\n    // Try to log error (but don't fail if this also fails)\n    try {\n      logError({\n        agent: entry.agent || 'Auto',\n        action: 'log_interaction',\n        error: `Failed to write interaction log: ${err.message}`,\n        context: { original_entry: logEntry }\n      });\n    } catch {\n      // If error logging also fails, just continue\n    }\n  }\n}\n\n/**\n * Log an error\n * @param {Object} entry - Error log entry\n * @param {string} entry.agent - Agent name\n * @param {string} entry.action - Action that failed\n * @param {string} entry.error - Error message\n * @param {Object} [entry.context] - Additional context\n */\nfunction logError(entry) {\n  const timestamp = new Date().toISOString();\n  const errorEntry = {\n    timestamp,\n    agent: entry.agent || 'Auto',\n    action: entry.action || 'unknown',\n    error: entry.error,\n    context: entry.context || {}\n  };\n\n  // Write to errors log\n  const today = new Date().toISOString().split('T')[0];\n  const errorFile = path.join(ERRORS_DIR, `${today}.jsonl`);\n\n  try {\n    fs.appendFileSync(errorFile, JSON.stringify(errorEntry) + '\\n', 'utf8');\n  } catch (err) {\n    // Last resort: write to stderr\n    console.error(`CRITICAL: Failed to write error log: ${err.message}`);\n    console.error(`Original error: ${JSON.stringify(errorEntry)}`);\n  }\n}\n\n/**\n * Generate daily metrics from interaction logs\n * @param {string} [date] - Date in YYYY-MM-DD format (defaults to today)\n * @returns {Object} Metrics object\n */\nfunction generateMetrics(date) {\n  const targetDate = date || new Date().toISOString().split('T')[0];\n  const logFile = path.join(INTERACTIONS_DIR, `${targetDate}.jsonl`);\n\n  if (!fs.existsSync(logFile)) {\n    return {\n      date: targetDate,\n      total_interactions: 0,\n      successful: 0,\n      failed: 0,\n      success_rate: 0,\n      avg_duration_ms: 0,\n      actions: {},\n      errors: []\n    };\n  }\n\n  const lines = fs.readFileSync(logFile, 'utf8')\n    .split('\\n')\n    .filter(line => line.trim());\n\n  const entries = lines.map(line => {\n    try {\n      return JSON.parse(line);\n    } catch {\n      return null;\n    }\n  }).filter(entry => entry !== null);\n\n  const metrics = {\n    date: targetDate,\n    total_interactions: entries.length,\n    successful: 0,\n    failed: 0,\n    success_rate: 0,\n    total_duration_ms: 0,\n    avg_duration_ms: 0,\n    actions: {},\n    errors: []\n  };\n\n  entries.forEach(entry => {\n    if (entry.success) {\n      metrics.successful++;\n    } else {\n      metrics.failed++;\n      if (entry.error) {\n        metrics.errors.push({\n          action: entry.action,\n          error: entry.error,\n          file: entry.file\n        });\n      }\n    }\n\n    if (entry.duration_ms) {\n      metrics.total_duration_ms += entry.duration_ms;\n    }\n\n    if (!metrics.actions[entry.action]) {\n      metrics.actions[entry.action] = {\n        count: 0,\n        successful: 0,\n        failed: 0,\n        total_duration_ms: 0\n      };\n    }\n    metrics.actions[entry.action].count++;\n    if (entry.success) {\n      metrics.actions[entry.action].successful++;\n    } else {\n      metrics.actions[entry.action].failed++;\n    }\n    if (entry.duration_ms) {\n      metrics.actions[entry.action].total_duration_ms += entry.duration_ms;\n    }\n  });\n\n  if (metrics.total_interactions > 0) {\n    metrics.success_rate = metrics.successful / metrics.total_interactions;\n    metrics.avg_duration_ms = metrics.total_duration_ms / metrics.total_interactions;\n  }\n\n  // Calculate averages for each action\n  Object.keys(metrics.actions).forEach(action => {\n    const actionData = metrics.actions[action];\n    if (actionData.count > 0) {\n      actionData.avg_duration_ms = actionData.total_duration_ms / actionData.count;\n      actionData.success_rate = actionData.successful / actionData.count;\n    }\n  });\n\n  return metrics;\n}\n\n/**\n * Write metrics to file\n * @param {string} [date] - Date in YYYY-MM-DD format (defaults to today)\n */\nfunction writeMetrics(date) {\n  const targetDate = date || new Date().toISOString().split('T')[0];\n  const metrics = generateMetrics(targetDate);\n  const metricsFile = path.join(METRICS_DIR, `${targetDate}.json`);\n\n  try {\n    fs.writeFileSync(metricsFile, JSON.stringify(metrics, null, 2), 'utf8');\n    return metrics;\n  } catch (err) {\n    console.error(`Failed to write metrics: ${err.message}`);\n    return null;\n  }\n}\n\n/**\n * Clean up old logs (keep last N days)\n * @param {number} daysToKeep - Number of days to keep (default: 30)\n */\nfunction cleanupOldLogs(daysToKeep = 30) {\n  const cutoffDate = new Date();\n  cutoffDate.setDate(cutoffDate.getDate() - daysToKeep);\n\n  [INTERACTIONS_DIR, ERRORS_DIR, METRICS_DIR].forEach(dir => {\n    if (!fs.existsSync(dir)) return;\n\n    const files = fs.readdirSync(dir);\n    files.forEach(file => {\n      const filePath = path.join(dir, file);\n      const stats = fs.statSync(filePath);\n      if (stats.mtime < cutoffDate) {\n        try {\n          fs.unlinkSync(filePath);\n        } catch (err) {\n          console.error(`Failed to delete old log file ${filePath}: ${err.message}`);\n        }\n      }\n    });\n  });\n}\n\n// CLI usage\nif (require.main === module) {\n  const command = process.argv[2];\n\n  if (command === 'metrics') {\n    const date = process.argv[3];\n    const metrics = writeMetrics(date);\n    if (metrics) {\n      console.log(JSON.stringify(metrics, null, 2));\n    }\n  } else if (command === 'cleanup') {\n    const days = parseInt(process.argv[3]) || 30;\n    cleanupOldLogs(days);\n    console.log(`Cleaned up logs older than ${days} days`);\n  } else {\n    console.log('Usage:');\n    console.log('  node agent-logger.js metrics [date]  - Generate and write metrics');\n    console.log('  node agent-logger.js cleanup [days] - Clean up old logs (default: 30 days)');\n  }\n}\n\n// Export for use as module\nmodule.exports = {\n  logInteraction,\n  logError,\n  generateMetrics,\n  writeMetrics,\n  cleanupOldLogs\n};\n"
        },
        {
          "path": ".repo/automation/scripts/check-artifacts-by-change-type.js",
          "type": "Node.js",
          "lines": 258,
          "purpose": "Checks required artifacts based on change type",
          "key_functionality": [
            "Parses change type from PR description (JSON or markdown)",
            "Checks artifacts per change type: feature (task_packet, trace_log, tests), api_change (task_packet, adr, trace_log, openapi_update), security (hitl, trace_log, security_tests), cross_module (adr, task_packet, trace_log), non_doc_change (agent_log, trace_log, reasoning_summary)",
            "Validates artifact recency (within 24 hours)",
            "Checks artifact locations and formats"
          ],
          "used_by": [
            "governance-verify.js"
          ],
          "referenced_by": [
            "QUALITY_GATES.md"
          ],
          "content": "#!/usr/bin/env node\n/**\n * check-artifacts-by-change-type.js\n * Checks required artifacts based on change type declared in PR\n *\n * Usage: node check-artifacts-by-change-type.js [pr-description-file] [changed-files...]\n */\n\nconst fs = require('fs');\nconst path = require('path');\n\n// Required artifacts by change type (from rules.json)\nconst ARTIFACT_REQUIREMENTS = {\n  feature: ['task_packet', 'trace_log', 'tests'],\n  api_change: ['task_packet', 'adr', 'trace_log', 'openapi_update'],\n  security: ['hitl', 'trace_log', 'security_tests'],\n  cross_module: ['adr', 'task_packet', 'trace_log'],\n  non_doc_change: ['agent_log', 'trace_log', 'reasoning_summary']\n};\n\nfunction parseChangeType(prDescription) {\n  // Try to find change_type in PR description\n  // Look for JSON format: \"change_type\": \"...\"\n  // Or markdown format: ## Change Type: ... or **Change Type:** ...\n\n  if (!prDescription) return null;\n\n  // JSON format\n  const jsonMatch = prDescription.match(/\"change_type\"\\s*:\\s*\"([^\"]+)\"/);\n  if (jsonMatch) return jsonMatch[1];\n\n  // Markdown format\n  const mdMatch = prDescription.match(/(?:change[_\\s]?type|Change Type)[:：]\\s*(\\w+)/i);\n  if (mdMatch) return mdMatch[1].toLowerCase().replace(/_/g, '_');\n\n  // Try to infer from content\n  const lower = prDescription.toLowerCase();\n  if (lower.includes('security') || lower.includes('auth') || lower.includes('payment')) {\n    return 'security';\n  }\n  if (lower.includes('api') || lower.includes('endpoint') || lower.includes('openapi')) {\n    return 'api_change';\n  }\n  if (lower.includes('cross-module') || lower.includes('cross module') || lower.includes('boundary')) {\n    return 'cross_module';\n  }\n  if (lower.includes('feature') || lower.includes('new functionality')) {\n    return 'feature';\n  }\n\n  return null;\n}\n\nfunction checkArtifact(artifactType, changedFiles, repoRoot) {\n  switch (artifactType) {\n    case 'task_packet':\n      // Check if task packet exists in TODO.md or separate file\n      const todoFile = path.join(repoRoot, '.repo/tasks/TODO.md');\n      if (fs.existsSync(todoFile)) {\n        const content = fs.readFileSync(todoFile, 'utf8');\n        if (content.includes('task_packet') || content.includes('Task Packet') || content.includes('goal')) {\n          return { found: true, location: todoFile };\n        }\n      }\n      // Check for task packet files in .repo/tasks/packets/\n      const packetsDir = path.join(repoRoot, '.repo/tasks/packets');\n      if (fs.existsSync(packetsDir)) {\n        const packetFiles = fs.readdirSync(packetsDir).filter(f => f.endsWith('.json') && f.includes('packet'));\n        if (packetFiles.length > 0) {\n          // Check if packet file is recent (within last day)\n          const latestPacket = packetFiles\n            .map(f => ({ file: f, mtime: fs.statSync(path.join(packetsDir, f)).mtime }))\n            .sort((a, b) => b.mtime - a.mtime)[0];\n          const oneDayAgo = Date.now() - 24 * 60 * 60 * 1000;\n          if (latestPacket.mtime.getTime() > oneDayAgo) {\n            return { found: true, location: path.join(packetsDir, latestPacket.file) };\n          }\n        }\n      }\n      return { found: false, location: 'TODO.md or .repo/tasks/packets/TASK-XXX-packet.json' };\n\n    case 'trace_log':\n      const tracesDir = path.join(repoRoot, '.repo/traces');\n      if (fs.existsSync(tracesDir)) {\n        const traceFiles = fs.readdirSync(tracesDir).filter(f => f.endsWith('.json'));\n        if (traceFiles.length > 0) {\n          // Check if trace log is recent (within last day)\n          const latestTrace = traceFiles\n            .map(f => ({ file: f, mtime: fs.statSync(path.join(tracesDir, f)).mtime }))\n            .sort((a, b) => b.mtime - a.mtime)[0];\n          const oneDayAgo = Date.now() - 24 * 60 * 60 * 1000;\n          if (latestTrace.mtime.getTime() > oneDayAgo) {\n            return { found: true, location: path.join(tracesDir, latestTrace.file) };\n          }\n        }\n      }\n      return { found: false, location: '.repo/traces/' };\n\n    case 'agent_log':\n      const logsDir = path.join(repoRoot, '.repo/logs');\n      if (fs.existsSync(logsDir)) {\n        const logFiles = fs.readdirSync(logsDir).filter(f => f.endsWith('.json'));\n        if (logFiles.length > 0) {\n          const latestLog = logFiles\n            .map(f => ({ file: f, mtime: fs.statSync(path.join(logsDir, f)).mtime }))\n            .sort((a, b) => b.mtime - a.mtime)[0];\n          const oneDayAgo = Date.now() - 24 * 60 * 60 * 1000;\n          if (latestLog.mtime.getTime() > oneDayAgo) {\n            return { found: true, location: path.join(logsDir, latestLog.file) };\n          }\n        }\n      }\n      return { found: false, location: '.repo/logs/' };\n\n    case 'adr':\n      const adrDir = path.join(repoRoot, 'docs/adr');\n      if (fs.existsSync(adrDir)) {\n        const adrFiles = fs.readdirSync(adrDir).filter(f => f.match(/^ADR-\\d+\\.md$/));\n        if (adrFiles.length > 0) {\n          const latestAdr = adrFiles\n            .map(f => ({ file: f, mtime: fs.statSync(path.join(adrDir, f)).mtime }))\n            .sort((a, b) => b.mtime - a.mtime)[0];\n          const oneDayAgo = Date.now() - 24 * 60 * 60 * 1000;\n          if (latestAdr.mtime.getTime() > oneDayAgo) {\n            return { found: true, location: path.join(adrDir, latestAdr.file) };\n          }\n        }\n      }\n      return { found: false, location: 'docs/adr/' };\n\n    case 'hitl':\n      const hitlDir = path.join(repoRoot, '.repo/hitl');\n      if (fs.existsSync(hitlDir)) {\n        const hitlFiles = fs.readdirSync(hitlDir).filter(f => f.match(/^HITL-\\d+\\.md$/));\n        if (hitlFiles.length > 0) {\n          const latestHitl = hitlFiles\n            .map(f => ({ file: f, mtime: fs.statSync(path.join(hitlDir, f)).mtime }))\n            .sort((a, b) => b.mtime - a.mtime)[0];\n          const oneDayAgo = Date.now() - 24 * 60 * 60 * 1000;\n          if (latestHitl.mtime.getTime() > oneDayAgo) {\n            return { found: true, location: path.join(hitlDir, latestHitl.file) };\n          }\n        }\n      }\n      return { found: false, location: '.repo/hitl/' };\n\n    case 'openapi_update':\n      // Check if openapi.yaml was modified\n      const openapiFile = path.join(repoRoot, 'backend/openapi.yaml');\n      if (changedFiles.some(f => f.includes('openapi.yaml'))) {\n        return { found: true, location: openapiFile };\n      }\n      return { found: false, location: 'backend/openapi.yaml (should be updated)' };\n\n    case 'tests':\n      // Check if test files were added/modified\n      const hasTests = changedFiles.some(f =>\n        f.includes('test') || f.includes('spec') || f.endsWith('.test.ts') || f.endsWith('_test.py')\n      );\n      return { found: hasTests, location: 'test files' };\n\n    case 'security_tests':\n      // Check if security test files were added/modified\n      const hasSecurityTests = changedFiles.some(f =>\n        (f.includes('test') || f.includes('spec')) &&\n        (f.includes('security') || f.includes('auth') || f.includes('payment'))\n      );\n      return { found: hasSecurityTests, location: 'security test files' };\n\n    case 'reasoning_summary':\n      // Check if agent log has reasoning_summary field\n      const logsDir2 = path.join(repoRoot, '.repo/logs');\n      if (fs.existsSync(logsDir2)) {\n        const logFiles = fs.readdirSync(logsDir2).filter(f => f.endsWith('.json'));\n        for (const logFile of logFiles.slice(-5)) { // Check last 5 logs\n          try {\n            const logContent = JSON.parse(fs.readFileSync(path.join(logsDir2, logFile), 'utf8'));\n            if (logContent.reasoning_summary && logContent.reasoning_summary.trim()) {\n              return { found: true, location: path.join(logsDir2, logFile) };\n            }\n          } catch (e) {\n            // Skip invalid JSON\n          }\n        }\n      }\n      return { found: false, location: '.repo/logs/ (agent log with reasoning_summary)' };\n\n    default:\n      return { found: false, location: `Unknown artifact type: ${artifactType}` };\n  }\n}\n\nfunction main() {\n  const args = process.argv.slice(2);\n  if (args.length === 0) {\n    console.error('Usage: node check-artifacts-by-change-type.js [pr-description-file] [changed-files...]');\n    process.exit(1);\n  }\n\n  const prDescriptionFile = args[0];\n  const changedFiles = args.slice(1);\n  const repoRoot = process.cwd();\n\n  let prDescription = '';\n  if (fs.existsSync(prDescriptionFile)) {\n    prDescription = fs.readFileSync(prDescriptionFile, 'utf8');\n  }\n\n  const changeType = parseChangeType(prDescription);\n\n  if (!changeType) {\n    console.log('⚠️  Could not determine change type from PR description');\n    console.log('   Add \"change_type\" field to PR description');\n    process.exit(2);\n  }\n\n  if (!ARTIFACT_REQUIREMENTS[changeType]) {\n    console.log(`⚠️  Unknown change type: ${changeType}`);\n    console.log(`   Valid types: ${Object.keys(ARTIFACT_REQUIREMENTS).join(', ')}`);\n    process.exit(2);\n  }\n\n  console.log(`\\n📋 Checking artifacts for change type: ${changeType}`);\n  console.log(`   Required: ${ARTIFACT_REQUIREMENTS[changeType].join(', ')}\\n`);\n\n  const requiredArtifacts = ARTIFACT_REQUIREMENTS[changeType];\n  const missing = [];\n  const found = [];\n\n  for (const artifact of requiredArtifacts) {\n    const result = checkArtifact(artifact, changedFiles, repoRoot);\n    if (result.found) {\n      console.log(`✅ ${artifact}: Found at ${result.location}`);\n      found.push(artifact);\n    } else {\n      console.log(`❌ ${artifact}: Missing (expected at ${result.location})`);\n      missing.push(artifact);\n    }\n  }\n\n  console.log('');\n\n  if (missing.length > 0) {\n    console.log(`❌ Missing required artifacts: ${missing.join(', ')}`);\n    console.log('   This is a HARD GATE failure - PR cannot be merged');\n    process.exit(1);\n  } else {\n    console.log('✅ All required artifacts present');\n    process.exit(0);\n  }\n}\n\nif (require.main === module) {\n  main();\n}\n\nmodule.exports = { parseChangeType, checkArtifact, ARTIFACT_REQUIREMENTS };\n"
        },
        {
          "path": ".repo/automation/scripts/check-boundaries.js",
          "type": "Node.js",
          "lines": 104,
          "purpose": "Boundary checking script (wraps lint-imports)",
          "key_functionality": [
            "Checks if lint-imports is installed",
            "Validates .importlinter config exists",
            "Runs lint-imports with config",
            "Parses violations from output",
            "Option to fail on violations (--fail-on-violations)"
          ],
          "dependencies": [
            "lint-imports (external tool)",
            ".importlinter config"
          ],
          "used_by": [
            "governance-verify.js",
            "CI workflows"
          ],
          "referenced_by": [
            "BOUNDARIES.md",
            "repo.manifest.yaml (check:boundaries)"
          ],
          "content": "#!/usr/bin/env node\n// /.repo/automation/scripts/check-boundaries.js\n// Boundary checking script - wraps lint-imports for agent use\n// Usage: node check-boundaries.js [--fail-on-violations]\n\nconst { execSync } = require('child_process');\nconst path = require('path');\n\n// Get repo root\nconst REPO_ROOT = path.resolve(__dirname, '../../..');\nconst IMPORTLINTER_CONFIG = path.join(REPO_ROOT, '.importlinter');\n\n// Colors\nconst RED = '\\x1b[31m';\nconst YELLOW = '\\x1b[33m';\nconst GREEN = '\\x1b[32m';\nconst RESET = '\\x1b[0m';\n\nfunction commandExists(cmd) {\n  try {\n    execSync(`which ${cmd} 2>/dev/null || where ${cmd} 2>/dev/null`, { stdio: 'ignore' });\n    return true;\n  } catch {\n    return false;\n  }\n}\n\nfunction checkBoundaries(failOnViolations = false) {\n  console.log('Checking module boundaries...\\n');\n\n  // Check if import-linter is installed\n  if (!commandExists('lint-imports')) {\n    console.error(`${RED}❌ ERROR: lint-imports not found${RESET}`);\n    console.error('Install with: pip install import-linter==2.0');\n    process.exit(1);\n  }\n\n  // Check if config file exists\n  const fs = require('fs');\n  if (!fs.existsSync(IMPORTLINTER_CONFIG)) {\n    console.error(`${RED}❌ ERROR: .importlinter config file not found${RESET}`);\n    console.error(`Expected at: ${IMPORTLINTER_CONFIG}`);\n    process.exit(1);\n  }\n\n  try {\n    // Run lint-imports\n    const result = execSync(\n      `lint-imports --config \"${IMPORTLINTER_CONFIG}\"`,\n      {\n        encoding: 'utf8',\n        cwd: REPO_ROOT,\n        stdio: 'pipe'\n      }\n    );\n\n    console.log(result);\n    console.log(`${GREEN}✅ Boundary check passed${RESET}`);\n    return { success: true, violations: [] };\n  } catch (e) {\n    const output = e.stdout || e.stderr || e.message;\n    console.error(`${RED}❌ Boundary violations detected:${RESET}\\n`);\n    console.error(output);\n\n    // Try to parse violations from output\n    const violations = [];\n    const lines = output.split('\\n');\n    let currentViolation = null;\n\n    for (const line of lines) {\n      if (line.includes('Broken contract:') || line.includes('Contract')) {\n        if (currentViolation) {\n          violations.push(currentViolation);\n        }\n        currentViolation = { contract: line.trim(), imports: [] };\n      } else if (line.includes('->') && currentViolation) {\n        currentViolation.imports.push(line.trim());\n      }\n    }\n    if (currentViolation) {\n      violations.push(currentViolation);\n    }\n\n    if (failOnViolations) {\n      console.error(`\\n${RED}Hard gate failure: Boundary violations must be fixed or waived${RESET}`);\n      console.error('See: .repo/policy/BOUNDARIES.md for boundary rules');\n      console.error('See: .repo/policy/QUALITY_GATES.md for waiver process');\n      process.exit(1);\n    }\n\n    return { success: false, violations };\n  }\n}\n\n// CLI usage\nif (require.main === module) {\n  const failOnViolations = process.argv.includes('--fail-on-violations');\n  const result = checkBoundaries(failOnViolations);\n  process.exit(result.success ? 0 : 1);\n}\n\n// Export for use as module\nmodule.exports = { checkBoundaries };\n"
        },
        {
          "path": ".repo/automation/scripts/validate-agent-context.js",
          "type": "Node.js",
          "lines": 156,
          "purpose": "Validates .agent-context.json files against schema",
          "key_functionality": [
            "Loads JSON schema (AGENT_CONTEXT_SCHEMA.json)",
            "Validates using ajv (with graceful fallback)",
            "Optional checks: --check-files (validates folder paths exist), --check-boundaries (validates boundary rules), --check-links (validates quick_links paths)",
            "Reports errors and warnings"
          ],
          "dependencies": [
            "ajv (optional, graceful fallback)",
            "AGENT_CONTEXT_SCHEMA.json"
          ],
          "used_by": [
            "governance-verify.js",
            "CI workflows"
          ],
          "referenced_by": [
            "check-stale-context.js"
          ],
          "content": "#!/usr/bin/env node\n// Validate .agent-context.json file against schema\n// Usage: node validate-agent-context.js <context-file> [--check-files] [--check-boundaries] [--check-links]\n\nconst fs = require('fs');\nconst path = require('path');\n\n// Try to load ajv, fall back to basic validation if not available\nlet Ajv;\nlet ajv;\ntry {\n  Ajv = require('ajv');\n  ajv = new Ajv({ allErrors: true, strict: false });\n} catch (err) {\n  console.warn('⚠️  ajv not found. Install with: npm install ajv (in .repo/automation/scripts/)');\n  console.warn('   Falling back to basic validation only.');\n}\n\nconst contextFile = process.argv[2];\nconst checkFiles = process.argv.includes('--check-files');\nconst checkBoundaries = process.argv.includes('--check-boundaries');\nconst checkLinks = process.argv.includes('--check-links');\n\nif (!contextFile) {\n  console.error('Usage: node validate-agent-context.js <context-file> [--check-files] [--check-boundaries] [--check-links]');\n  process.exit(1);\n}\n\nif (!fs.existsSync(contextFile)) {\n  console.error(`File not found: ${contextFile}`);\n  process.exit(1);\n}\n\n// Get repo root (assumes script is in .repo/automation/scripts/)\nconst REPO_ROOT = path.resolve(__dirname, '../../..');\nconst SCHEMA_FILE = path.join(REPO_ROOT, '.repo/templates/AGENT_CONTEXT_SCHEMA.json');\n\nlet errors = [];\nlet warnings = [];\n\nfunction addError(msg) {\n  errors.push(msg);\n}\n\nfunction addWarning(msg) {\n  warnings.push(msg);\n}\n\ntry {\n  const content = JSON.parse(fs.readFileSync(contextFile, 'utf8'));\n\n  // Load and validate against JSON schema if ajv is available\n  if (ajv && fs.existsSync(SCHEMA_FILE)) {\n    const schema = JSON.parse(fs.readFileSync(SCHEMA_FILE, 'utf8'));\n    const validate = ajv.compile(schema);\n    const valid = validate(content);\n\n    if (!valid) {\n      validate.errors.forEach(err => {\n        addError(`${err.instancePath || 'root'}: ${err.message}`);\n      });\n    }\n  } else {\n    // Fallback: Basic validation\n    const required = ['version', 'type', 'folder'];\n    const missing = required.filter(field => !content[field]);\n\n    if (missing.length > 0) {\n      addError(`Missing required fields: ${missing.join(', ')}`);\n    }\n\n    if (content.type && content.type !== 'folder_context') {\n      addError(`Invalid type: ${content.type} (expected: folder_context)`);\n    }\n\n    if (content.folder && !content.folder.path) {\n      addError('Missing folder.path');\n    }\n  }\n\n  // File path validation\n  if (checkFiles && content.folder && content.folder.path) {\n    const folderPath = path.join(REPO_ROOT, content.folder.path);\n    if (!fs.existsSync(folderPath)) {\n      addError(`Folder path does not exist: ${content.folder.path}`);\n    } else if (!fs.statSync(folderPath).isDirectory()) {\n      addError(`Folder path is not a directory: ${content.folder.path}`);\n    }\n\n    // Check if patterns match actual code (basic check)\n    if (content.patterns) {\n      Object.keys(content.patterns).forEach(patternName => {\n        // This is a basic check - could be enhanced to actually parse code\n        const pattern = content.patterns[patternName];\n        if (typeof pattern !== 'string' || pattern.length === 0) {\n          addWarning(`Pattern \"${patternName}\" is empty or invalid`);\n        }\n      });\n    }\n  }\n\n  // Boundary validation\n  if (checkBoundaries && content.boundaries) {\n    if (content.boundaries.can_import_from) {\n      content.boundaries.can_import_from.forEach(importPath => {\n        const fullPath = path.join(REPO_ROOT, importPath);\n        if (!fs.existsSync(fullPath)) {\n          addWarning(`Boundary can_import_from path does not exist: ${importPath}`);\n        }\n      });\n    }\n    if (content.boundaries.cannot_import_from) {\n      content.boundaries.cannot_import_from.forEach(importPath => {\n        const fullPath = path.join(REPO_ROOT, importPath);\n        if (!fs.existsSync(fullPath)) {\n          addWarning(`Boundary cannot_import_from path does not exist: ${importPath}`);\n        }\n      });\n    }\n  }\n\n  // Link validation\n  if (checkLinks && content.quick_links) {\n    Object.keys(content.quick_links).forEach(linkType => {\n      const linkPath = content.quick_links[linkType];\n      if (linkPath) {\n        const fullPath = path.join(REPO_ROOT, linkPath);\n        if (!fs.existsSync(fullPath)) {\n          addWarning(`Quick link \"${linkType}\" points to non-existent file: ${linkPath}`);\n        }\n      }\n    });\n  }\n\n  // Output results\n  if (errors.length > 0) {\n    console.error('❌ Validation failed:');\n    errors.forEach(err => console.error(`   ${err}`));\n    console.error('\\nSee: .repo/templates/AGENT_CONTEXT_SCHEMA.json for schema');\n    console.error('See: .repo/docs/TROUBLESHOOTING.md for help');\n    process.exit(1);\n  }\n\n  if (warnings.length > 0) {\n    console.warn('⚠️  Warnings:');\n    warnings.forEach(warn => console.warn(`   ${warn}`));\n    console.warn('\\nWarnings are non-blocking but should be addressed');\n  }\n\n  console.log(`✅ ${contextFile} is valid`);\n  process.exit(0);\n} catch (e) {\n  console.error(`Error validating ${contextFile}:`, e.message);\n  process.exit(1);\n}\n"
        },
        {
          "path": ".repo/automation/scripts/check-stale-context.js",
          "type": "Node.js",
          "lines": 113,
          "purpose": "Checks for stale context files (older than threshold)",
          "key_functionality": [
            "Finds all .agent-context.json files recursively",
            "Checks last_verified date against threshold (default 30 days)",
            "Reports missing last_verified dates",
            "Reports stale files (older than threshold)",
            "Option: --warn-only (doesn't exit with error)",
            "Option: --threshold-days=N (custom threshold)"
          ],
          "dependencies": [
            "validate-agent-context.js (indirect)"
          ],
          "used_by": [
            "CI workflows",
            "maintenance scripts"
          ],
          "referenced_by": [
            "Context file maintenance workflow"
          ],
          "content": "#!/usr/bin/env node\n// /.repo/automation/scripts/check-stale-context.js\n// Check for stale context files (older than threshold)\n// Usage: node check-stale-context.js [--threshold-days=30] [--warn-only]\n\nconst fs = require('fs');\nconst path = require('path');\n\n// Get repo root\nconst REPO_ROOT = path.resolve(__dirname, '../../..');\nconst THRESHOLD_DAYS = parseInt(process.env.THRESHOLD_DAYS || process.argv.find(arg => arg.startsWith('--threshold-days='))?.split('=')[1] || '30');\nconst WARN_ONLY = process.argv.includes('--warn-only');\n\n// Colors\nconst RED = '\\x1b[31m';\nconst YELLOW = '\\x1b[33m';\nconst GREEN = '\\x1b[32m';\nconst RESET = '\\x1b[0m';\n\nfunction findContextFiles(dir, fileList = []) {\n  const files = fs.readdirSync(dir);\n\n  files.forEach(file => {\n    const filePath = path.join(dir, file);\n    const stat = fs.statSync(filePath);\n\n    if (stat.isDirectory() && !file.startsWith('.') && file !== 'node_modules') {\n      findContextFiles(filePath, fileList);\n    } else if (file === '.agent-context.json') {\n      fileList.push(filePath);\n    }\n  });\n\n  return fileList;\n}\n\nfunction checkStaleContextFiles() {\n  console.log(`Checking for stale context files (threshold: ${THRESHOLD_DAYS} days)...\\n`);\n\n  const contextFiles = findContextFiles(REPO_ROOT);\n  const thresholdDate = new Date();\n  thresholdDate.setDate(thresholdDate.getDate() - THRESHOLD_DAYS);\n\n  const staleFiles = [];\n  const missingDateFiles = [];\n\n  contextFiles.forEach(filePath => {\n    try {\n      const content = JSON.parse(fs.readFileSync(filePath, 'utf8'));\n      const stats = fs.statSync(filePath);\n      const relativePath = path.relative(REPO_ROOT, filePath);\n\n      // Check if last_verified exists\n      if (!content.metrics || !content.metrics.last_verified) {\n        missingDateFiles.push({\n          path: relativePath,\n          lastModified: stats.mtime,\n          age: Math.floor((Date.now() - stats.mtime.getTime()) / (1000 * 60 * 60 * 24))\n        });\n      } else {\n        // Check if last_verified is older than threshold\n        const lastVerified = new Date(content.metrics.last_verified);\n        if (lastVerified < thresholdDate) {\n          const age = Math.floor((Date.now() - lastVerified.getTime()) / (1000 * 60 * 60 * 24));\n          staleFiles.push({\n            path: relativePath,\n            lastVerified: lastVerified,\n            age: age\n          });\n        }\n      }\n    } catch (err) {\n      console.error(`${RED}Error reading ${filePath}: ${err.message}${RESET}`);\n    }\n  });\n\n  // Report results\n  if (missingDateFiles.length > 0) {\n    console.log(`${YELLOW}⚠️  Context files missing last_verified date:${RESET}`);\n    missingDateFiles.forEach(file => {\n      console.log(`   ${file.path} (last modified: ${file.age} days ago)`);\n    });\n    console.log();\n  }\n\n  if (staleFiles.length > 0) {\n    console.log(`${YELLOW}⚠️  Stale context files (older than ${THRESHOLD_DAYS} days):${RESET}`);\n    staleFiles.forEach(file => {\n      console.log(`   ${file.path} (last verified: ${file.age} days ago)`);\n    });\n    console.log();\n    console.log(`   Update with: node .repo/automation/scripts/update-context-verified.js ${staleFiles.map(f => f.path).join(' ')}`);\n    console.log();\n\n    if (!WARN_ONLY) {\n      console.log(`${RED}❌ Stale context files detected${RESET}`);\n      process.exit(1);\n    }\n  } else if (missingDateFiles.length === 0) {\n    console.log(`${GREEN}✅ All context files are up to date${RESET}`);\n  }\n\n  return { staleFiles, missingDateFiles };\n}\n\n// CLI usage\nif (require.main === module) {\n  checkStaleContextFiles();\n}\n\n// Export for use as module\nmodule.exports = { checkStaleContextFiles };\n"
        },
        {
          "path": ".repo/automation/scripts/update-context-verified.js",
          "type": "Node.js",
          "purpose": "Updates last_verified dates in context files",
          "key_functionality": [
            "Updates metrics.last_verified to current date",
            "Can update single file or batch"
          ],
          "used_by": [
            "Maintenance scripts",
            "agents after verifying context"
          ],
          "content": "#!/usr/bin/env node\n// /.repo/automation/scripts/update-context-verified.js\n// Update last_verified date in context files\n// Usage: node update-context-verified.js [context-file...] or --all\n\nconst fs = require('fs');\nconst path = require('path');\n\n// Get repo root\nconst REPO_ROOT = path.resolve(__dirname, '../../..');\n\nfunction findContextFiles(dir, fileList = []) {\n  const files = fs.readdirSync(dir);\n\n  files.forEach(file => {\n    const filePath = path.join(dir, file);\n    const stat = fs.statSync(filePath);\n\n    if (stat.isDirectory() && !file.startsWith('.') && file !== 'node_modules') {\n      findContextFiles(filePath, fileList);\n    } else if (file === '.agent-context.json') {\n      fileList.push(filePath);\n    }\n  });\n\n  return fileList;\n}\n\nfunction updateContextFile(filePath) {\n  try {\n    const content = JSON.parse(fs.readFileSync(filePath, 'utf8'));\n    const today = new Date().toISOString().split('T')[0];\n\n    // Ensure metrics object exists\n    if (!content.metrics) {\n      content.metrics = {};\n    }\n\n    // Update last_verified\n    content.metrics.last_verified = today;\n\n    // Write back\n    fs.writeFileSync(filePath, JSON.stringify(content, null, 2) + '\\n', 'utf8');\n\n    const relativePath = path.relative(REPO_ROOT, filePath);\n    console.log(`✅ Updated ${relativePath}`);\n    return true;\n  } catch (err) {\n    console.error(`❌ Error updating ${filePath}: ${err.message}`);\n    return false;\n  }\n}\n\n// CLI usage\nif (require.main === module) {\n  const args = process.argv.slice(2);\n  const updateAll = args.includes('--all');\n\n  let filesToUpdate = [];\n\n  if (updateAll) {\n    filesToUpdate = findContextFiles(REPO_ROOT);\n  } else if (args.length > 0) {\n    filesToUpdate = args.map(file => {\n      if (path.isAbsolute(file)) {\n        return file;\n      }\n      return path.join(REPO_ROOT, file);\n    }).filter(file => fs.existsSync(file));\n  } else {\n    console.error('Usage: node update-context-verified.js [context-file...] or --all');\n    process.exit(1);\n  }\n\n  if (filesToUpdate.length === 0) {\n    console.error('No context files found to update');\n    process.exit(1);\n  }\n\n  console.log(`Updating last_verified date for ${filesToUpdate.length} file(s)...\\n`);\n\n  let successCount = 0;\n  filesToUpdate.forEach(file => {\n    if (updateContextFile(file)) {\n      successCount++;\n    }\n  });\n\n  console.log(`\\n✅ Updated ${successCount}/${filesToUpdate.length} file(s)`);\n}\n\n// Export for use as module\nmodule.exports = { updateContextFile };\n"
        },
        {
          "path": ".repo/automation/scripts/validate-agent-trace.js",
          "type": "Node.js",
          "purpose": "Validates trace logs against schema",
          "key_functionality": [
            "Validates trace log JSON against AGENT_TRACE_SCHEMA.json",
            "Checks required fields: intent, files, commands, evidence, hitl, unknowns"
          ],
          "dependencies": [
            "AGENT_TRACE_SCHEMA.json"
          ],
          "used_by": [
            "governance-verify.js",
            "generate-trace-log.sh"
          ],
          "referenced_by": [
            "QUALITY_GATES.md (hard gate)"
          ],
          "content": "#!/usr/bin/env node\n// /.repo/automation/scripts/validate-agent-trace.js\n// Validate trace logs against AGENT_TRACE_SCHEMA.json using JSON schema validation\n\nconst fs = require('fs');\nconst path = require('path');\n\n// Colors for output\nconst RED = '\\x1b[31m';\nconst GREEN = '\\x1b[32m';\nconst YELLOW = '\\x1b[33m';\nconst RESET = '\\x1b[0m';\n\nfunction logError(msg) {\n  console.error(`${RED}✗ ${msg}${RESET}`);\n}\n\nfunction logSuccess(msg) {\n  console.log(`${GREEN}✓ ${msg}${RESET}`);\n}\n\nfunction logWarning(msg) {\n  console.warn(`${YELLOW}⚠ ${msg}${RESET}`);\n}\n\nfunction validateTraceLog(traceFile, schemaFile) {\n  // Read files\n  let traceData, schemaData;\n\n  try {\n    traceData = JSON.parse(fs.readFileSync(traceFile, 'utf8'));\n  } catch (e) {\n    logError(`Invalid JSON in trace log: ${traceFile}`);\n    console.error(e.message);\n    return false;\n  }\n\n  try {\n    schemaData = JSON.parse(fs.readFileSync(schemaFile, 'utf8'));\n  } catch (e) {\n    logError(`Invalid JSON in schema: ${schemaFile}`);\n    console.error(e.message);\n    return false;\n  }\n\n  // Check required fields from schema\n  const required = schemaData.required || [];\n  const missing = required.filter(field => !(field in traceData));\n\n  if (missing.length > 0) {\n    logError(`Missing required fields: ${missing.join(', ')}`);\n    return false;\n  }\n\n  // Validate field types\n  const properties = schemaData.properties || {};\n  let valid = true;\n\n  for (const [field, spec] of Object.entries(properties)) {\n    if (!(field in traceData)) continue; // Optional fields\n\n    const value = traceData[field];\n    const expectedType = spec.type;\n\n    if (expectedType === 'array' && !Array.isArray(value)) {\n      logError(`Field '${field}' must be an array`);\n      valid = false;\n    } else if (expectedType === 'string' && typeof value !== 'string') {\n      logError(`Field '${field}' must be a string`);\n      valid = false;\n    } else if (expectedType === 'object' && (typeof value !== 'object' || Array.isArray(value))) {\n      logError(`Field '${field}' must be an object`);\n      valid = false;\n    }\n  }\n\n  if (valid) {\n    logSuccess(`Trace log validation passed: ${traceFile}`);\n    return true;\n  }\n\n  return false;\n}\n\n// Main\nif (require.main === module) {\n  const args = process.argv.slice(2);\n\n  if (args.length < 1) {\n    console.error('Usage: validate-agent-trace.js <trace-log-file> [schema-file]');\n    process.exit(1);\n  }\n\n  const traceFile = path.resolve(args[0]);\n  const schemaFile = args[1] || path.resolve(__dirname, '../../templates/AGENT_TRACE_SCHEMA.json');\n\n  if (!fs.existsSync(traceFile)) {\n    logError(`Trace log file not found: ${traceFile}`);\n    process.exit(1);\n  }\n\n  if (!fs.existsSync(schemaFile)) {\n    logError(`Schema file not found: ${schemaFile}`);\n    process.exit(1);\n  }\n\n  const valid = validateTraceLog(traceFile, schemaFile);\n  process.exit(valid ? 0 : 1);\n}\n\nmodule.exports = { validateTraceLog };\n"
        },
        {
          "path": ".repo/automation/scripts/pattern-verification.js",
          "type": "Node.js",
          "purpose": "Verifies code patterns match context files",
          "used_by": [
            "Governance verification"
          ],
          "content": "#!/usr/bin/env node\n// /.repo/automation/scripts/pattern-verification.js\n// Basic pattern verification - checks if pattern files exist and are referenced\n// Usage: node pattern-verification.js [--warn-only]\n\nconst fs = require('fs');\nconst path = require('path');\n\n// Get repo root\nconst REPO_ROOT = path.resolve(__dirname, '../../..');\nconst WARN_ONLY = process.argv.includes('--warn-only');\n\n// Colors\nconst YELLOW = '\\x1b[33m';\nconst GREEN = '\\x1b[32m';\nconst RESET = '\\x1b[0m';\n\nfunction findPatternFiles(dir, fileList = []) {\n  const files = fs.readdirSync(dir);\n\n  files.forEach(file => {\n    const filePath = path.join(dir, file);\n    const stat = fs.statSync(filePath);\n\n    if (stat.isDirectory() && !file.startsWith('.') && file !== 'node_modules') {\n      findPatternFiles(filePath, fileList);\n    } else if (file === 'PATTERNS.md') {\n      fileList.push(filePath);\n    }\n  });\n\n  return fileList;\n}\n\nfunction checkPatternFiles() {\n  console.log('Checking pattern files...\\n');\n\n  const patternFiles = findPatternFiles(REPO_ROOT);\n  const issues = [];\n\n  patternFiles.forEach(filePath => {\n    const relativePath = path.relative(REPO_ROOT, filePath);\n    const dir = path.dirname(filePath);\n    const dirName = path.basename(dir);\n\n    try {\n      const content = fs.readFileSync(filePath, 'utf8');\n\n      // Check if pattern file has content\n      if (content.trim().length < 100) {\n        issues.push({\n          file: relativePath,\n          issue: 'Pattern file is very short (may be incomplete)'\n        });\n      }\n\n      // Check if corresponding .AGENT.md references it\n      const agentMdPath = path.join(dir, '.AGENT.md');\n      if (fs.existsSync(agentMdPath)) {\n        const agentContent = fs.readFileSync(agentMdPath, 'utf8');\n        if (!agentContent.includes('PATTERNS.md') && !agentContent.includes('patterns')) {\n          issues.push({\n            file: relativePath,\n            issue: 'Pattern file exists but not referenced in .AGENT.md'\n          });\n        }\n      }\n\n      // Check if corresponding .agent-context.json references it\n      const contextPath = path.join(dir, '.agent-context.json');\n      if (fs.existsSync(contextPath)) {\n        const contextContent = JSON.parse(fs.readFileSync(contextPath, 'utf8'));\n        if (!contextContent.patterns || Object.keys(contextContent.patterns).length === 0) {\n          issues.push({\n            file: relativePath,\n            issue: 'Pattern file exists but .agent-context.json has no patterns field'\n          });\n        }\n      }\n    } catch (err) {\n      issues.push({\n        file: relativePath,\n        issue: `Error reading file: ${err.message}`\n      });\n    }\n  });\n\n  if (issues.length > 0) {\n    console.log(`${YELLOW}⚠️  Pattern file issues found:${RESET}`);\n    issues.forEach(issue => {\n      console.log(`   ${issue.file}: ${issue.issue}`);\n    });\n    console.log();\n\n    if (!WARN_ONLY) {\n      process.exit(1);\n    }\n  } else {\n    console.log(`${GREEN}✅ Pattern files are properly configured${RESET}`);\n  }\n\n  return issues;\n}\n\n// CLI usage\nif (require.main === module) {\n  checkPatternFiles();\n}\n\n// Export for use as module\nmodule.exports = { checkPatternFiles };\n"
        },
        {
          "path": ".repo/automation/scripts/generate-agent-context.js",
          "type": "Node.js",
          "purpose": "Generates .agent-context.json from code analysis",
          "used_by": [
            "Context file creation/update"
          ],
          "content": "#!/usr/bin/env node\n// Generate .agent-context.json file for a folder\n// Usage: node generate-agent-context.js <folder_path>\n\nconst fs = require('fs');\nconst path = require('path');\n\nconst folderPath = process.argv[2];\n\nif (!folderPath) {\n  console.error('Usage: node generate-agent-context.js <folder_path>');\n  process.exit(1);\n}\n\nconst schemaPath = path.resolve(__dirname, '../../templates/AGENT_CONTEXT_SCHEMA.json');\nconst template = {\n  \"$schema\": \"../../.repo/templates/AGENT_CONTEXT_SCHEMA.json\",\n  \"version\": \"1.0.0\",\n  \"type\": \"folder_context\",\n  \"folder\": {\n    \"path\": folderPath,\n    \"purpose\": \"TODO: Describe folder purpose\",\n    \"layer\": \"domain\",\n    \"depends_on\": [],\n    \"used_by\": []\n  },\n  \"agent_rules\": {\n    \"can_do\": [],\n    \"cannot_do\": [],\n    \"requires_hitl\": []\n  },\n  \"patterns\": {},\n  \"boundaries\": {\n    \"can_import_from\": [],\n    \"cannot_import_from\": [],\n    \"cross_module_requires_adr\": true\n  },\n  \"quick_links\": {\n    \"guide\": `${folderPath}/.AGENT.md`,\n    \"index\": `${folderPath}/INDEX.md`,\n    \"policy\": \".repo/policy/BOUNDARIES.md\",\n    \"best_practices\": \".repo/policy/BESTPR.md\"\n  },\n  \"common_tasks\": [],\n  \"metrics\": {\n    \"files_count\": 0,\n    \"last_modified\": new Date().toISOString().split('T')[0],\n    \"test_coverage\": 0\n  }\n};\n\nconst outputPath = path.join(folderPath, '.agent-context.json');\nfs.writeFileSync(outputPath, JSON.stringify(template, null, 2));\nconsole.log(`Created ${outputPath}`);\nconsole.log('Please fill in the template with folder-specific information.');\n"
        },
        {
          "path": ".repo/automation/scripts/generate-index-json.js",
          "type": "Node.js",
          "purpose": "Generates index JSON for documentation",
          "used_by": [
            "Documentation generation"
          ],
          "content": "#!/usr/bin/env node\n// Generate INDEX.json file for a folder\n// Usage: node generate-index-json.js <folder_path>\n\nconst fs = require('fs');\nconst path = require('path');\nconst { execSync } = require('child_process');\n\nconst folderPath = process.argv[2] || process.cwd();\n\nif (!fs.existsSync(folderPath)) {\n  console.error(`Folder not found: ${folderPath}`);\n  process.exit(1);\n}\n\nfunction getFileInfo(filePath) {\n  const stats = fs.statSync(filePath);\n  const content = fs.readFileSync(filePath, 'utf8');\n\n  // Try to detect file type and key classes\n  let type = 'unknown';\n  let keyClasses = [];\n\n  if (filePath.endsWith('.py')) {\n    type = 'python';\n    // Extract class definitions\n    const classMatches = content.match(/^class\\s+(\\w+)/gm);\n    if (classMatches) {\n      keyClasses = classMatches.map(m => m.replace(/^class\\s+/, ''));\n    }\n  } else if (filePath.endsWith('.ts') || filePath.endsWith('.tsx')) {\n    type = 'typescript';\n    // Extract class/function exports\n    const exportMatches = content.match(/^export\\s+(?:const|function|class)\\s+(\\w+)/gm);\n    if (exportMatches) {\n      keyClasses = exportMatches.map(m => m.replace(/^export\\s+(?:const|function|class)\\s+/, ''));\n    }\n  } else if (filePath.endsWith('.md')) {\n    type = 'markdown';\n  } else if (filePath.endsWith('.json')) {\n    type = 'json';\n  }\n\n  return {\n    path: path.relative(folderPath, filePath),\n    type,\n    key_classes: keyClasses.slice(0, 10), // Limit to 10\n    line_count: content.split('\\n').length,\n    size_bytes: stats.size\n  };\n}\n\nfunction getSubfolders(dirPath) {\n  const entries = fs.readdirSync(dirPath, { withFileTypes: true });\n  return entries\n    .filter(entry => entry.isDirectory())\n    .filter(entry => !entry.name.startsWith('.') && entry.name !== '__pycache__' && entry.name !== 'node_modules')\n    .map(entry => ({\n      path: entry.name,\n      purpose: 'TODO: Describe subfolder purpose'\n    }));\n}\n\nfunction getDependencies(folderPath) {\n  // Try to detect imports/dependencies\n  const dependencies = {\n    imports: [],\n    imported_by: []\n  };\n\n  // This is a placeholder - could be enhanced with actual import analysis\n  return dependencies;\n}\n\nfunction main() {\n  const index = {\n    folder: folderPath,\n    generated_at: new Date().toISOString(),\n    files: [],\n    subfolders: [],\n    dependencies: getDependencies(folderPath)\n  };\n\n  // Get all files\n  function walkDir(dir, baseDir = dir) {\n    const entries = fs.readdirSync(dir, { withFileTypes: true });\n\n    for (const entry of entries) {\n      const fullPath = path.join(dir, entry.name);\n      const relativePath = path.relative(baseDir, fullPath);\n\n      if (entry.isDirectory()) {\n        if (!entry.name.startsWith('.') && entry.name !== '__pycache__' && entry.name !== 'node_modules') {\n          walkDir(fullPath, baseDir);\n        }\n      } else if (entry.isFile()) {\n        // Skip hidden files and common non-code files\n        if (!entry.name.startsWith('.') &&\n            !entry.name.endsWith('.pyc') &&\n            !entry.name.endsWith('.log')) {\n          try {\n            index.files.push(getFileInfo(fullPath));\n          } catch (e) {\n            // Skip files that can't be read\n          }\n        }\n      }\n    }\n  }\n\n  walkDir(folderPath);\n\n  // Get subfolders\n  index.subfolders = getSubfolders(folderPath);\n\n  // Write index\n  const outputPath = path.join(folderPath, 'INDEX.json');\n  fs.writeFileSync(outputPath, JSON.stringify(index, null, 2));\n\n  console.log(`✅ Generated INDEX.json for ${folderPath}`);\n  console.log(`   Files: ${index.files.length}`);\n  console.log(`   Subfolders: ${index.subfolders.length}`);\n}\n\nmain();\n"
        },
        {
          "path": ".repo/automation/scripts/package.json",
          "type": "JSON",
          "purpose": "Node.js dependencies for automation scripts",
          "dependencies": [
            "ajv (for JSON schema validation)"
          ],
          "used_by": [
            "npm install in .repo/automation/scripts/"
          ],
          "content": "{\n  \"name\": \"repo-automation-scripts\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Automation scripts for repository governance and agent tooling\",\n  \"private\": true,\n  \"scripts\": {\n    \"validate-context\": \"node validate-agent-context.js\",\n    \"validate-trace\": \"node validate-agent-trace.js\",\n    \"governance-verify\": \"node governance-verify.js\",\n    \"generate-metrics\": \"node agent-logger.js metrics\",\n    \"cleanup-logs\": \"node agent-logger.js cleanup\"\n  },\n  \"dependencies\": {\n    \"ajv\": \"^8.12.0\"\n  },\n  \"engines\": {\n    \"node\": \">=14.0.0\"\n  }\n}\n"
        },
        {
          "path": ".repo/automation/scripts/setup-agent-logs.sh",
          "type": "Bash",
          "purpose": "Sets up agent log directories",
          "used_by": [
            "Initial setup"
          ],
          "content": "#!/bin/bash\n# Setup agent interaction logging infrastructure\n# Creates .agent-logs/ directory structure\n\nset -e\n\nREPO_ROOT=\"$(git rev-parse --show-toplevel 2>/dev/null || pwd)\"\nLOGS_DIR=\"${REPO_ROOT}/.agent-logs\"\n\necho \"Setting up agent interaction logging...\"\n\n# Create directory structure\nmkdir -p \"${LOGS_DIR}/interactions\"\nmkdir -p \"${LOGS_DIR}/metrics\"\nmkdir -p \"${LOGS_DIR}/errors\"\n\n# Create README\ncat > \"${LOGS_DIR}/README.md\" << 'EOF'\n# Agent Interaction Logs\n\nThis directory contains logs of agent interactions with the repository.\n\n## Structure\n\n- `interactions/` - Individual interaction logs (JSONL format)\n- `metrics/` - Aggregated metrics (JSON format)\n- `errors/` - Error logs\n\n## Log Format\n\nEach interaction log entry is a JSON object:\n\n```json\n{\n  \"timestamp\": \"2026-01-23T10:30:00Z\",\n  \"agent\": \"Auto\",\n  \"action\": \"read_file\",\n  \"file\": \"backend/modules/clients/models.py\",\n  \"duration_ms\": 45,\n  \"success\": true,\n  \"context\": {\n    \"task\": \"TASK-001\",\n    \"folder\": \"backend/modules/clients\"\n  }\n}\n```\n\n## Metrics\n\nMetrics are aggregated daily and stored in `metrics/` directory.\n\n## Privacy\n\nLogs may contain file paths and action types but should not contain:\n- Code content\n- Secrets or credentials\n- Personal information\n\nEOF\n\necho \"✅ Agent logging infrastructure created at ${LOGS_DIR}\"\necho \"📁 Directory structure:\"\ntree -L 2 \"${LOGS_DIR}\" || find \"${LOGS_DIR}\" -type d | head -10\n"
        },
        {
          "path": ".repo/automation/scripts/SETUP_INSTRUCTIONS.md",
          "type": "Markdown",
          "purpose": "Setup instructions for automation scripts",
          "used_by": [
            "Initial setup"
          ],
          "content": "# Setup Instructions\n\n**File**: `.repo/automation/scripts/SETUP_INSTRUCTIONS.md`\n\n## Quick Start\n\nSince Node.js is not available in all environments, follow these steps when Node.js is available:\n\n### Step 1: Install Node.js (if not installed)\n\n1. Download from: https://nodejs.org/\n2. Install (recommended: LTS version)\n3. Verify: `node --version` (should show v14+)\n4. Verify: `npm --version`\n\n### Step 2: Install Dependencies\n\n```bash\ncd .repo/automation/scripts\nnpm install\n```\n\nThis installs:\n- `ajv` (^8.12.0) - JSON schema validator\n\n**Expected output:**\n```\nadded 1 package, and audited 2 packages in 2s\n```\n\n### Step 3: Update Context Files\n\n```bash\n# Update all context files with last_verified date\nnode update-context-verified.js --all\n```\n\n**Expected output:**\n```\nUpdating last_verified date for 11 file(s)...\n\n✅ Updated backend/.agent-context.json\n✅ Updated frontend/.agent-context.json\n✅ Updated backend/modules/clients/.agent-context.json\n... (and so on)\n\n✅ Updated 11/11 file(s)\n```\n\n### Step 4: Verify Scripts Work\n\n```bash\n# Test logging SDK\nnode agent-logger.js metrics\n\n# Test stale context detection\nnode check-stale-context.js --warn-only\n\n# Test pattern verification\nnode pattern-verification.js --warn-only\n\n# Test validation\nnode validate-agent-context.js ../../backend/.agent-context.json\n```\n\n## Manual Alternative\n\nIf Node.js is not available, you can manually update context files:\n\n1. Open each `.agent-context.json` file\n2. Find the `metrics` section\n3. Add `\"last_verified\": \"2026-01-23\"` (use today's date)\n4. Save the file\n\nExample:\n```json\n\"metrics\": {\n  \"files_count\": 500,\n  \"last_modified\": \"2026-01-23\",\n  \"last_verified\": \"2026-01-23\",  // Add this line\n  \"test_coverage\": 0.82\n}\n```\n\n## Files That Need Updating\n\nAll `.agent-context.json` files should have `last_verified` in their `metrics` section:\n\n- `backend/.agent-context.json` ✅ (already updated)\n- `frontend/.agent-context.json`\n- `backend/modules/clients/.agent-context.json`\n- `backend/modules/finance/.agent-context.json`\n- `backend/modules/core/.agent-context.json`\n- `backend/modules/firm/.agent-context.json`\n- `backend/modules/crm/.agent-context.json`\n- `backend/modules/projects/.agent-context.json`\n- `backend/api/clients/.agent-context.json`\n- `frontend/src/api/.agent-context.json`\n- `frontend/src/components/.agent-context.json`\n\n## Verification\n\nAfter setup, verify:\n\n1. ✅ `node_modules/` directory exists in `.repo/automation/scripts/`\n2. ✅ `package-lock.json` exists\n3. ✅ All context files have `last_verified` field\n4. ✅ Scripts can be executed without errors\n\n## Troubleshooting\n\nSee `.repo/automation/scripts/VERIFICATION.md` for detailed troubleshooting.\n\n---\n\n**Created:** 2026-01-23\n"
        },
        {
          "path": ".repo/automation/scripts/STATUS.md",
          "type": "Markdown",
          "purpose": "Status of automation scripts",
          "used_by": [
            "Maintenance"
          ],
          "content": "# Script Setup Status\n\n**Date:** 2026-01-23\n**Status:** Files Ready - Node.js Required for Execution\n\n---\n\n## ✅ Completed\n\n1. **All Scripts Created:**\n   - ✅ `agent-logger.js` - Logging SDK\n   - ✅ `check-boundaries.js` - Boundary checker\n   - ✅ `check-stale-context.js` - Stale context detector\n   - ✅ `update-context-verified.js` - Context file updater\n   - ✅ `pattern-verification.js` - Pattern verifier\n   - ✅ `validate-agent-context.js` - Enhanced validation\n   - ✅ `governance-verify.js` - Enhanced with new checks\n\n2. **Configuration Files:**\n   - ✅ `package.json` - Node.js dependencies defined\n   - ✅ Schema updated with `last_verified` field\n\n3. **Documentation:**\n   - ✅ `SETUP_INSTRUCTIONS.md` - Step-by-step setup guide\n   - ✅ `VERIFICATION.md` - Testing and verification guide\n   - ✅ `STATUS.md` - This file\n\n4. **Sample Updates:**\n   - ✅ `backend/.agent-context.json` - Updated with `last_verified` field as example\n\n---\n\n## ⚠️ Requires Node.js\n\nThe following steps require Node.js to be installed:\n\n### Step 1: Install Dependencies\n```bash\ncd .repo/automation/scripts\nnpm install\n```\n\n### Step 2: Update All Context Files\n```bash\nnode update-context-verified.js --all\n```\n\nThis will update all 11 `.agent-context.json` files with the `last_verified` date.\n\n### Step 3: Test Scripts\n```bash\n# Test logging\nnode agent-logger.js metrics\n\n# Test stale detection\nnode check-stale-context.js --warn-only\n\n# Test pattern verification\nnode pattern-verification.js --warn-only\n\n# Test validation\nnode validate-agent-context.js ../../backend/.agent-context.json\n```\n\n---\n\n## 📋 Manual Alternative\n\nIf Node.js is not available, you can manually update context files:\n\n1. Open each `.agent-context.json` file (11 total)\n2. Find the `metrics` section\n3. Add: `\"last_verified\": \"2026-01-23\"` (use today's date)\n4. Save\n\n**Files to update:**\n- `backend/.agent-context.json` ✅ (already done as example)\n- `frontend/.agent-context.json`\n- `backend/modules/clients/.agent-context.json`\n- `backend/modules/finance/.agent-context.json`\n- `backend/modules/core/.agent-context.json`\n- `backend/modules/firm/.agent-context.json`\n- `backend/modules/crm/.agent-context.json`\n- `backend/modules/projects/.agent-context.json`\n- `backend/api/clients/.agent-context.json`\n- `frontend/src/api/.agent-context.json`\n- `frontend/src/components/.agent-context.json`\n\n---\n\n## ✅ Verification Checklist\n\nWhen Node.js is available, verify:\n\n- [ ] `npm install` completes successfully\n- [ ] `node_modules/` directory exists\n- [ ] `package-lock.json` exists\n- [ ] All context files have `last_verified` field\n- [ ] Scripts execute without errors\n- [ ] Logging SDK generates metrics\n- [ ] Validation scripts work correctly\n\n---\n\n## 📚 Documentation\n\n- **Setup:** See `SETUP_INSTRUCTIONS.md`\n- **Verification:** See `VERIFICATION.md`\n- **Troubleshooting:** See `.repo/docs/TROUBLESHOOTING.md`\n\n---\n\n**Note:** All scripts are ready and will work once Node.js is installed and dependencies are installed.\n"
        },
        {
          "path": ".repo/automation/scripts/VERIFICATION.md",
          "type": "Markdown",
          "purpose": "Verification documentation",
          "used_by": [
            "Testing"
          ],
          "content": "# Script Verification Guide\n\n**File**: `.repo/automation/scripts/VERIFICATION.md`\n\nThis guide helps verify that all scripts are working correctly.\n\n## Prerequisites\n\n1. **Node.js installed** (v14 or higher)\n   - Check: `node --version`\n   - Install: https://nodejs.org/\n\n2. **Dependencies installed**\n   ```bash\n   cd .repo/automation/scripts\n   npm install\n   ```\n\n## Verification Steps\n\n### 1. Install Dependencies\n\n```bash\ncd .repo/automation/scripts\nnpm install\n```\n\n**Expected output:**\n- `ajv` package installed in `node_modules/`\n- `package-lock.json` created/updated\n\n### 2. Update Context Files\n\n```bash\nnode update-context-verified.js --all\n```\n\n**Expected output:**\n- All `.agent-context.json` files updated with `last_verified` date\n- Success message for each file\n\n**Manual verification:**\n- Check that `metrics.last_verified` field exists in context files\n- Date should be today's date (YYYY-MM-DD format)\n\n### 3. Test Logging SDK\n\n```bash\n# Generate metrics for today\nnode agent-logger.js metrics\n\n# Generate metrics for specific date\nnode agent-logger.js metrics 2026-01-23\n\n# Cleanup old logs (keep last 30 days)\nnode agent-logger.js cleanup 30\n```\n\n**Expected output:**\n- Metrics JSON printed to console\n- Metrics file created in `.agent-logs/metrics/`\n\n### 4. Test Stale Context Detection\n\n```bash\n# Check for stale files (warn only)\nnode check-stale-context.js --warn-only\n\n# Check for stale files (fail on stale)\nnode check-stale-context.js --threshold-days=30\n```\n\n**Expected output:**\n- List of stale files (if any)\n- Warning messages for files missing `last_verified`\n- Success message if all files are up to date\n\n### 5. Test Pattern Verification\n\n```bash\n# Check pattern files (warn only)\nnode pattern-verification.js --warn-only\n\n# Check pattern files (fail on issues)\nnode pattern-verification.js\n```\n\n**Expected output:**\n- List of pattern file issues (if any)\n- Success message if all patterns are properly configured\n\n### 6. Test Context Validation\n\n```bash\n# Basic validation\nnode validate-agent-context.js ../../backend/.agent-context.json\n\n# With file path checking\nnode validate-agent-context.js ../../backend/.agent-context.json --check-files\n\n# With all checks\nnode validate-agent-context.js ../../backend/.agent-context.json --check-files --check-boundaries --check-links\n```\n\n**Expected output:**\n- Validation success message\n- Warnings for non-critical issues (if any)\n- Errors for critical issues (if any)\n\n### 7. Test Boundary Checking\n\n```bash\n# Check boundaries (requires import-linter)\nnode check-boundaries.js --fail-on-violations\n```\n\n**Expected output:**\n- Boundary check results\n- List of violations (if any)\n- Success message if no violations\n\n**Note:** Requires `import-linter` to be installed:\n```bash\npip install import-linter==2.0\n```\n\n## Troubleshooting\n\n### Node.js Not Found\n\n**Error:** `node: command not found`\n\n**Solution:**\n1. Install Node.js from https://nodejs.org/\n2. Restart terminal/IDE\n3. Verify: `node --version`\n\n### npm Install Fails\n\n**Error:** `npm ERR!` messages\n\n**Solutions:**\n1. Check internet connection\n2. Clear npm cache: `npm cache clean --force`\n3. Try: `npm install --legacy-peer-deps`\n\n### Scripts Fail with Module Errors\n\n**Error:** `Cannot find module 'ajv'`\n\n**Solution:**\n```bash\ncd .repo/automation/scripts\nnpm install\n```\n\n### Permission Errors\n\n**Error:** `EACCES: permission denied`\n\n**Solution:**\n- On Linux/Mac: Use `sudo` (if needed) or fix permissions\n- On Windows: Run as Administrator or fix folder permissions\n\n## Manual Verification Checklist\n\nIf scripts can't run, verify manually:\n\n- [ ] `package.json` exists in `.repo/automation/scripts/`\n- [ ] All `.js` script files exist and are executable\n- [ ] Context files have `metrics.last_verified` field (can add manually)\n- [ ] Pattern files exist and are referenced in `.AGENT.md` files\n- [ ] Scripts have proper shebang (`#!/usr/bin/env node`)\n\n## Success Criteria\n\nAll scripts are working correctly if:\n- ✅ Dependencies install without errors\n- ✅ Context files can be updated\n- ✅ Logging SDK generates metrics\n- ✅ Validation scripts run and report correctly\n- ✅ No critical errors in script execution\n\n---\n\n**Last updated:** 2026-01-23\n"
        },
        {
          "path": ".repo/automation/ci/governance-verify.yml",
          "type": "YAML (GitHub Actions template)",
          "purpose": "CI workflow template for governance verification",
          "status": "Template (needs integration into .github/workflows/)",
          "used_by": [
            "CI integration (when integrated)"
          ],
          "content": "# /.repo/automation/ci/governance-verify.yml\n# Template CI job calling manifest-defined command.\njobs:\n  governance_verify:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: Install deps\n        run: <FILL_FROM_REPO_INSTALL>\n      - name: Governance Verify\n        run: <FILL_FROM_REPO_GOVERNANCE>\n"
        },
        {
          "path": ".repo/automation/README.md",
          "type": "Markdown",
          "purpose": "Automation directory documentation",
          "used_by": [
            "Understanding automation structure"
          ],
          "content": "# Automation Scripts\n\n**File**: `.repo/automation/README.md`\n\nThis directory contains automation scripts for governance verification and validation.\n\n## Script Naming Convention\n\n### Canonical Scripts (Used in CI/Manifest)\n\n- **`scripts/governance-verify.sh`** - Canonical governance verification script (used in CI)\n  - Referenced in `.repo/repo.manifest.yaml` as `check:governance`\n  - Used in `.github/workflows/ci.yml` governance job\n  - Exit codes: 0=pass, 1=hard failure, 2=waiverable failure\n\n### Alternative Implementations\n\n- **`.repo/automation/scripts/governance-verify.js`** - Node.js version (alternative)\n  - Same functionality as bash version\n  - Can be used if Node.js is preferred\n  - Not currently used in CI (bash version is canonical)\n\n### Validation Scripts\n\n- **`scripts/validate-trace-log.sh`** - Validates trace logs (bash)\n- **`.repo/automation/scripts/validate-agent-trace.js`** - Validates trace logs (Node.js)\n  - Both validate against `.repo/templates/AGENT_TRACE_SCHEMA.json`\n  - Use either one based on preference\n\n## Directory Structure\n\n```\n.repo/automation/\n├── README.md                    # This file\n├── scripts/\n│   ├── agent-logger.js          # Agent interaction logging SDK\n│   ├── governance-verify.js     # Node.js governance verification\n│   ├── validate-agent-context.js # Context file validation (with JSON schema)\n│   ├── validate-agent-trace.js  # Node.js trace log validation\n│   └── package.json              # Node.js dependencies (ajv for schema validation)\n└── ci/\n    └── governance-verify.yml    # CI template (not used, CI uses .github/workflows/ci.yml)\n```\n\n## Usage\n\n### Governance Verification\n\n```bash\n# Canonical (bash) - used in CI\n./scripts/governance-verify.sh\n\n# Alternative (Node.js)\nnode .repo/automation/scripts/governance-verify.js\n```\n\n### Trace Log Validation\n\n```bash\n# Bash version\n./scripts/validate-trace-log.sh .repo/traces/TASK-001-trace-20260123-120000.json\n\n# Node.js version\nnode .repo/automation/scripts/validate-agent-trace.js .repo/traces/TASK-001-trace-20260123-120000.json\n```\n\n## Setup\n\n### Node.js Dependencies\n\nFor scripts that use JSON schema validation (e.g., `validate-agent-context.js`), install dependencies:\n\n```bash\ncd .repo/automation/scripts\nnpm install\n```\n\nThis installs `ajv` for JSON schema validation. If `ajv` is not installed, validation falls back to basic checks.\n\n## Agent Interaction Logging\n\nThe `agent-logger.js` module provides logging SDK for agent interactions:\n\n```javascript\nconst logger = require('.repo/automation/scripts/agent-logger.js');\n\n// Log an interaction\nlogger.logInteraction({\n  agent: 'Auto',\n  action: 'read_file',\n  file: 'backend/models.py',\n  duration_ms: 45,\n  success: true,\n  context: { task: 'TASK-001' }\n});\n\n// Log an error\nlogger.logError({\n  agent: 'Auto',\n  action: 'read_file',\n  error: 'File not found',\n  context: { file: 'missing.txt' }\n});\n\n// Generate daily metrics\nlogger.writeMetrics(); // Generates metrics for today\nlogger.writeMetrics('2026-01-23'); // Generate for specific date\n\n// Cleanup old logs (keep last 30 days)\nlogger.cleanupOldLogs(30);\n```\n\nLogs are written to:\n- `.agent-logs/interactions/` - Individual interaction logs (JSONL)\n- `.agent-logs/errors/` - Error logs (JSONL)\n- `.agent-logs/metrics/` - Daily aggregated metrics (JSON)\n\n## Context File Validation\n\nThe `validate-agent-context.js` script validates `.agent-context.json` files:\n\n```bash\n# Basic validation (schema + required fields)\nnode .repo/automation/scripts/validate-agent-context.js path/to/.agent-context.json\n\n# With file path checking\nnode .repo/automation/scripts/validate-agent-context.js path/to/.agent-context.json --check-files\n\n# With boundary validation\nnode .repo/automation/scripts/validate-agent-context.js path/to/.agent-context.json --check-boundaries\n\n# With link validation\nnode .repo/automation/scripts/validate-agent-context.js path/to/.agent-context.json --check-links\n\n# All checks\nnode .repo/automation/scripts/validate-agent-context.js path/to/.agent-context.json --check-files --check-boundaries --check-links\n```\n\n## Additional Scripts\n\n### Context File Management\n\n**Check for stale context files:**\n```bash\nnode .repo/automation/scripts/check-stale-context.js [--threshold-days=30] [--warn-only]\n```\n\n**Update last_verified dates:**\n```bash\n# Update specific files\nnode .repo/automation/scripts/update-context-verified.js path/to/.agent-context.json\n\n# Update all context files\nnode .repo/automation/scripts/update-context-verified.js --all\n```\n\n### Pattern Verification\n\n**Check pattern files:**\n```bash\nnode .repo/automation/scripts/pattern-verification.js [--warn-only]\n```\n\nVerifies that pattern files exist, are referenced in `.AGENT.md` files, and have corresponding entries in `.agent-context.json`.\n\n### Boundary Checking\n\n**Check module boundaries:**\n```bash\nnode .repo/automation/scripts/check-boundaries.js [--fail-on-violations]\n```\n\nWraps `lint-imports` for easier use. Can be integrated into CI or run manually.\n\n## Troubleshooting\n\nFor help with script failures and recovery procedures, see `.repo/docs/TROUBLESHOOTING.md`.\n\n## Notes\n\n- Bash scripts are the canonical implementation (used in CI)\n- Node.js scripts are provided as alternatives\n- Both implementations should produce equivalent results\n- If you add new scripts, prefer bash for consistency with existing scripts\n- Logging SDK is Node.js only (no bash equivalent needed)\n- All scripts include error handling and graceful degradation\n"
        }
      ]
    },
    "shell_scripts": {
      "description": "Shell scripts and Python scripts",
      "files": [
        {
          "path": "scripts/governance-verify.sh",
          "type": "Bash",
          "lines": 309,
          "purpose": "Governance verification script (bash version)",
          "key_functionality": [
            "Same functionality as governance-verify.js (bash implementation)",
            "Checks policy files, manifest, HITL, structure, artifacts, boundaries",
            "Exit codes: 0 = pass, 1 = hard failure, 2 = waiverable failure"
          ],
          "used_by": [
            "Makefile (check-governance target)",
            "CI workflows"
          ],
          "referenced_by": [
            "repo.manifest.yaml (check:governance)"
          ],
          "content": "#!/bin/bash\n# governance-verify.sh\n# Enforces quality gates per .repo/policy/QUALITY_GATES.md\n#\n# Exit codes:\n#   0 = pass (all checks pass)\n#   1 = fail (hard gate failure - blocks merge)\n#   2 = waiverable failure (requires waiver)\n\nset -euo pipefail\n\nREPO_ROOT=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)\"\ncd \"$REPO_ROOT\"\n\nERRORS=0\nWARNINGS=0\nHARD_FAILURES=()\n\n# Colors for output\nRED='\\033[0;31m'\nYELLOW='\\033[1;33m'\nGREEN='\\033[0;32m'\nNC='\\033[0m' # No Color\n\nlog_error() {\n    echo -e \"${RED}❌ ERROR:${NC} $1\" >&2\n    ERRORS=$((ERRORS + 1))\n    HARD_FAILURES+=(\"$1\")\n}\n\nlog_warning() {\n    echo -e \"${YELLOW}⚠️  WARNING:${NC} $1\" >&2\n    WARNINGS=$((WARNINGS + 1))\n}\n\nlog_info() {\n    echo -e \"${GREEN}ℹ️  INFO:${NC} $1\"\n}\n\nlog_success() {\n    echo -e \"${GREEN}✅${NC} $1\"\n}\n\n# Check 1: Required policy files exist\nlog_info \"Checking required policy files...\"\nREQUIRED_POLICY_FILES=(\n    \".repo/policy/CONSTITUTION.md\"\n    \".repo/policy/PRINCIPLES.md\"\n    \".repo/policy/QUALITY_GATES.md\"\n    \".repo/policy/SECURITY_BASELINE.md\"\n    \".repo/policy/HITL.md\"\n    \".repo/policy/BOUNDARIES.md\"\n)\n\nfor file in \"${REQUIRED_POLICY_FILES[@]}\"; do\n    if [[ ! -f \"$file\" ]]; then\n        log_error \"Required policy file missing: $file\"\n    else\n        log_success \"Policy file exists: $file\"\n    fi\ndone\n\n# Check 2: Manifest exists\nlog_info \"Checking repository manifest...\"\nif [[ ! -f \".repo/repo.manifest.yaml\" ]]; then\n    log_error \"Repository manifest missing: .repo/repo.manifest.yaml\"\nelse\n    log_success \"Manifest exists: .repo/repo.manifest.yaml\"\n    # Check for UNKNOWN placeholders (hard failure)\n    if grep -q \"<UNKNOWN>\" \".repo/repo.manifest.yaml\"; then\n        log_error \"Manifest contains <UNKNOWN> placeholders (must be resolved via HITL)\"\n    fi\nfi\n\n# Check 3: HITL items status (if HITL.md exists)\nlog_info \"Checking HITL items status...\"\nif [[ -f \".repo/policy/HITL.md\" ]]; then\n    # Check if there are any active HITL items that are not Completed\n    # This is a simplified check - in practice, you'd parse the HITL.md table\n    # For now, we just verify the file exists and is readable\n    if grep -q \"|.*Pending\\|.*In Progress\\|.*Blocked\" \".repo/policy/HITL.md\" 2>/dev/null; then\n        log_warning \"Active HITL items found that are not Completed (check .repo/policy/HITL.md)\"\n    else\n        log_success \"No blocking HITL items found\"\n    fi\nelse\n    log_warning \"HITL index file not found: .repo/policy/HITL.md\"\nfi\n\n# Check 4: Repository structure compliance\nlog_info \"Checking repository structure...\"\nREQUIRED_DIRS=(\n    \".repo\"\n    \".repo/policy\"\n    \".repo/hitl\"\n    \"backend\"\n    \"frontend\"\n)\n\nfor dir in \"${REQUIRED_DIRS[@]}\"; do\n    if [[ ! -d \"$dir\" ]]; then\n        log_error \"Required directory missing: $dir\"\n    else\n        log_success \"Directory exists: $dir\"\n    fi\ndone\n\n# Check 5: Trace log schema validation\nlog_info \"Checking trace log schema...\"\nTRACE_SCHEMA=\".repo/templates/AGENT_TRACE_SCHEMA.json\"\nif [[ -f \"$TRACE_SCHEMA\" ]]; then\n    log_success \"Trace log schema exists: $TRACE_SCHEMA\"\n\n    # Check if Python is available for JSON schema validation\n    if command -v python3 &> /dev/null; then\n        # Validate schema itself is valid JSON\n        if python3 -m json.tool \"$TRACE_SCHEMA\" > /dev/null 2>&1; then\n            log_success \"Trace log schema is valid JSON\"\n        else\n            log_error \"Trace log schema is not valid JSON: $TRACE_SCHEMA\"\n        fi\n    fi\nelse\n    log_warning \"Trace log schema not found: $TRACE_SCHEMA (optional, but recommended)\"\nfi\n\n# Check 6: Trace log validation (if trace logs exist in current changes)\nlog_info \"Checking for trace logs in recent changes...\"\nTRACE_DIR=\".repo/traces\"\nif [[ -d \"$TRACE_DIR\" ]]; then\n    log_success \"Trace log directory exists: $TRACE_DIR\"\n\n    # Check for trace logs in git changes\n    if command -v git &> /dev/null && git rev-parse --git-dir > /dev/null 2>&1; then\n        # Check for trace log files in staged/unstaged changes\n        TRACE_LOGS=$(git diff --name-only --cached HEAD 2>/dev/null | grep -E \"\\.repo/traces/.*\\.json$\" || true)\n        TRACE_LOGS=\"$TRACE_LOGS $(git diff --name-only HEAD 2>/dev/null | grep -E \"\\.repo/traces/.*\\.json$\" || true)\"\n\n        # Also check for trace logs in the directory\n        if [[ -n \"$(find \"$TRACE_DIR\" -name \"*.json\" 2>/dev/null)\" ]]; then\n            TRACE_LOGS=\"$TRACE_LOGS $(find \"$TRACE_DIR\" -name \"*.json\" -type f)\"\n        fi\n\n        if [[ -n \"$TRACE_LOGS\" ]] && [[ -f \"$TRACE_SCHEMA\" ]] && command -v python3 &> /dev/null; then\n            # Use validate-trace-log.sh if available, otherwise basic validation\n            VALIDATOR=\"scripts/validate-trace-log.sh\"\n            for trace_file in $TRACE_LOGS; do\n                if [[ -f \"$trace_file\" ]]; then\n                    if [[ -f \"$VALIDATOR\" ]] && [[ -x \"$VALIDATOR\" ]]; then\n                        if \"$VALIDATOR\" \"$trace_file\" > /dev/null 2>&1; then\n                            log_success \"Trace log validated: $trace_file\"\n                        else\n                            log_warning \"Trace log validation failed: $trace_file (run: $VALIDATOR $trace_file)\"\n                        fi\n                    else\n                        # Basic validation fallback\n                        if python3 -m json.tool \"$trace_file\" > /dev/null 2>&1; then\n                            # Check for required fields\n                            if grep -q '\"intent\"' \"$trace_file\" && \\\n                               grep -q '\"files\"' \"$trace_file\" && \\\n                               grep -q '\"commands\"' \"$trace_file\" && \\\n                               grep -q '\"evidence\"' \"$trace_file\" && \\\n                               grep -q '\"hitl\"' \"$trace_file\" && \\\n                               grep -q '\"unknowns\"' \"$trace_file\"; then\n                                log_success \"Trace log is valid: $trace_file\"\n                            else\n                                log_warning \"Trace log missing required fields: $trace_file\"\n                            fi\n                        else\n                            log_warning \"Trace log is not valid JSON: $trace_file\"\n                        fi\n                    fi\n                fi\n            done\n        fi\n    fi\nelse\n    log_warning \"Trace log directory not found: $TRACE_DIR (create with: mkdir -p $TRACE_DIR)\"\nfi\n\n# Check 7: HITL items detailed parsing\nlog_info \"Parsing HITL items status...\"\nif [[ -f \".repo/policy/HITL.md\" ]]; then\n    # Extract active HITL items from the table\n    # Look for table rows with Status that's not \"Completed\" or \"Superseded\"\n    BLOCKING_HITL=$(grep -E \"^\\|.*\\|.*\\|.*\\|.*\\|\" \".repo/policy/HITL.md\" | \\\n        grep -v \"^\\|.*ID\\|\" | \\\n        grep -v \"^\\|.*---\\|\" | \\\n        awk -F'|' '{print $2, $4}' | \\\n        grep -vE \"Completed|Superseded\" | \\\n        awk '{print $1}' | \\\n        tr -d ' ' || true)\n\n    if [[ -n \"$BLOCKING_HITL\" ]]; then\n        log_warning \"Active HITL items found (not Completed): $BLOCKING_HITL\"\n        log_warning \"  → Check .repo/policy/HITL.md for details\"\n        log_warning \"  → PR merge may be blocked until HITL items are Completed\"\n    else\n        log_success \"No blocking HITL items found\"\n    fi\n\n    # Check for HITL item files\n    HITL_ITEM_COUNT=$(find .repo/hitl -name \"HITL-*.md\" 2>/dev/null | wc -l || echo \"0\")\n    if [[ \"$HITL_ITEM_COUNT\" -gt 0 ]]; then\n        log_info \"Found $HITL_ITEM_COUNT HITL item file(s) in .repo/hitl/\"\n    fi\nfi\n\n# Check 8: Required artifacts for change types (basic check)\nlog_info \"Checking for required artifacts...\"\n# This is a simplified check - in practice, you'd parse PR description or git commit messages\n# to determine change type and check for corresponding artifacts\nif command -v git &> /dev/null && git rev-parse --git-dir > /dev/null 2>&1; then\n    # Check if there are any ADR triggers in changed files\n    CHANGED_FILES=$(git diff --name-only HEAD 2>/dev/null | head -20 || true)\n    if echo \"$CHANGED_FILES\" | grep -qE \"(api/|modules/)\" && \\\n       ! find docs/adr -name \"ADR-*.md\" -newer \"$(git merge-base HEAD origin/main 2>/dev/null || echo \"HEAD~10\")\" 2>/dev/null | grep -q .; then\n        log_warning \"API/module changes detected but no recent ADR found (cross-feature imports may require ADR per Principle 23)\"\n    fi\nfi\n\n# Check 9: Boundary checker configuration\nlog_info \"Checking boundary checker configuration...\"\nif [[ -f \".importlinter\" ]]; then\n    log_success \"Import linter config exists: .importlinter\"\n    if command -v lint-imports &> /dev/null || command -v import-linter &> /dev/null; then\n        log_success \"Boundary checker tool available\"\n    else\n        log_warning \"Boundary checker tool not found (install: pip install import-linter)\"\n    fi\nelse\n    log_warning \"Import linter config not found: .importlinter (boundary checking may not work)\"\nfi\n\n# Check 10: Governance-verify script itself is executable\nif [[ ! -x \"scripts/governance-verify.sh\" ]]; then\n    log_warning \"governance-verify.sh is not executable (chmod +x scripts/governance-verify.sh)\"\nfi\n\n# Check 11: Trace log directory exists\nlog_info \"Checking trace log directory...\"\nif [[ -d \".repo/traces\" ]]; then\n    log_success \"Trace log directory exists: .repo/traces\"\nelse\n    log_warning \"Trace log directory missing: .repo/traces (create with: mkdir -p .repo/traces)\"\nfi\n\n# Check 12: Validate task format (if task files exist)\nlog_info \"Checking task format...\"\nTASK_VALIDATOR=\"scripts/validate-task-format.sh\"\nif [[ -f \"$TASK_VALIDATOR\" ]] && [[ -x \"$TASK_VALIDATOR\" ]]; then\n    for task_file in \".repo/tasks/TODO.md\" \".repo/tasks/BACKLOG.md\"; do\n        if [[ -f \"$task_file\" ]]; then\n            if \"$TASK_VALIDATOR\" \"$task_file\" > /dev/null 2>&1; then\n                log_success \"Task format valid: $task_file\"\n            else\n                log_warning \"Task format issues in: $task_file (run: $TASK_VALIDATOR $task_file)\"\n            fi\n        fi\n    done\nfi\n\n# Check 13: ADR trigger detection\nlog_info \"Checking for ADR triggers...\"\nADR_DETECTOR=\"scripts/detect-adr-triggers.sh\"\nif [[ -f \"$ADR_DETECTOR\" ]] && [[ -x \"$ADR_DETECTOR\" ]] && command -v git &> /dev/null && git rev-parse --git-dir > /dev/null 2>&1; then\n    if \"$ADR_DETECTOR\" > /dev/null 2>&1; then\n        log_success \"No ADR triggers detected\"\n    else\n        log_warning \"ADR may be required (run: $ADR_DETECTOR for details)\"\n    fi\nfi\n\n# Check 14: Expired waivers\nlog_info \"Checking for expired waivers...\"\nWAIVER_CHECKER=\"scripts/check-expired-waivers.sh\"\nif [[ -f \"$WAIVER_CHECKER\" ]] && [[ -x \"$WAIVER_CHECKER\" ]]; then\n    if \"$WAIVER_CHECKER\" > /dev/null 2>&1; then\n        log_success \"No expired waivers found\"\n    else\n        log_warning \"Expired waivers detected (run: $WAIVER_CHECKER for details)\"\n    fi\nfi\n\n# Summary\necho \"\"\necho \"==========================================\"\necho \"Governance Verification Summary\"\necho \"==========================================\"\necho \"Errors (hard failures): $ERRORS\"\necho \"Warnings (waiverable): $WARNINGS\"\necho \"\"\n\nif [[ $ERRORS -gt 0 ]]; then\n    echo \"Hard failures (blocks merge):\"\n    for failure in \"${HARD_FAILURES[@]}\"; do\n        echo \"  - $failure\"\n    done\n    echo \"\"\n    echo \"❌ Governance verification FAILED (hard gate)\"\n    exit 1\nelif [[ $WARNINGS -gt 0 ]]; then\n    echo \"⚠️  Governance verification passed with warnings (may require waiver)\"\n    exit 2\nelse\n    echo \"✅ Governance verification PASSED\"\n    exit 0\nfi\n"
        },
        {
          "path": "scripts/archive-task.py",
          "type": "Python 3",
          "lines": 291,
          "purpose": "Archives completed task and promotes next task",
          "key_functionality": [
            "Reads current task from TODO.md",
            "Checks if all acceptance criteria are complete",
            "Moves task to ARCHIVE.md (prepends)",
            "Promotes next task from BACKLOG.md to TODO.md",
            "Updates archive statistics",
            "Option: --force (archive even if incomplete)"
          ],
          "dependencies": [
            "Python 3",
            "re",
            "sys",
            "pathlib",
            "datetime"
          ],
          "used_by": [
            "Task completion workflow",
            "CI workflows (if integrated)"
          ],
          "referenced_by": [
            "TODO.md workflow instructions"
          ],
          "content": "#!/usr/bin/env python3\n\"\"\"\nArchive completed task from TODO.md to ARCHIVE.md.\n\nThis script:\n1. Reads the current task from .repo/tasks/TODO.md\n2. Checks if all acceptance criteria are marked complete\n3. Moves task to .repo/tasks/ARCHIVE.md (prepends)\n4. Promotes next task from BACKLOG.md to TODO.md\n\nUsage:\n    python scripts/archive-task.py [--force]\n\n    --force: Archive even if not all criteria are complete\n\"\"\"\n\nimport re\nimport sys\nfrom pathlib import Path\nfrom typing import Dict, List, Optional\nfrom datetime import datetime\n\nREPO_ROOT = Path(__file__).parent.parent\nTODO_FILE = REPO_ROOT / \".repo\" / \"tasks\" / \"TODO.md\"\nBACKLOG_FILE = REPO_ROOT / \".repo\" / \"tasks\" / \"BACKLOG.md\"\nARCHIVE_FILE = REPO_ROOT / \".repo\" / \"tasks\" / \"ARCHIVE.md\"\n\n\ndef parse_task(content: str) -> Optional[Dict]:\n    \"\"\"Parse task from markdown content.\"\"\"\n    lines = content.split('\\n')\n    task = {\n        'header': '',\n        'metadata': {},\n        'acceptance_criteria': [],\n        'notes': [],\n        'raw': content\n    }\n\n    in_criteria = False\n    in_notes = False\n    criteria_start = None\n\n    for i, line in enumerate(lines):\n        # Task header\n        if line.startswith('### [TASK-'):\n            task['header'] = line\n            continue\n\n        # Metadata\n        if line.startswith('- **'):\n            match = re.match(r'- \\*\\*([^:]+):\\*\\*\\s*(.+)', line)\n            if match:\n                key = match.group(1).lower().replace(' ', '_')\n                task['metadata'][key] = match.group(2).strip()\n            continue\n\n        # Acceptance criteria section\n        if '#### Acceptance Criteria' in line:\n            in_criteria = True\n            criteria_start = i\n            continue\n\n        if '#### Notes' in line:\n            in_criteria = False\n            in_notes = True\n            continue\n\n        if in_criteria and line.strip().startswith('- ['):\n            task['acceptance_criteria'].append(line)\n\n        if in_notes and line.strip():\n            task['notes'].append(line)\n\n    return task if task['header'] else None\n\n\ndef is_task_complete(task: Dict) -> bool:\n    \"\"\"Check if all acceptance criteria are complete.\"\"\"\n    if not task['acceptance_criteria']:\n        return False\n\n    for criterion in task['acceptance_criteria']:\n        if not criterion.strip().startswith('- [x]'):\n            return False\n\n    return True\n\n\ndef extract_task_from_file(filepath: Path) -> Optional[Dict]:\n    \"\"\"Extract task from TODO.md or BACKLOG.md.\"\"\"\n    if not filepath.exists():\n        return None\n\n    content = filepath.read_text(encoding='utf-8')\n\n    # Find task block (between \"## Active Task\" or \"### [TASK-\" and next \"### [TASK-\" or end)\n    match = re.search(r'### \\[TASK-\\d+\\].*?(?=\\n### \\[TASK-|\\Z)', content, re.DOTALL)\n    if match:\n        return parse_task(match.group(0))\n\n    return None\n\n\ndef get_next_task_from_backlog() -> Optional[Dict]:\n    \"\"\"Get highest priority task from backlog.\"\"\"\n    if not BACKLOG_FILE.exists():\n        return None\n\n    content = BACKLOG_FILE.read_text(encoding='utf-8')\n\n    # Find first task (highest priority)\n    match = re.search(r'### \\[TASK-\\d+\\].*?(?=\\n### \\[TASK-|\\Z)', content, re.DOTALL)\n    if match:\n        return parse_task(match.group(0))\n\n    return None\n\n\ndef archive_task(task: Dict) -> None:\n    \"\"\"Add task to archive file.\"\"\"\n    # Add completion date if not present\n    if 'completed' not in task['metadata']:\n        task['metadata']['completed'] = datetime.now().strftime('%Y-%m-%d')\n\n    # Format archived task\n    archived = f\"\\n{task['header']}\\n\"\n    for key, value in task['metadata'].items():\n        formatted_key = key.replace('_', ' ').title()\n        archived += f\"- **{formatted_key}:** {value}\\n\"\n\n    archived += \"\\n#### Acceptance Criteria\\n\"\n    for criterion in task['acceptance_criteria']:\n        archived += f\"{criterion}\\n\"\n\n    if task['notes']:\n        archived += \"\\n#### Notes\\n\"\n        archived += '\\n'.join(task['notes']) + '\\n'\n\n    archived += \"\\n---\\n\"\n\n    # Prepend to archive\n    if ARCHIVE_FILE.exists():\n        existing = ARCHIVE_FILE.read_text(encoding='utf-8')\n        ARCHIVE_FILE.write_text(archived + existing, encoding='utf-8')\n    else:\n        ARCHIVE_FILE.write_text(f\"# Archived Tasks\\n\\n{archived}\", encoding='utf-8')\n\n\ndef update_todo_file(new_task: Optional[Dict]) -> None:\n    \"\"\"Update TODO.md with new task or clear it.\"\"\"\n    if new_task:\n        # Format new task\n        content = \"# 🎯 Current Task\\n\\n\"\n        content += \"> **Single Active Task** — Only ONE task should be in this file at any time.\\n\\n\"\n        content += \"---\\n\\n\"\n        content += f\"{new_task['header']}\\n\"\n        for key, value in new_task['metadata'].items():\n            formatted_key = key.replace('_', ' ').title()\n            content += f\"- **{formatted_key}:** {value}\\n\"\n        content += \"\\n#### Acceptance Criteria\\n\"\n        for criterion in new_task['acceptance_criteria']:\n            content += f\"{criterion}\\n\"\n        if new_task['notes']:\n            content += \"\\n#### Notes\\n\"\n            content += '\\n'.join(new_task['notes']) + '\\n'\n\n        TODO_FILE.write_text(content, encoding='utf-8')\n    else:\n        # Clear TODO file\n        TODO_FILE.write_text(\n            \"# 🎯 Current Task\\n\\n\"\n            \"> **No active task** — Promote a task from BACKLOG.md\\n\\n\",\n            encoding='utf-8'\n        )\n\n\ndef remove_task_from_backlog(task_id: str) -> None:\n    \"\"\"Remove task from backlog file.\"\"\"\n    if not BACKLOG_FILE.exists():\n        return\n\n    content = BACKLOG_FILE.read_text(encoding='utf-8')\n\n    # Remove task block\n    pattern = rf'### \\[{re.escape(task_id)}\\].*?(?=\\n### \\[TASK-|\\Z)'\n    content = re.sub(pattern, '', content, flags=re.DOTALL)\n\n    BACKLOG_FILE.write_text(content, encoding='utf-8')\n\n\ndef update_archive_statistics():\n    \"\"\"Update statistics in ARCHIVE.md.\"\"\"\n    if not ARCHIVE_FILE.exists():\n        return\n\n    content = ARCHIVE_FILE.read_text(encoding='utf-8')\n\n    # Count tasks by priority\n    p0_count = len(re.findall(r'\\*\\*Priority:\\*\\*\\s*P0', content))\n    p1_count = len(re.findall(r'\\*\\*Priority:\\*\\*\\s*P1', content))\n    p2_count = len(re.findall(r'\\*\\*Priority:\\*\\*\\s*P2', content))\n    p3_count = len(re.findall(r'\\*\\*Priority:\\*\\*\\s*P3', content))\n    total = p0_count + p1_count + p2_count + p3_count\n\n    # Update statistics section\n    stats_section = f\"\"\"## Statistics\n| Metric | Count |\n|--------|-------|\n| Total Completed | {total} |\n| P0 Completed | {p0_count} |\n| P1 Completed | {p1_count} |\n| P2 Completed | {p2_count} |\n| P3 Completed | {p3_count} |\n\n*Statistics auto-updated on {datetime.now().strftime('%Y-%m-%d')}*\n\"\"\"\n\n    # Replace or add statistics section\n    if re.search(r'^## Statistics', content, re.MULTILINE):\n        content = re.sub(\n            r'^## Statistics.*?(?=^## |\\Z)',\n            stats_section,\n            content,\n            flags=re.MULTILINE | re.DOTALL\n        )\n    else:\n        # Add statistics after header\n        content = re.sub(\n            r'^(# .*?\\n)',\n            r'\\1\\n' + stats_section + '\\n',\n            content,\n            flags=re.MULTILINE\n        )\n\n    ARCHIVE_FILE.write_text(content, encoding='utf-8')\n\n\ndef main():\n    \"\"\"Main entry point.\"\"\"\n    force = '--force' in sys.argv\n\n    # Read current task\n    current_task = extract_task_from_file(TODO_FILE)\n    if not current_task:\n        print(\"No task found in TODO.md\")\n        return 1\n\n    # Check if complete\n    if not is_task_complete(current_task) and not force:\n        print(\"Task is not complete. All acceptance criteria must be marked [x].\")\n        print(\"Use --force to archive anyway.\")\n        return 1\n\n    # Extract task ID\n    task_id_match = re.search(r'\\[TASK-(\\d+)\\]', current_task['header'])\n    if not task_id_match:\n        print(\"Could not extract task ID\")\n        return 1\n\n    task_id = f\"TASK-{task_id_match.group(1)}\"\n\n    # Archive task\n    print(f\"Archiving {task_id}...\")\n    archive_task(current_task)\n\n    # Update statistics\n    print(\"Updating archive statistics...\")\n    update_archive_statistics()\n\n    # Get next task from backlog\n    next_task = get_next_task_from_backlog()\n    if next_task:\n        next_id_match = re.search(r'\\[TASK-(\\d+)\\]', next_task['header'])\n        if next_id_match:\n            next_id = f\"TASK-{next_id_match.group(1)}\"\n            print(f\"Promoting {next_id} to TODO.md...\")\n            next_task['metadata']['status'] = 'In Progress'\n            update_todo_file(next_task)\n            remove_task_from_backlog(next_id)\n    else:\n        print(\"No tasks in backlog. Clearing TODO.md...\")\n        update_todo_file(None)\n\n    print(\"Done!\")\n    return 0\n\n\nif __name__ == \"__main__\":\n    sys.exit(main())\n"
        },
        {
          "path": "scripts/promote-task.sh",
          "type": "Bash",
          "lines": 125,
          "purpose": "Promotes task from BACKLOG.md to TODO.md",
          "key_functionality": [
            "Checks if TODO.md already has task (prevents duplicates)",
            "Promotes specific task (by ID) or highest priority task",
            "Updates status to \"In Progress\"",
            "Removes task from BACKLOG.md"
          ],
          "dependencies": [
            "Bash",
            "grep",
            "sed"
          ],
          "used_by": [
            "Task promotion workflow",
            "archive-task.py (indirect)"
          ],
          "referenced_by": [
            "TODO.md workflow instructions"
          ],
          "content": "#!/bin/bash\n# promote-task.sh\n# Promotes a task from BACKLOG.md to TODO.md\n#\n# Usage: ./scripts/promote-task.sh [task-id]\n#   task-id: Optional task ID (e.g., TASK-001). If not provided, promotes highest priority task.\n\nset -euo pipefail\n\nREPO_ROOT=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)\"\ncd \"$REPO_ROOT\"\n\n# Colors\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m'\n\nTODO_FILE=\".repo/tasks/TODO.md\"\nBACKLOG_FILE=\".repo/tasks/BACKLOG.md\"\n\n# Check if TODO.md already has a task\nif grep -q \"^### \\[TASK-\" \"$TODO_FILE\" 2>/dev/null; then\n    CURRENT_TASK=$(grep \"^### \\[TASK-\" \"$TODO_FILE\" | head -1 | sed 's/^### \\[\\(TASK-[0-9]*\\)\\].*/\\1/')\n    echo -e \"${YELLOW}Warning:${NC} TODO.md already contains task: $CURRENT_TASK\"\n    echo \"Only one task should be in TODO.md at a time.\"\n    echo \"Archive the current task first, or remove it manually.\"\n    exit 1\nfi\n\n# If task ID provided, promote that specific task\nif [[ $# -ge 1 ]]; then\n    TASK_ID=\"$1\"\n\n    # Find task in BACKLOG\n    if ! grep -q \"^### \\[$TASK_ID\\]\" \"$BACKLOG_FILE\" 2>/dev/null; then\n        echo -e \"${RED}Error:${NC} Task $TASK_ID not found in BACKLOG.md\"\n        exit 1\n    fi\n\n    # Extract task block from BACKLOG\n    TASK_START=$(grep -n \"^### \\[$TASK_ID\\]\" \"$BACKLOG_FILE\" | cut -d: -f1)\n    if [[ -z \"$TASK_START\" ]]; then\n        echo -e \"${RED}Error:${NC} Could not find task $TASK_ID in BACKLOG.md\"\n        exit 1\n    fi\n\n    # Read task block (until next ### or end of file)\n    TASK_BLOCK=\"\"\n    LINE_NUM=$TASK_START\n    while IFS= read -r line || [[ -n \"$line\" ]]; do\n        if [[ $LINE_NUM -lt $TASK_START ]]; then\n            LINE_NUM=$((LINE_NUM + 1))\n            continue\n        fi\n\n        # Stop at next task or end of file\n        if [[ $LINE_NUM -gt $TASK_START ]] && [[ \"$line\" =~ ^###\\ \\[TASK- ]]; then\n            break\n        fi\n\n        TASK_BLOCK+=\"$line\"$'\\n'\n        LINE_NUM=$((LINE_NUM + 1))\n    done < \"$BACKLOG_FILE\"\n\n    # Update status to \"In Progress\"\n    TASK_BLOCK=$(echo \"$TASK_BLOCK\" | sed 's/\\*\\*Status:\\*\\* Pending/\\*\\*Status:\\*\\* In Progress/')\n\n    # Add to TODO.md\n    {\n        echo \"# 🎯 Current Task\"\n        echo \"\"\n        echo \"> **Single Active Task** — Only ONE task should be in this file at any time.\"\n        echo \"\"\n        echo \"---\"\n        echo \"\"\n        echo \"$TASK_BLOCK\"\n    } > \"$TODO_FILE\"\n\n    # Remove from BACKLOG.md\n    TEMP_FILE=$(mktemp)\n    IN_TASK=false\n    SKIP_TASK=false\n\n    while IFS= read -r line || [[ -n \"$line\" ]]; do\n        if [[ \"$line\" =~ ^###\\ \\[$TASK_ID\\] ]]; then\n            SKIP_TASK=true\n            continue\n        fi\n\n        if [[ \"$SKIP_TASK\" == true ]]; then\n            # Stop skipping when we hit next task or section\n            if [[ \"$line\" =~ ^###\\ \\[TASK- ]] || [[ \"$line\" =~ ^##\\  ]]; then\n                SKIP_TASK=false\n                echo \"$line\"\n            fi\n            continue\n        fi\n\n        echo \"$line\"\n    done < \"$BACKLOG_FILE\" > \"$TEMP_FILE\"\n\n    mv \"$TEMP_FILE\" \"$BACKLOG_FILE\"\n\n    echo -e \"${GREEN}✓ Task $TASK_ID promoted to TODO.md${NC}\"\n    echo \"  Updated status to: In Progress\"\n    echo \"  Removed from BACKLOG.md\"\n\nelse\n    # Promote highest priority task (first P0, then P1, etc.)\n    echo \"Finding highest priority task in BACKLOG...\"\n\n    # Find first task in BACKLOG (should be highest priority)\n    FIRST_TASK=$(grep \"^### \\[TASK-\" \"$BACKLOG_FILE\" | head -1 | sed 's/^### \\[\\(TASK-[0-9]*\\)\\].*/\\1/')\n\n    if [[ -z \"$FIRST_TASK\" ]]; then\n        echo -e \"${RED}Error:${NC} No tasks found in BACKLOG.md\"\n        exit 1\n    fi\n\n    echo \"Promoting task: $FIRST_TASK\"\n    # Recursively call with task ID\n    exec \"$0\" \"$FIRST_TASK\"\nfi\n"
        },
        {
          "path": "scripts/create-hitl-item.sh",
          "type": "Bash",
          "lines": 142,
          "purpose": "Creates new HITL item from template",
          "key_functionality": [
            "Validates category (External Integration, Clarification, Risk, Feedback, Vendor)",
            "Generates next HITL ID (HITL-XXXX)",
            "Creates HITL item file (.repo/hitl/HITL-XXXX.md)",
            "Adds entry to HITL.md index (Active table)",
            "Uses template format"
          ],
          "dependencies": [
            "Bash",
            "date",
            "find",
            "sort"
          ],
          "used_by": [
            "Agents creating HITL items",
            "workflow automation"
          ],
          "referenced_by": [
            "HITL.md",
            "AGENTS.json (HITL workflow)"
          ],
          "content": "#!/bin/bash\n# create-hitl-item.sh\n# Creates a new HITL item from template and adds it to HITL.md index\n#\n# Usage: ./scripts/create-hitl-item.sh [category] [summary]\n#   category: External Integration | Clarification | Risk | Feedback | Vendor\n#   summary: Brief description of the HITL item\n\nset -euo pipefail\n\nREPO_ROOT=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)\"\ncd \"$REPO_ROOT\"\n\n# Colors\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m'\n\n# Validate arguments\nif [[ $# -lt 2 ]]; then\n    echo -e \"${RED}Error:${NC} Missing required arguments\"\n    echo \"Usage: $0 [category] [summary]\"\n    echo \"  category: External Integration | Clarification | Risk | Feedback | Vendor\"\n    echo \"  summary: Brief description of the HITL item\"\n    exit 1\nfi\n\nCATEGORY=\"$1\"\nSUMMARY=\"$2\"\n\n# Validate category\nVALID_CATEGORIES=(\"External Integration\" \"Clarification\" \"Risk\" \"Feedback\" \"Vendor\")\nif [[ ! \" ${VALID_CATEGORIES[@]} \" =~ \" ${CATEGORY} \" ]]; then\n    echo -e \"${RED}Error:${NC} Invalid category: $CATEGORY\"\n    echo \"Valid categories: ${VALID_CATEGORIES[*]}\"\n    exit 1\nfi\n\n# Get next HITL ID\nHITL_DIR=\".repo/hitl\"\nHITL_INDEX=\".repo/policy/HITL.md\"\nmkdir -p \"$HITL_DIR\"\n\n# Find highest existing HITL ID\nLAST_ID=$(find \"$HITL_DIR\" -name \"HITL-*.md\" 2>/dev/null | \\\n    sed 's/.*HITL-\\([0-9]*\\)\\.md/\\1/' | \\\n    sort -n | \\\n    tail -1 || echo \"0\")\n\nNEXT_ID=$((LAST_ID + 1))\nHITL_ID=$(printf \"HITL-%04d\" \"$NEXT_ID\")\nHITL_FILE=\"$HITL_DIR/$HITL_ID.md\"\n\n# Create HITL item file\ncat > \"$HITL_FILE\" <<EOF\n# $HITL_ID: $SUMMARY\n\n**Category:** $CATEGORY\n**Required For:** [Change types that require this HITL]\n**Owner:** [Human Name]\n**Reviewer:** [Human Name]\n**Status:** Pending\n**Date Required:** $(date +%Y-%m-%d)\n**Date Completed:**\n\n## Summary\n\n$SUMMARY\n\n## Required Human Action Steps\n\n1. [Action step 1]\n2. [Action step 2]\n3. [Action step 3]\n\n## Evidence of Completion\n\n- [Evidence will be added here when completed]\n\n## Related Artifacts\n\n- **PR:** [PR number or link]\n- **Task Packet:** [Task reference]\n- **ADR:** [ADR reference if applicable]\n- **Waiver:** [Waiver reference if applicable]\n\n## Notes\n\n[Additional context or notes]\nEOF\n\necho -e \"${GREEN}Created:${NC} $HITL_FILE\"\n\n# Add to HITL.md index (Active table)\nif [[ -f \"$HITL_INDEX\" ]]; then\n    # Find the Active table and add entry\n    # This is a simple implementation - assumes table format\n    TEMP_FILE=$(mktemp)\n    IN_ACTIVE_TABLE=false\n    TABLE_ENDED=false\n\n    while IFS= read -r line; do\n        if [[ \"$line\" =~ \"### Active\" ]]; then\n            IN_ACTIVE_TABLE=true\n            echo \"$line\"\n            # Print header if next line is table header\n            continue\n        fi\n\n        if [[ \"$IN_ACTIVE_TABLE\" == true ]] && [[ \"$line\" =~ \"^\\|.*ID\\|\" ]]; then\n            echo \"$line\"\n            echo \"|$HITL_ID|$CATEGORY|Pending|$SUMMARY|$HITL_FILE|\"\n            continue\n        fi\n\n        if [[ \"$IN_ACTIVE_TABLE\" == true ]] && [[ \"$line\" =~ \"### Archived\" ]]; then\n            IN_ACTIVE_TABLE=false\n            TABLE_ENDED=true\n        fi\n\n        echo \"$line\"\n    done < \"$HITL_INDEX\" > \"$TEMP_FILE\"\n\n    mv \"$TEMP_FILE\" \"$HITL_INDEX\"\n    echo -e \"${GREEN}Updated:${NC} $HITL_INDEX (added to Active table)\"\nelse\n    echo -e \"${YELLOW}Warning:${NC} $HITL_INDEX not found. Please add entry manually:\"\n    echo \"|$HITL_ID|$CATEGORY|Pending|$SUMMARY|$HITL_FILE|\"\nfi\n\necho \"\"\necho -e \"${GREEN}✓ HITL item created successfully${NC}\"\necho \"  File: $HITL_FILE\"\necho \"  ID: $HITL_ID\"\necho \"  Category: $CATEGORY\"\necho \"\"\necho \"Next steps:\"\necho \"  1. Edit $HITL_FILE to fill in details\"\necho \"  2. Update Required Human Action Steps\"\necho \"  3. Link to related PR/task/ADR\"\n"
        },
        {
          "path": "scripts/create-waiver.sh",
          "type": "Bash",
          "lines": 175,
          "purpose": "Creates new waiver from template",
          "key_functionality": [
            "Creates waiver file (.repo/waivers/WAIVER-XXX.md)",
            "Uses WAIVER_TEMPLATE.md",
            "Adds to waivers index (if exists)",
            "Sets creation date"
          ],
          "dependencies": [
            "Bash",
            "date"
          ],
          "used_by": [
            "Agents creating waivers",
            "governance-verify (auto-generation)"
          ],
          "referenced_by": [
            "QUALITY_GATES.md"
          ],
          "content": "#!/bin/bash\n# create-waiver.sh\n# Creates a new waiver from template\n#\n# Usage: ./scripts/create-waiver.sh [waiver-id] [what-it-waives] [why]\n#   waiver-id: Unique waiver identifier (e.g., WAIVER-001)\n#   what-it-waives: What gate/rule is being waived\n#   why: Brief justification\n\nset -euo pipefail\n\nREPO_ROOT=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)\"\ncd \"$REPO_ROOT\"\n\n# Colors\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m'\n\n# Validate arguments\nif [[ $# -lt 3 ]]; then\n    echo -e \"${RED}Error:${NC} Missing required arguments\"\n    echo \"Usage: $0 [waiver-id] [what-it-waives] [why]\"\n    echo \"  waiver-id: Unique identifier (e.g., WAIVER-001)\"\n    echo \"  what-it-waives: What gate/rule is being waived\"\n    echo \"  why: Brief justification\"\n    exit 1\nfi\n\nWAIVER_ID=\"$1\"\nWHAT_WAIVES=\"$2\"\nWHY=\"$3\"\nWAIVER_DIR=\".repo/waivers\"\nWAIVER_FILE=\"$WAIVER_DIR/${WAIVER_ID}.md\"\nWAIVER_INDEX=\".repo/policy/WAIVERS.md\"\nWAIVER_TEMPLATE=\".repo/templates/WAIVER_TEMPLATE.md\"\n\nmkdir -p \"$WAIVER_DIR\"\n\n# Read template if it exists\nif [[ -f \"$WAIVER_TEMPLATE\" ]]; then\n    TEMPLATE_CONTENT=$(cat \"$WAIVER_TEMPLATE\")\nelse\n    # Use default template\n    TEMPLATE_CONTENT='{\n  \"waives\": \"\",\n  \"why\": \"\",\n  \"scope\": \"\",\n  \"owner\": \"\",\n  \"expiration\": \"\",\n  \"remediation_plan\": \"\",\n  \"link\": \"\",\n  \"notes\": \"Auto-generated waivers allowed for gate failures only.\"\n}'\nfi\n\n# Create waiver file (JSON format)\ncat > \"$WAIVER_FILE\" <<EOF\n# $WAIVER_ID\n\n**Created:** $(date +%Y-%m-%d)\n**Expires:** [SET EXPIRATION DATE]\n**Status:** Active\n\n## What This Waives\n\n$WHAT_WAIVES\n\n## Why\n\n$WHY\n\n## Scope\n\n[Describe scope of waiver - specific PR, feature, time period]\n\n## Owner\n\n[Human name responsible for this waiver]\n\n## Remediation Plan\n\n[How will this be fixed? Timeline?]\n\n## Related Artifacts\n\n- **PR:** [PR number or link]\n- **Task:** [Task reference]\n- **HITL:** [HITL item if applicable]\n\n## Notes\n\n[Additional context]\nEOF\n\necho -e \"${GREEN}Created:${NC} $WAIVER_FILE\"\n\n# Add to WAIVERS.md index if it exists, or create it\nif [[ ! -f \"$WAIVER_INDEX\" ]]; then\n    cat > \"$WAIVER_INDEX\" <<EOF\n# Active Waivers\n\n**File**: `.repo/policy/WAIVERS.md`\n\nThis file tracks active policy waivers. See `.repo/policy/QUALITY_GATES.md` for waiver policy.\n\n## Active Waivers\n\n| ID | What It Waives | Owner | Expires | Status | Filepath |\n|---|---|---|---|---|---|\nEOF\nfi\n\n# Add entry to index\nTEMP_FILE=$(mktemp)\nIN_ACTIVE_TABLE=false\nTABLE_HEADER_ADDED=false\n\nwhile IFS= read -r line || [[ -n \"$line\" ]]; do\n    if [[ \"$line\" =~ \"## Active Waivers\" ]]; then\n        IN_ACTIVE_TABLE=true\n        echo \"$line\"\n        continue\n    fi\n\n    if [[ \"$IN_ACTIVE_TABLE\" == true ]] && [[ \"$line\" =~ \"^\\|.*ID\\|\" ]] && [[ \"$TABLE_HEADER_ADDED\" == false ]]; then\n        echo \"$line\"\n        echo \"|$WAIVER_ID|$WHAT_WAIVES|[Owner]|$(date +%Y-%m-%d)|Active|$WAIVER_FILE|\"\n        TABLE_HEADER_ADDED=true\n        continue\n    fi\n\n    if [[ \"$IN_ACTIVE_TABLE\" == true ]] && [[ \"$line\" =~ \"## Archived\" ]]; then\n        IN_ACTIVE_TABLE=false\n    fi\n\n    echo \"$line\"\ndone < \"$WAIVER_INDEX\" > \"$TEMP_FILE\" 2>/dev/null || {\n    # If file doesn't exist or is empty, create it\n    cat > \"$WAIVER_INDEX\" <<EOF\n# Active Waivers\n\n**File**: `.repo/policy/WAIVERS.md`\n\nThis file tracks active policy waivers. See `.repo/policy/QUALITY_GATES.md` for waiver policy.\n\n## Active Waivers\n\n| ID | What It Waives | Owner | Expires | Status | Filepath |\n|---|---|---|---|---|---|\n|$WAIVER_ID|$WHAT_WAIVES|[Owner]|$(date +%Y-%m-%d)|Active|$WAIVER_FILE|\n\n## Archived Waivers\n\n| ID | What It Waives | Owner | Expired | Status | Filepath |\n|---|---|---|---|---|---|\nEOF\n    TEMP_FILE=\"$WAIVER_INDEX\"\n}\n\nmv \"$TEMP_FILE\" \"$WAIVER_INDEX\"\necho -e \"${GREEN}Updated:${NC} $WAIVER_INDEX\"\n\necho \"\"\necho -e \"${GREEN}✓ Waiver created successfully${NC}\"\necho \"  File: $WAIVER_FILE\"\necho \"  ID: $WAIVER_ID\"\necho \"\"\necho \"Next steps:\"\necho \"  1. Edit $WAIVER_FILE to fill in details\"\necho \"  2. Set expiration date\"\necho \"  3. Add owner and remediation plan\"\necho \"  4. Link to related PR/task/HITL\"\n"
        },
        {
          "path": "scripts/sync-hitl-to-pr.py",
          "type": "Python 3",
          "lines": 199,
          "purpose": "Syncs HITL items status to PR description",
          "key_functionality": [
            "Parses HITL index (.repo/policy/HITL.md)",
            "Reads HITL item files (.repo/hitl/)",
            "Updates PR description via GitHub API",
            "Formats HITL section in PR",
            "Handles Completed/Superseded items (archives)"
          ],
          "dependencies": [
            "Python 3",
            "requests (optional)",
            "GitHub API"
          ],
          "environment_variables": [
            "GITHUB_TOKEN",
            "GITHUB_REPOSITORY"
          ],
          "used_by": [
            "CI workflows (after HITL status changes)"
          ],
          "referenced_by": [
            "CI integration (governance-verify.yml)"
          ],
          "content": "#!/usr/bin/env python3\n\"\"\"\nSync HITL items status to PR description.\n\nThis script reads HITL items from .repo/policy/HITL.md and .repo/hitl/\nand updates the PR description with current status.\n\nUsage:\n    python scripts/sync-hitl-to-pr.py [PR_NUMBER]\n\n    If PR_NUMBER is not provided, tries to detect from git context.\n\nEnvironment variables:\n    GITHUB_TOKEN: GitHub API token (required for API updates)\n    GITHUB_REPOSITORY: Repository in format owner/repo (auto-detected in CI)\n\"\"\"\n\nimport os\nimport re\nimport sys\nfrom pathlib import Path\nfrom typing import List, Dict, Optional\n\ntry:\n    import requests\n    HAS_REQUESTS = True\nexcept ImportError:\n    HAS_REQUESTS = False\n    if __name__ == \"__main__\":\n        print(\"Warning: 'requests' not installed. Install with: pip install requests\", file=sys.stderr)\n        print(\"Script will work but cannot update PRs via API.\", file=sys.stderr)\n\nREPO_ROOT = Path(__file__).parent.parent\nHITL_INDEX = REPO_ROOT / \".repo\" / \"policy\" / \"HITL.md\"\nHITL_DIR = REPO_ROOT / \".repo\" / \"hitl\"\n\n\ndef parse_hitl_index() -> List[Dict[str, str]]:\n    \"\"\"Parse HITL index file and return list of active items.\"\"\"\n    if not HITL_INDEX.exists():\n        return []\n\n    items = []\n    in_active_table = False\n\n    with open(HITL_INDEX, 'r', encoding='utf-8') as f:\n        for line in f:\n            # Detect active table\n            if \"### Active\" in line:\n                in_active_table = True\n                continue\n            if \"### Archived\" in line:\n                in_active_table = False\n                continue\n\n            if not in_active_table:\n                continue\n\n            # Parse table row: |ID|Category|Status|Summary|Filepath|\n            match = re.match(r'^\\|([^|]+)\\|([^|]+)\\|([^|]+)\\|([^|]+)\\|([^|]+)\\|', line)\n            if match and not match.group(1).strip().startswith('ID'):\n                items.append({\n                    'id': match.group(1).strip(),\n                    'category': match.group(2).strip(),\n                    'status': match.group(3).strip(),\n                    'summary': match.group(4).strip(),\n                    'filepath': match.group(5).strip(),\n                })\n\n    return items\n\n\ndef read_hitl_item(item_id: str) -> Optional[Dict[str, str]]:\n    \"\"\"Read HITL item file and return details.\"\"\"\n    item_file = HITL_DIR / f\"{item_id}.md\"\n    if not item_file.exists():\n        return None\n\n    details = {'id': item_id}\n    with open(item_file, 'r', encoding='utf-8') as f:\n        content = f.read()\n\n        # Extract key fields\n        for field in ['Category', 'Status', 'Summary', 'Owner', 'Date Required', 'Date Completed']:\n            match = re.search(rf'\\*\\*{field}:\\*\\*\\s*(.+)', content)\n            if match:\n                details[field.lower().replace(' ', '_')] = match.group(1).strip()\n\n    return details\n\n\ndef generate_hitl_section(items: List[Dict[str, str]]) -> str:\n    \"\"\"Generate HITL section for PR description.\"\"\"\n    if not items:\n        return \"## HITL Items\\n\\n✅ No active HITL items.\"\n\n    section = \"## HITL Items\\n\\n\"\n    section += \"| ID | Category | Status | Summary |\\n\"\n    section += \"|----|----------|--------|----------|\\n\"\n\n    for item in items:\n        status_emoji = {\n            'Completed': '✅',\n            'Superseded': '✅',\n            'Pending': '⏳',\n            'In Progress': '🔄',\n            'Blocked': '🚫'\n        }.get(item['status'], '❓')\n        section += f\"| {item['id']} | {item['category']} | {status_emoji} {item['status']} | {item['summary']} |\\n\"\n\n    # Check for blocking items\n    blocking = [i for i in items if i['status'] not in ['Completed', 'Superseded']]\n    if blocking:\n        section += f\"\\n⚠️ **Warning**: {len(blocking)} HITL item(s) not Completed. PR merge may be blocked per `.repo/policy/QUALITY_GATES.md`.\\n\"\n        section += \"\\n**Blocking items:**\\n\"\n        for item in blocking:\n            section += f\"- {item['id']}: {item['summary']} ({item['status']})\\n\"\n\n    return section\n\n\ndef update_pr_via_api(pr_number: str, section: str, repo: str, token: str) -> bool:\n    \"\"\"Update PR description via GitHub API.\"\"\"\n    if not HAS_REQUESTS:\n        return False\n\n    owner, repo_name = repo.split('/')\n    url = f\"https://api.github.com/repos/{owner}/{repo_name}/pulls/{pr_number}\"\n\n    # Get current PR body\n    headers = {\n        \"Authorization\": f\"token {token}\",\n        \"Accept\": \"application/vnd.github.v3+json\"\n    }\n\n    try:\n        response = requests.get(url, headers=headers)\n        response.raise_for_status()\n        pr_data = response.json()\n        current_body = pr_data.get(\"body\", \"\")\n\n        # Check if HITL section already exists\n        if \"## HITL Items\" in current_body:\n            # Replace existing section\n            pattern = r\"## HITL Items.*?(?=\\n## |\\Z)\"\n            new_body = re.sub(pattern, section, current_body, flags=re.DOTALL)\n        else:\n            # Append section\n            new_body = f\"{current_body}\\n\\n{section}\" if current_body else section\n\n        # Update PR\n        update_response = requests.patch(\n            url,\n            headers=headers,\n            json={\"body\": new_body}\n        )\n        update_response.raise_for_status()\n        return True\n    except Exception as e:\n        print(f\"Error updating PR via API: {e}\", file=sys.stderr)\n        return False\n\n\ndef main():\n    \"\"\"Main entry point.\"\"\"\n    items = parse_hitl_index()\n\n    if not items:\n        print(\"No active HITL items found.\")\n        return 0\n\n    section = generate_hitl_section(items)\n    print(section)\n\n    # Try to update PR if number provided\n    if len(sys.argv) > 1:\n        pr_number = sys.argv[1]\n        token = os.getenv(\"GITHUB_TOKEN\")\n        repo = os.getenv(\"GITHUB_REPOSITORY\")\n\n        if token and repo:\n            print(f\"\\nUpdating PR #{pr_number} via GitHub API...\")\n            if update_pr_via_api(pr_number, section, repo, token):\n                print(f\"✅ Successfully updated PR #{pr_number}\")\n                return 0\n            else:\n                print(f\"⚠️  Failed to update PR via API, falling back to manual method\")\n\n        # Fallback: GitHub CLI or manual\n        print(f\"\\nTo update PR #{pr_number} manually:\")\n        print(f\"  gh pr edit {pr_number} --body-file <(echo '{section}')\")\n        print(f\"\\nOr copy the section above and paste into PR description.\")\n\n    return 0\n\n\nif __name__ == \"__main__\":\n    sys.exit(main())\n"
        },
        {
          "path": "scripts/generate-trace-log.sh",
          "type": "Bash",
          "purpose": "Generates trace log from workflow",
          "key_functionality": [
            "Creates trace log JSON file",
            "Validates against schema",
            "Saves to .repo/traces/"
          ],
          "used_by": [
            "Agents in Pass 3 (Verify)"
          ],
          "referenced_by": [
            "QUALITY_GATES.md (hard gate)"
          ],
          "content": "#!/bin/bash\n# generate-trace-log.sh\n# Generates a trace log file from template\n#\n# Usage: ./scripts/generate-trace-log.sh [task-id] [intent]\n#   task-id: Task identifier (e.g., TASK-001)\n#   intent: Brief description of what this change does\n\nset -euo pipefail\n\nREPO_ROOT=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)\"\ncd \"$REPO_ROOT\"\n\n# Colors\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nNC='\\033[0m'\n\n# Validate arguments\nif [[ $# -lt 2 ]]; then\n    echo -e \"${RED}Error:${NC} Missing required arguments\"\n    echo \"Usage: $0 [task-id] [intent]\"\n    echo \"  task-id: Task identifier (e.g., TASK-001)\"\n    echo \"  intent: Brief description of what this change does\"\n    exit 1\nfi\n\nTASK_ID=\"$1\"\nINTENT=\"$2\"\nTRACE_DIR=\".repo/traces\"\nTRACE_SCHEMA=\".repo/templates/AGENT_TRACE_SCHEMA.json\"\n\nmkdir -p \"$TRACE_DIR\"\n\n# Generate filename from task ID and timestamp\nTIMESTAMP=$(date +%Y%m%d-%H%M%S)\nTRACE_FILE=\"$TRACE_DIR/${TASK_ID}-trace-${TIMESTAMP}.json\"\n\n# Create trace log from schema template\ncat > \"$TRACE_FILE\" <<EOF\n{\n  \"intent\": \"$INTENT\",\n  \"task_id\": \"$TASK_ID\",\n  \"timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\",\n  \"files\": [],\n  \"commands\": [],\n  \"evidence\": [],\n  \"hitl\": [],\n  \"unknowns\": []\n}\nEOF\n\n# Validate against schema if Python is available\nif command -v python3 &> /dev/null && [[ -f \"$TRACE_SCHEMA\" ]]; then\n    if python3 -c \"import json, sys; json.load(open('$TRACE_FILE'))\" 2>/dev/null; then\n        echo -e \"${GREEN}✓ Trace log created and validated${NC}\"\n    else\n        echo -e \"${RED}Warning:${NC} Trace log may be invalid JSON\"\n    fi\nelse\n    echo -e \"${GREEN}✓ Trace log created${NC}\"\nfi\n\necho \"  File: $TRACE_FILE\"\necho \"\"\necho \"Next steps:\"\necho \"  1. Add modified files to 'files' array\"\necho \"  2. Add commands run to 'commands' array\"\necho \"  3. Add evidence (test results, outputs) to 'evidence' array\"\necho \"  4. Add HITL item IDs to 'hitl' array if applicable\"\necho \"  5. Add UNKNOWN items to 'unknowns' array if any\"\n"
        },
        {
          "path": "scripts/generate-agent-log.sh",
          "type": "Bash",
          "purpose": "Generates agent log",
          "used_by": [
            "Agents for non_doc_change"
          ],
          "content": "#!/bin/bash\n# generate-agent-log.sh\n# Generates an agent log file from template\n#\n# Usage: ./scripts/generate-agent-log.sh [task-id] [action]\n#   task-id: Task identifier (e.g., TASK-001)\n#   action: Brief description of action taken\n\nset -euo pipefail\n\nREPO_ROOT=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)\"\ncd \"$REPO_ROOT\"\n\n# Colors\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nNC='\\033[0m'\n\n# Validate arguments\nif [[ $# -lt 2 ]]; then\n    echo -e \"${RED}Error:${NC} Missing required arguments\"\n    echo \"Usage: $0 [task-id] [action]\"\n    echo \"  task-id: Task identifier (e.g., TASK-001)\"\n    echo \"  action: Brief description of action taken\"\n    exit 1\nfi\n\nTASK_ID=\"$1\"\nACTION=\"$2\"\nLOG_TEMPLATE=\".repo/templates/AGENT_LOG_TEMPLATE.md\"\n\n# Generate log file\nTIMESTAMP=$(date +%Y%m%d-%H%M%S)\nLOG_FILE=\".repo/logs/${TASK_ID}-log-${TIMESTAMP}.json\"\nmkdir -p \"$(dirname \"$LOG_FILE\")\"\n\n# Read template if it exists, otherwise use default JSON structure\nif [[ -f \"$LOG_TEMPLATE\" ]]; then\n    LOG_CONTENT=$(cat \"$LOG_TEMPLATE\")\n    # Replace empty intent with action\n    LOG_CONTENT=$(echo \"$LOG_CONTENT\" | sed \"s/\\\"intent\\\": \\\"\\\"/\\\"intent\\\": \\\"$ACTION\\\"/\")\nelse\n    # Use default JSON template\n    LOG_CONTENT=$(cat <<EOF\n{\n  \"intent\": \"$ACTION\",\n  \"task_id\": \"$TASK_ID\",\n  \"timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\",\n  \"plan\": [],\n  \"actions\": [],\n  \"evidence\": [],\n  \"decisions\": [],\n  \"risks\": [],\n  \"follow_ups\": [],\n  \"reasoning_summary\": \"\",\n  \"notes\": \"No secrets. No private data. No raw chain-of-thought.\"\n}\nEOF\n)\nfi\n\necho \"$LOG_CONTENT\" > \"$LOG_FILE\"\n\n# Validate JSON\nif command -v python3 &> /dev/null; then\n    if python3 -m json.tool \"$LOG_FILE\" > /dev/null 2>&1; then\n        echo -e \"${GREEN}✓ Valid JSON${NC}\"\n    else\n        echo -e \"${RED}Warning: Invalid JSON generated${NC}\"\n    fi\nfi\n\necho -e \"${GREEN}✓ Agent log created${NC}\"\necho \"  File: $LOG_FILE\"\necho \"\"\necho \"Next steps:\"\necho \"  1. Fill in Files Modified section\"\necho \"  2. Add Commands Run\"\necho \"  3. Add Evidence (test results, outputs)\"\necho \"  4. Add HITL item IDs if applicable\"\necho \"  5. Add UNKNOWN items if any\"\n"
        },
        {
          "path": "scripts/create-adr-from-trigger.sh",
          "type": "Bash",
          "purpose": "Creates ADR from trigger detection",
          "used_by": [
            "Agents when ADR trigger detected"
          ],
          "content": "#!/bin/bash\n# create-adr-from-trigger.sh\n# Creates an ADR from detected ADR triggers\n#\n# Usage: ./scripts/create-adr-from-trigger.sh [trigger-details]\n#   Or run detect-adr-triggers.sh first and pipe output\n\nset -euo pipefail\n\nREPO_ROOT=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)\"\ncd \"$REPO_ROOT\"\n\n# Colors\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m'\n\nADR_DIR=\"docs/adr\"\nADR_TEMPLATE=\".repo/templates/ADR_TEMPLATE.md\"\nmkdir -p \"$ADR_DIR\"\n\n# Get next ADR number\nLAST_ADR=$(find \"$ADR_DIR\" -name \"ADR-*.md\" 2>/dev/null | \\\n    sed 's/.*ADR-\\([0-9]*\\)\\.md/\\1/' | \\\n    sort -n | \\\n    tail -1 || echo \"0\")\n\nNEXT_ADR=$((LAST_ADR + 1))\nADR_ID=$(printf \"ADR-%04d\" \"$NEXT_ADR\")\nADR_FILE=\"$ADR_DIR/$ADR_ID.md\"\n\n# Run ADR trigger detection to get context\nTRIGGER_OUTPUT=$(./scripts/detect-adr-triggers.sh 2>&1 || true)\n\n# Extract trigger information\nCROSS_MODULE_IMPORTS=$(echo \"$TRIGGER_OUTPUT\" | grep -i \"cross-module\" || true)\nAPI_CHANGES=$(echo \"$TRIGGER_OUTPUT\" | grep -i \"API\" || true)\nSCHEMA_CHANGES=$(echo \"$TRIGGER_OUTPUT\" | grep -i \"schema\\|migration\" || true)\n\n# Build context\nCONTEXT=\"\"\nif [[ -n \"$CROSS_MODULE_IMPORTS\" ]]; then\n    CONTEXT+=\"Cross-module imports detected. \"\nfi\nif [[ -n \"$API_CHANGES\" ]]; then\n    CONTEXT+=\"API contract changes detected. \"\nfi\nif [[ -n \"$SCHEMA_CHANGES\" ]]; then\n    CONTEXT+=\"Database schema changes detected. \"\nfi\n\nif [[ -z \"$CONTEXT\" ]]; then\n    CONTEXT=\"ADR required per governance framework (Principle 23: ADR Required When Triggered)\"\nfi\n\n# Read template\nif [[ -f \"$ADR_TEMPLATE\" ]]; then\n    TEMPLATE_CONTENT=$(cat \"$ADR_TEMPLATE\")\nelse\n    # Default template\n    TEMPLATE_CONTENT='{\n  \"context\": \"\",\n  \"decision_drivers\": [],\n  \"options\": [],\n  \"decision\": \"\",\n  \"consequences\": [],\n  \"modules\": [],\n  \"commands\": [],\n  \"migration\": [],\n  \"boundary_impact\": \"\",\n  \"hitl\": []\n}'\nfi\n\n# Create ADR file\ncat > \"$ADR_FILE\" <<EOF\n# $ADR_ID: [Decision Title]\n\n**Status:** Proposed\n**Date:** $(date +%Y-%m-%d)\n**Context:** $CONTEXT\n\n## Context\n\n$CONTEXT\n\nThis ADR was auto-generated from detected triggers. Please fill in the decision details.\n\n## Decision Drivers\n\n- [Driver 1: e.g., Need to share functionality across modules]\n- [Driver 2: e.g., Performance requirements]\n- [Driver 3: e.g., Maintainability concerns]\n\n## Considered Options\n\n### Option 1: [Option name]\n- Pros: [List pros]\n- Cons: [List cons]\n\n### Option 2: [Option name]\n- Pros: [List pros]\n- Cons: [List cons]\n\n## Decision\n\n[Chosen option and rationale]\n\n## Consequences\n\n### Positive\n- [Positive consequence 1]\n- [Positive consequence 2]\n\n### Negative\n- [Negative consequence 1]\n- [Negative consequence 2]\n\n## Modules Affected\n\n- [List affected modules]\n\n## Boundary Impact\n\n[Describe impact on module boundaries]\n\n## Migration Notes\n\n[If applicable, describe migration steps]\n\n## HITL Items\n\n- [List related HITL items if any]\n\n## Notes\n\n[Additional context or notes]\nEOF\n\necho -e \"${GREEN}✓ ADR created: $ADR_FILE${NC}\"\necho \"\"\necho \"Next steps:\"\necho \"  1. Fill in decision title in header\"\necho \"  2. Complete decision drivers\"\necho \"  3. Document considered options\"\necho \"  4. Record decision and rationale\"\necho \"  5. Document consequences\"\necho \"  6. List affected modules\"\necho \"\"\necho \"Trigger details:\"\nif [[ -n \"$CROSS_MODULE_IMPORTS\" ]]; then\n    echo \"  - Cross-module imports detected\"\nfi\nif [[ -n \"$API_CHANGES\" ]]; then\n    echo \"  - API changes detected\"\nfi\nif [[ -n \"$SCHEMA_CHANGES\" ]]; then\n    echo \"  - Schema changes detected\"\nfi\n"
        },
        {
          "path": "scripts/detect-adr-triggers.sh",
          "type": "Bash",
          "purpose": "Detects ADR triggers in changes",
          "used_by": [
            "Governance verification"
          ],
          "content": "#!/bin/bash\n# detect-adr-triggers.sh\n# Detects if ADR is required based on code changes\n#\n# Usage: ./scripts/detect-adr-triggers.sh [base-branch]\n#   base-branch: Base branch to compare against (default: main)\n\nset -euo pipefail\n\nREPO_ROOT=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)\"\ncd \"$REPO_ROOT\"\n\n# Colors\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m'\n\nBASE_BRANCH=\"${1:-main}\"\n\nif ! command -v git &> /dev/null; then\n    echo -e \"${RED}Error:${NC} git is required for ADR trigger detection\"\n    exit 1\nfi\n\nif ! git rev-parse --git-dir > /dev/null 2>&1; then\n    echo -e \"${YELLOW}Warning:${NC} Not in a git repository\"\n    exit 0\nfi\n\n# Get changed files\nCHANGED_FILES=$(git diff --name-only \"$BASE_BRANCH\" HEAD 2>/dev/null || \\\n    git diff --name-only HEAD 2>/dev/null || echo \"\")\n\nif [[ -z \"$CHANGED_FILES\" ]]; then\n    echo \"No changed files detected\"\n    exit 0\nfi\n\nADR_REQUIRED=false\nREASONS=()\n\n# Check for cross-feature imports (ADR trigger per BOUNDARIES.md)\necho \"Checking for cross-feature imports...\"\n\n# Python files: check for imports across module boundaries\nPYTHON_FILES=$(echo \"$CHANGED_FILES\" | grep -E \"\\.py$\" || true)\nif [[ -n \"$PYTHON_FILES\" ]]; then\n    for file in $PYTHON_FILES; do\n        # Skip if file doesn't exist (deleted)\n        [[ ! -f \"$file\" ]] && continue\n\n        # Check for imports from other modules\n        # Pattern: from modules.X import or import modules.X\n        IMPORTS=$(grep -E \"^(from|import)\\s+modules\\.\" \"$file\" 2>/dev/null || true)\n\n        if [[ -n \"$IMPORTS\" ]]; then\n            # Extract module names\n            MODULE_FROM=$(echo \"$file\" | sed -n 's|.*modules/\\([^/]*\\)/.*|\\1|p')\n\n            while IFS= read -r import_line; do\n                MODULE_TO=$(echo \"$import_line\" | sed -n 's|.*modules\\.\\([^./]*\\)\\..*|\\1|p')\n\n                if [[ -n \"$MODULE_FROM\" ]] && [[ -n \"$MODULE_TO\" ]] && [[ \"$MODULE_FROM\" != \"$MODULE_TO\" ]]; then\n                    ADR_REQUIRED=true\n                    REASONS+=(\"Cross-module import: $file imports from modules.$MODULE_TO (current module: $MODULE_FROM)\")\n                fi\n            done <<< \"$IMPORTS\"\n        fi\n    done\nfi\n\n# Check for API contract changes (may require ADR)\nAPI_FILES=$(echo \"$CHANGED_FILES\" | grep -E \"(api/|serializers\\.py|views\\.py)\" || true)\nif [[ -n \"$API_FILES\" ]]; then\n    # Check if OpenAPI schema was updated\n    if ! echo \"$CHANGED_FILES\" | grep -q \"openapi.yaml\"; then\n        REASONS+=(\"API changes detected but openapi.yaml not updated (may require ADR)\")\n    fi\nfi\n\n# Check for schema/migration changes (may require ADR)\nMIGRATION_FILES=$(echo \"$CHANGED_FILES\" | grep -E \"migrations/.*\\.py$\" || true)\nif [[ -n \"$MIGRATION_FILES\" ]]; then\n    # Schema changes often require ADR\n    REASONS+=(\"Database schema changes detected (migrations) - may require ADR\")\nfi\n\n# Summary\necho \"\"\nif [[ \"$ADR_REQUIRED\" == true ]] || [[ ${#REASONS[@]} -gt 0 ]]; then\n    echo -e \"${YELLOW}⚠ ADR may be required${NC}\"\n    echo \"\"\n    echo \"Reasons:\"\n    for reason in \"${REASONS[@]}\"; do\n        echo \"  - $reason\"\n    done\n    echo \"\"\n    echo \"Per Principle 23 (ADR Required When Triggered) and BOUNDARIES.md:\"\n    echo \"  - Cross-feature imports require ADR\"\n    echo \"  - Large exceptions to boundaries require ADR\"\n    echo \"\"\n    echo \"Check if ADR is needed and create one if required:\"\n    echo \"  - Template: .repo/templates/ADR_TEMPLATE.md\"\n    echo \"  - Location: docs/adr/\"\n    exit 1\nelse\n    echo -e \"${GREEN}✓ No ADR triggers detected${NC}\"\n    exit 0\nfi\n"
        },
        {
          "path": "scripts/validate-manifest-commands.sh",
          "type": "Bash",
          "purpose": "Validates commands in manifest exist",
          "used_by": [
            "Governance verification"
          ],
          "content": "#!/bin/bash\n# validate-manifest-commands.sh\n# Validates that commands in repo.manifest.yaml match actual Makefile/package.json commands\n#\n# Usage: ./scripts/validate-manifest-commands.sh\n\nset -euo pipefail\n\nREPO_ROOT=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)\"\ncd \"$REPO_ROOT\"\n\n# Colors\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m'\n\nMANIFEST=\".repo/repo.manifest.yaml\"\nMAKEFILE=\"Makefile\"\nPACKAGE_JSON=\"frontend/package.json\"\n\nERRORS=0\nWARNINGS=0\n\necho \"Validating manifest commands against actual sources...\"\n\n# Check if files exist\nif [[ ! -f \"$MANIFEST\" ]]; then\n    echo -e \"${RED}Error:${NC} Manifest not found: $MANIFEST\"\n    exit 1\nfi\n\n# Extract commands from manifest\nif ! command -v yq &> /dev/null && ! command -v python3 &> /dev/null; then\n    echo -e \"${YELLOW}Warning:${NC} yq or python3 required for YAML parsing. Using basic grep.\"\n    # Basic validation - check if manifest references make commands\n    if grep -q \"make setup\" \"$MANIFEST\"; then\n        if [[ -f \"$MAKEFILE\" ]] && grep -q \"^setup:\" \"$MAKEFILE\"; then\n            echo -e \"${GREEN}✓${NC} 'make setup' exists in Makefile\"\n        else\n            echo -e \"${RED}✗${NC} 'make setup' in manifest but not found in Makefile\"\n            ERRORS=$((ERRORS + 1))\n        fi\n    fi\n\n    if grep -q \"make lint\" \"$MANIFEST\"; then\n        if [[ -f \"$MAKEFILE\" ]] && grep -q \"^lint:\" \"$MAKEFILE\"; then\n            echo -e \"${GREEN}✓${NC} 'make lint' exists in Makefile\"\n        else\n            echo -e \"${YELLOW}⚠${NC} 'make lint' in manifest but not found in Makefile\"\n            WARNINGS=$((WARNINGS + 1))\n        fi\n    fi\n\n    if grep -q \"make verify\" \"$MANIFEST\"; then\n        if [[ -f \"$MAKEFILE\" ]] && grep -q \"^verify:\" \"$MAKEFILE\"; then\n            echo -e \"${GREEN}✓${NC} 'make verify' exists in Makefile\"\n        else\n            echo -e \"${YELLOW}⚠${NC} 'make verify' in manifest but not found in Makefile\"\n            WARNINGS=$((WARNINGS + 1))\n        fi\n    fi\nelse\n    # Use Python for YAML parsing if available\n    if command -v python3 &> /dev/null; then\n        python3 <<EOF\nimport yaml\nimport sys\nimport re\nfrom pathlib import Path\n\nrepo_root = Path(\"$REPO_ROOT\")\nmanifest_path = repo_root / \".repo\" / \"repo.manifest.yaml\"\nmakefile_path = repo_root / \"Makefile\"\npackage_json_path = repo_root / \"package.json\"\n\nerrors = 0\nwarnings = 0\n\n# Load manifest\nwith open(manifest_path) as f:\n    manifest = yaml.safe_load(f)\n\ncommands = manifest.get('commands', {})\n\n# Check Makefile targets\nif makefile_path.exists():\n    with open(makefile_path) as f:\n        makefile_content = f.read()\n\n    # Check each manifest command\n    for cmd_name, cmd_value in commands.items():\n        if not cmd_value or cmd_value == \"<UNKNOWN>\":\n            continue\n\n        # Extract make targets\n        make_matches = re.findall(r'make (\\w+)', cmd_value)\n        for target in make_matches:\n            # Check if target exists in Makefile\n            if re.search(rf'^{target}:', makefile_content, re.MULTILINE):\n                print(f\"✓ '{cmd_name}' -> 'make {target}' exists in Makefile\")\n            else:\n                print(f\"⚠ '{cmd_name}' -> 'make {target}' not found in Makefile\")\n                warnings += 1\n\n# Check package.json scripts\nif package_json_path.exists():\n    import json\n    with open(package_json_path) as f:\n        package_data = json.load(f)\n\n    scripts = package_data.get('scripts', {})\n\n    for cmd_name, cmd_value in commands.items():\n        if not cmd_value:\n            continue\n\n        # Check for npm scripts\n        npm_matches = re.findall(r'npm run (\\w+)', cmd_value)\n        for script in npm_matches:\n            if script in scripts:\n                print(f\"✓ '{cmd_name}' -> 'npm run {script}' exists in package.json\")\n            else:\n                print(f\"⚠ '{cmd_name}' -> 'npm run {script}' not found in package.json\")\n                warnings += 1\n\nsys.exit(0 if errors == 0 and warnings == 0 else 1)\nEOF\n        EXIT_CODE=$?\n        if [[ $EXIT_CODE -ne 0 ]]; then\n            WARNINGS=$((WARNINGS + 1))\n        fi\n    fi\nfi\n\n# Summary\necho \"\"\nif [[ $ERRORS -gt 0 ]]; then\n    echo -e \"${RED}✗ Validation failed with $ERRORS error(s) and $WARNINGS warning(s)${NC}\"\n    exit 1\nelif [[ $WARNINGS -gt 0 ]]; then\n    echo -e \"${YELLOW}⚠ Validation passed with $WARNINGS warning(s)${NC}\"\n    exit 0\nelse\n    echo -e \"${GREEN}✓ All manifest commands validated${NC}\"\n    exit 0\nfi\n"
        },
        {
          "path": "scripts/validate-pr-body.sh",
          "type": "Bash",
          "purpose": "Validates PR body format",
          "used_by": [
            "PR validation"
          ],
          "content": "#!/bin/bash\n# validate-pr-body.sh\n# Validates PR body contains required sections per governance framework\n#\n# Usage: ./scripts/validate-pr-body.sh [pr-body-file] OR reads from stdin\n#   pr-body-file: Path to file containing PR body text\n\nset -euo pipefail\n\nREPO_ROOT=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)\"\ncd \"$REPO_ROOT\"\n\n# Colors\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m'\n\n# Read PR body from file or stdin\nif [[ $# -ge 1 ]] && [[ -f \"$1\" ]]; then\n    PR_BODY=$(cat \"$1\")\nelse\n    PR_BODY=$(cat)\nfi\n\nERRORS=0\nWARNINGS=0\n\n# Required sections per Principle 17: PR Narration\nREQUIRED_SECTIONS=(\n    \"what\"\n    \"why\"\n    \"filepaths\"\n    \"verification\"\n    \"risks\"\n    \"rollback\"\n)\n\necho \"Validating PR body format...\"\n\n# Check for required sections (case-insensitive, flexible matching)\nfor section in \"${REQUIRED_SECTIONS[@]}\"; do\n    if echo \"$PR_BODY\" | grep -qiE \"(^|\\n|##?)\\s*${section}|${section}\\s*:\"; then\n        echo -e \"${GREEN}✓ Found: $section${NC}\"\n    else\n        echo -e \"${RED}✗ Missing: $section${NC}\"\n        ERRORS=$((ERRORS + 1))\n    fi\ndone\n\n# Check for filepaths (Principle: global rule - filepaths required everywhere)\nif echo \"$PR_BODY\" | grep -qE \"(filepath|file path|files?:\\s*|modified files?|changed files?)\" -i; then\n    echo -e \"${GREEN}✓ Filepaths mentioned${NC}\"\nelse\n    echo -e \"${YELLOW}⚠ Filepaths not clearly mentioned (required per global rule)${NC}\"\n    WARNINGS=$((WARNINGS + 1))\nfi\n\n# Check for HITL references if security-related keywords present\nSECURITY_KEYWORDS=(\"security\" \"auth\" \"login\" \"payment\" \"money\" \"credential\" \"secret\" \"token\" \"key\")\nHAS_SECURITY=$(echo \"$PR_BODY\" | grep -qiE \"$(IFS='|'; echo \"${SECURITY_KEYWORDS[*]}\")\" && echo \"yes\" || echo \"no\")\n\nif [[ \"$HAS_SECURITY\" == \"yes\" ]]; then\n    if echo \"$PR_BODY\" | grep -qiE \"(HITL|hitl|human.*loop|human.*required)\"; then\n        echo -e \"${GREEN}✓ Security-related change mentions HITL${NC}\"\n    else\n        echo -e \"${YELLOW}⚠ Security-related change detected but HITL not mentioned (may require HITL per SECURITY_BASELINE.md)${NC}\"\n        WARNINGS=$((WARNINGS + 1))\n    fi\nfi\n\n# Check for task reference (Article 5: Strict Traceability)\nif echo \"$PR_BODY\" | grep -qiE \"(TASK-|task|backlog|todo)\"; then\n    echo -e \"${GREEN}✓ Task reference found${NC}\"\nelse\n    echo -e \"${YELLOW}⚠ No task reference found (required per Article 5: Strict Traceability)${NC}\"\n    WARNINGS=$((WARNINGS + 1))\nfi\n\n# Summary\necho \"\"\nif [[ $ERRORS -gt 0 ]]; then\n    echo -e \"${RED}✗ PR body validation FAILED with $ERRORS error(s) and $WARNINGS warning(s)${NC}\"\n    echo \"\"\n    echo \"Required sections:\"\n    for section in \"${REQUIRED_SECTIONS[@]}\"; do\n        echo \"  - $section\"\n    done\n    exit 1\nelif [[ $WARNINGS -gt 0 ]]; then\n    echo -e \"${YELLOW}⚠ PR body validation passed with $WARNINGS warning(s)${NC}\"\n    exit 0\nelse\n    echo -e \"${GREEN}✓ PR body validation PASSED${NC}\"\n    exit 0\nfi\n"
        },
        {
          "path": "scripts/validate-task-format.sh",
          "type": "Bash",
          "purpose": "Validates task format in TODO.md/BACKLOG.md",
          "used_by": [
            "Task validation"
          ],
          "content": "#!/bin/bash\n# validate-task-format.sh\n# Validates task format in TODO.md, BACKLOG.md, or ARCHIVE.md\n#\n# Usage: ./scripts/validate-task-format.sh [task-file]\n\nset -euo pipefail\n\nREPO_ROOT=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)\"\ncd \"$REPO_ROOT\"\n\n# Colors\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m'\n\n# Validate arguments\nif [[ $# -lt 1 ]]; then\n    echo -e \"${RED}Error:${NC} Missing task file\"\n    echo \"Usage: $0 [task-file]\"\n    echo \"  task-file: .repo/tasks/TODO.md, BACKLOG.md, or ARCHIVE.md\"\n    exit 1\nfi\n\nTASK_FILE=\"$1\"\n\nif [[ ! -f \"$TASK_FILE\" ]]; then\n    echo -e \"${RED}Error:${NC} Task file not found: $TASK_FILE\"\n    exit 1\nfi\n\nERRORS=0\nWARNINGS=0\n\n# Check for task format\necho \"Validating task format in $TASK_FILE...\"\n\n# Check for task headers (### [TASK-XXX])\nTASK_COUNT=$(grep -c \"^### \\[TASK-\" \"$TASK_FILE\" || echo \"0\")\nif [[ \"$TASK_COUNT\" -eq 0 ]]; then\n    echo -e \"${YELLOW}⚠ Warning:${NC} No tasks found in file\"\n    WARNINGS=$((WARNINGS + 1))\nelse\n    echo -e \"${GREEN}✓ Found $TASK_COUNT task(s)${NC}\"\nfi\n\n# Validate each task\nwhile IFS= read -r line; do\n    if [[ \"$line\" =~ ^###\\ \\[TASK- ]]; then\n        TASK_ID=$(echo \"$line\" | sed -n 's/^### \\[\\(TASK-[0-9]*\\)\\].*/\\1/p')\n        TASK_TITLE=$(echo \"$line\" | sed -n 's/^### \\[TASK-[0-9]*\\] \\(.*\\)/\\1/p')\n\n        # Read task block (until next ### or end of file)\n        TASK_BLOCK=\"\"\n        IN_TASK=true\n        while IFS= read -r task_line && [[ \"$IN_TASK\" == true ]]; do\n            if [[ \"$task_line\" =~ ^###\\ \\[TASK- ]] && [[ \"$task_line\" != \"$line\" ]]; then\n                IN_TASK=false\n                break\n            fi\n            TASK_BLOCK+=\"$task_line\"$'\\n'\n        done <<< \"$(tail -n +$(grep -n \"^### \\[TASK-\" \"$TASK_FILE\" | grep -n \"$line\" | cut -d: -f1 | head -1) \"$TASK_FILE\")\"\n\n        # Check required fields\n        if ! echo \"$TASK_BLOCK\" | grep -q \"^\\*\\*Priority:\\*\\*\"; then\n            echo -e \"${RED}✗ $TASK_ID: Missing Priority field${NC}\"\n            ERRORS=$((ERRORS + 1))\n        fi\n\n        if ! echo \"$TASK_BLOCK\" | grep -q \"^\\*\\*Status:\\*\\*\"; then\n            echo -e \"${RED}✗ $TASK_ID: Missing Status field${NC}\"\n            ERRORS=$((ERRORS + 1))\n        fi\n\n        if ! echo \"$TASK_BLOCK\" | grep -q \"^\\*\\*Created:\\*\\*\"; then\n            echo -e \"${RED}✗ $TASK_ID: Missing Created field${NC}\"\n            ERRORS=$((ERRORS + 1))\n        fi\n\n        if ! echo \"$TASK_BLOCK\" | grep -q \"^#### Acceptance Criteria\"; then\n            echo -e \"${YELLOW}⚠ $TASK_ID: Missing Acceptance Criteria section${NC}\"\n            WARNINGS=$((WARNINGS + 1))\n        fi\n\n        # Check priority format\n        PRIORITY=$(echo \"$TASK_BLOCK\" | grep \"^\\*\\*Priority:\\*\\*\" | sed 's/.*\\*\\*Priority:\\*\\* *\\(P[0-3]\\).*/\\1/')\n        if [[ ! \"$PRIORITY\" =~ ^P[0-3]$ ]]; then\n            echo -e \"${RED}✗ $TASK_ID: Invalid priority format (should be P0, P1, P2, or P3)${NC}\"\n            ERRORS=$((ERRORS + 1))\n        fi\n\n        # Check status format\n        STATUS=$(echo \"$TASK_BLOCK\" | grep \"^\\*\\*Status:\\*\\*\" | sed 's/.*\\*\\*Status:\\*\\* *\\([^ ]*\\).*/\\1/')\n        VALID_STATUSES=(\"Pending\" \"In Progress\" \"Completed\" \"Blocked\")\n        if [[ ! \" ${VALID_STATUSES[@]} \" =~ \" ${STATUS} \" ]]; then\n            echo -e \"${YELLOW}⚠ $TASK_ID: Unusual status: $STATUS${NC}\"\n            WARNINGS=$((WARNINGS + 1))\n        fi\n    fi\ndone < \"$TASK_FILE\"\n\n# Summary\necho \"\"\nif [[ $ERRORS -gt 0 ]]; then\n    echo -e \"${RED}✗ Validation FAILED with $ERRORS error(s) and $WARNINGS warning(s)${NC}\"\n    exit 1\nelif [[ $WARNINGS -gt 0 ]]; then\n    echo -e \"${YELLOW}⚠ Validation passed with $WARNINGS warning(s)${NC}\"\n    exit 0\nelse\n    echo -e \"${GREEN}✓ Validation PASSED${NC}\"\n    exit 0\nfi\n"
        },
        {
          "path": "scripts/validate-trace-log.sh",
          "type": "Bash",
          "purpose": "Validates trace log format",
          "used_by": [
            "Trace log validation"
          ],
          "content": "#!/bin/bash\n# validate-trace-log.sh\n# Validates a trace log file against AGENT_TRACE_SCHEMA.json\n#\n# Usage: ./scripts/validate-trace-log.sh [trace-log-file]\n\nset -euo pipefail\n\nREPO_ROOT=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)\"\ncd \"$REPO_ROOT\"\n\n# Colors\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m'\n\n# Validate arguments\nif [[ $# -lt 1 ]]; then\n    echo -e \"${RED}Error:${NC} Missing trace log file\"\n    echo \"Usage: $0 [trace-log-file]\"\n    exit 1\nfi\n\nTRACE_FILE=\"$1\"\nTRACE_SCHEMA=\".repo/templates/AGENT_TRACE_SCHEMA.json\"\n\nif [[ ! -f \"$TRACE_FILE\" ]]; then\n    echo -e \"${RED}Error:${NC} Trace log file not found: $TRACE_FILE\"\n    exit 1\nfi\n\nif [[ ! -f \"$TRACE_SCHEMA\" ]]; then\n    echo -e \"${RED}Error:${NC} Schema file not found: $TRACE_SCHEMA\"\n    exit 1\nfi\n\n# Check if Python is available\nif ! command -v python3 &> /dev/null; then\n    echo -e \"${RED}Error:${NC} Python 3 is required for validation\"\n    exit 1\nfi\n\n# Validate JSON syntax\necho \"Validating JSON syntax...\"\nif ! python3 -m json.tool \"$TRACE_FILE\" > /dev/null 2>&1; then\n    echo -e \"${RED}✗ Invalid JSON syntax${NC}\"\n    python3 -m json.tool \"$TRACE_FILE\" 2>&1 | head -10\n    exit 1\nfi\necho -e \"${GREEN}✓ Valid JSON syntax${NC}\"\n\n# Load schema and trace log\nSCHEMA=$(python3 -c \"import json; print(json.dumps(json.load(open('$TRACE_SCHEMA'))))\" 2>/dev/null)\nTRACE=$(python3 -c \"import json; print(json.dumps(json.load(open('$TRACE_FILE'))))\" 2>/dev/null)\n\n# Check required fields\nREQUIRED_FIELDS=(\"intent\" \"files\" \"commands\" \"evidence\" \"hitl\" \"unknowns\")\nMISSING_FIELDS=()\n\nfor field in \"${REQUIRED_FIELDS[@]}\"; do\n    if ! echo \"$TRACE\" | python3 -c \"import sys, json; data=json.load(sys.stdin); sys.exit(0 if '$field' in data else 1)\" 2>/dev/null; then\n        MISSING_FIELDS+=(\"$field\")\n    fi\ndone\n\nif [[ ${#MISSING_FIELDS[@]} -gt 0 ]]; then\n    echo -e \"${RED}✗ Missing required fields:${NC} ${MISSING_FIELDS[*]}\"\n    exit 1\nfi\necho -e \"${GREEN}✓ All required fields present${NC}\"\n\n# Validate field types\necho \"Validating field types...\"\n\n# Check files is array\nif ! echo \"$TRACE\" | python3 -c \"import sys, json; data=json.load(sys.stdin); sys.exit(0 if isinstance(data.get('files'), list) else 1)\" 2>/dev/null; then\n    echo -e \"${RED}✗ 'files' must be an array${NC}\"\n    exit 1\nfi\n\n# Check commands is array\nif ! echo \"$TRACE\" | python3 -c \"import sys, json; data=json.load(sys.stdin); sys.exit(0 if isinstance(data.get('commands'), list) else 1)\" 2>/dev/null; then\n    echo -e \"${RED}✗ 'commands' must be an array${NC}\"\n    exit 1\nfi\n\n# Check evidence is array\nif ! echo \"$TRACE\" | python3 -c \"import sys, json; data=json.load(sys.stdin); sys.exit(0 if isinstance(data.get('evidence'), list) else 1)\" 2>/dev/null; then\n    echo -e \"${RED}✗ 'evidence' must be an array${NC}\"\n    exit 1\nfi\n\n# Check hitl is array\nif ! echo \"$TRACE\" | python3 -c \"import sys, json; data=json.load(sys.stdin); sys.exit(0 if isinstance(data.get('hitl'), list) else 1)\" 2>/dev/null; then\n    echo -e \"${RED}✗ 'hitl' must be an array${NC}\"\n    exit 1\nfi\n\n# Check unknowns is array\nif ! echo \"$TRACE\" | python3 -c \"import sys, json; data=json.load(sys.stdin); sys.exit(0 if isinstance(data.get('unknowns'), list) else 1)\" 2>/dev/null; then\n    echo -e \"${RED}✗ 'unknowns' must be an array${NC}\"\n    exit 1\nfi\n\n# Check intent is string\nif ! echo \"$TRACE\" | python3 -c \"import sys, json; data=json.load(sys.stdin); sys.exit(0 if isinstance(data.get('intent'), str) else 1)\" 2>/dev/null; then\n    echo -e \"${RED}✗ 'intent' must be a string${NC}\"\n    exit 1\nfi\n\necho -e \"${GREEN}✓ All field types valid${NC}\"\n\n# Summary\necho \"\"\necho -e \"${GREEN}✓ Trace log validation PASSED${NC}\"\necho \"  File: $TRACE_FILE\"\necho \"  Schema: $TRACE_SCHEMA\"\n"
        },
        {
          "path": "scripts/check-expired-waivers.sh",
          "type": "Bash",
          "purpose": "Checks for expired waivers",
          "used_by": [
            "Governance verification"
          ],
          "content": "#!/bin/bash\n# check-expired-waivers.sh\n# Checks for expired waivers and reports them\n#\n# Usage: ./scripts/check-expired-waivers.sh\n\nset -euo pipefail\n\nREPO_ROOT=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)\"\ncd \"$REPO_ROOT\"\n\n# Colors\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m'\n\nWAIVER_INDEX=\".repo/policy/WAIVERS.md\"\nWAIVER_DIR=\".repo/waivers\"\nTODAY=$(date +%Y-%m-%d)\n\nif [[ ! -f \"$WAIVER_INDEX\" ]]; then\n    echo \"No waivers file found: $WAIVER_INDEX\"\n    exit 0\nfi\n\nEXPIRED_COUNT=0\nEXPIRING_SOON_COUNT=0\nEXPIRING_SOON_DAYS=7\n\necho \"Checking for expired waivers...\"\necho \"Today: $TODAY\"\necho \"\"\n\n# Parse active waivers table\nwhile IFS='|' read -r id what owner expires status filepath; do\n    # Skip header and separator lines\n    [[ \"$id\" =~ \"ID\" ]] && continue\n    [[ \"$id\" =~ \"---\" ]] && continue\n    [[ -z \"$id\" ]] && continue\n\n    id=$(echo \"$id\" | xargs)\n    expires=$(echo \"$expires\" | xargs)\n\n    if [[ -z \"$expires\" ]] || [[ \"$expires\" == \"[SET EXPIRATION DATE]\" ]]; then\n        echo -e \"${YELLOW}⚠ Waiver $id has no expiration date set${NC}\"\n        continue\n    fi\n\n    # Compare dates\n    if [[ \"$expires\" < \"$TODAY\" ]]; then\n        echo -e \"${RED}✗ EXPIRED: $id (expired on $expires)${NC}\"\n        EXPIRED_COUNT=$((EXPIRED_COUNT + 1))\n    elif [[ \"$expires\" == \"$TODAY\" ]]; then\n        echo -e \"${YELLOW}⚠ EXPIRES TODAY: $id${NC}\"\n        EXPIRING_SOON_COUNT=$((EXPIRING_SOON_COUNT + 1))\n    else\n        # Calculate days until expiration\n        EXPIRES_EPOCH=$(date -d \"$expires\" +%s 2>/dev/null || echo \"0\")\n        TODAY_EPOCH=$(date -d \"$TODAY\" +%s 2>/dev/null || echo \"0\")\n\n        if [[ $EXPIRES_EPOCH -gt 0 ]] && [[ $TODAY_EPOCH -gt 0 ]]; then\n            DAYS_LEFT=$(( (EXPIRES_EPOCH - TODAY_EPOCH) / 86400 ))\n            if [[ $DAYS_LEFT -le $EXPIRING_SOON_DAYS ]] && [[ $DAYS_LEFT -gt 0 ]]; then\n                echo -e \"${YELLOW}⚠ Expires soon: $id (expires in $DAYS_LEFT days on $expires)${NC}\"\n                EXPIRING_SOON_COUNT=$((EXPIRING_SOON_COUNT + 1))\n            fi\n        fi\n    fi\ndone < <(grep -A 1000 \"## Active Waivers\" \"$WAIVER_INDEX\" | grep \"^|\" | head -100)\n\necho \"\"\nif [[ $EXPIRED_COUNT -gt 0 ]]; then\n    echo -e \"${RED}Found $EXPIRED_COUNT expired waiver(s)${NC}\"\n    echo \"Expired waivers should be archived or renewed.\"\n    exit 1\nelif [[ $EXPIRING_SOON_COUNT -gt 0 ]]; then\n    echo -e \"${YELLOW}Found $EXPIRING_SOON_COUNT waiver(s) expiring soon${NC}\"\n    exit 0\nelse\n    echo -e \"${GREEN}✓ No expired waivers found${NC}\"\n    exit 0\nfi\n"
        },
        {
          "path": "scripts/archive-hitl-items.sh",
          "type": "Bash",
          "purpose": "Archives completed HITL items",
          "used_by": [
            "HITL maintenance"
          ],
          "content": "#!/bin/bash\n# archive-hitl-items.sh\n# Archives completed or superseded HITL items from Active to Archived table\n#\n# Usage: ./scripts/archive-hitl-items.sh [--dry-run]\n#   --dry-run: Show what would be archived without making changes\n\nset -euo pipefail\n\nREPO_ROOT=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)\"\ncd \"$REPO_ROOT\"\n\n# Colors\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m'\n\nDRY_RUN=false\nif [[ \"${1:-}\" == \"--dry-run\" ]]; then\n    DRY_RUN=true\n    echo -e \"${YELLOW}DRY RUN MODE: No changes will be made${NC}\\n\"\nfi\n\nHITL_INDEX=\".repo/policy/HITL.md\"\nHITL_DIR=\".repo/hitl\"\nTODAY=$(date +%Y-%m-%d)\n\nif [[ ! -f \"$HITL_INDEX\" ]]; then\n    echo -e \"${RED}Error:${NC} HITL index not found: $HITL_INDEX\"\n    exit 1\nfi\n\nARCHIVED_COUNT=0\n\n# Parse active HITL items and find completed/superseded ones\necho \"Checking for HITL items to archive...\"\n\n# Read HITL.md and process\nTEMP_FILE=$(mktemp)\nIN_ACTIVE_TABLE=false\nIN_ARCHIVED_TABLE=false\nARCHIVED_ITEMS=()\n\nwhile IFS= read -r line; do\n    # Detect table sections\n    if [[ \"$line\" =~ \"### Active\" ]]; then\n        IN_ACTIVE_TABLE=true\n        IN_ARCHIVED_TABLE=false\n        echo \"$line\" >> \"$TEMP_FILE\"\n        # Print header\n        read -r header_line\n        echo \"$header_line\" >> \"$TEMP_FILE\"\n        read -r separator_line\n        echo \"$separator_line\" >> \"$TEMP_FILE\"\n        continue\n    fi\n\n    if [[ \"$line\" =~ \"### Archived\" ]]; then\n        IN_ACTIVE_TABLE=false\n        IN_ARCHIVED_TABLE=true\n        echo \"$line\" >> \"$TEMP_FILE\"\n        # Print header\n        read -r header_line\n        echo \"$header_line\" >> \"$TEMP_FILE\"\n        read -r separator_line\n        echo \"$separator_line\" >> \"$TEMP_FILE\"\n        continue\n    fi\n\n    # Process active table rows\n    if [[ \"$IN_ACTIVE_TABLE\" == true ]] && [[ \"$line\" =~ ^\\| ]]; then\n        # Skip header/separator\n        if [[ \"$line\" =~ \"^\\|.*ID\\|\" ]] || [[ \"$line\" =~ \"^\\|.*---\\|\" ]]; then\n            echo \"$line\" >> \"$TEMP_FILE\"\n            continue\n        fi\n\n        # Parse row: |ID|Category|Status|Summary|Filepath|\n        IFS='|' read -r -a fields <<< \"$line\"\n        if [[ ${#fields[@]} -ge 4 ]]; then\n            HITL_ID=$(echo \"${fields[1]}\" | xargs)\n            STATUS=$(echo \"${fields[3]}\" | xargs)\n\n            # Check if item should be archived\n            if [[ \"$STATUS\" == \"Completed\" ]] || [[ \"$STATUS\" == \"Superseded\" ]]; then\n                ARCHIVED_ITEMS+=(\"$line\")\n                ARCHIVED_COUNT=$((ARCHIVED_COUNT + 1))\n\n                # Update HITL item file\n                HITL_FILE=\"$HITL_DIR/$HITL_ID.md\"\n                if [[ -f \"$HITL_FILE\" ]]; then\n                    if [[ \"$DRY_RUN\" == false ]]; then\n                        # Add Archived On date if not present\n                        if ! grep -q \"^\\*\\*Archived On:\\*\\*\" \"$HITL_FILE\"; then\n                            sed -i \"/^## Notes/a\\\\\n\\\\\n**Archived On:** $TODAY\" \"$HITL_FILE\"\n                        fi\n                    fi\n                    echo -e \"${GREEN}✓${NC} Would archive: $HITL_ID ($STATUS)\"\n                fi\n            else\n                # Keep in active table\n                echo \"$line\" >> \"$TEMP_FILE\"\n            fi\n        else\n            echo \"$line\" >> \"$TEMP_FILE\"\n        fi\n    # Process archived table - append new items\n    elif [[ \"$IN_ARCHIVED_TABLE\" == true ]] && [[ \"$line\" =~ ^\\| ]]; then\n        echo \"$line\" >> \"$TEMP_FILE\"\n        # Append archived items after existing archived items\n        if [[ ${#ARCHIVED_ITEMS[@]} -gt 0 ]] && [[ ! \"$line\" =~ \"^\\|.*ID\\|\" ]] && [[ ! \"$line\" =~ \"^\\|.*---\\|\" ]]; then\n            # Check if this is the last archived item\n            # (Simple heuristic: if next line is not a table row, we're at the end)\n            for archived_line in \"${ARCHIVED_ITEMS[@]}\"; do\n                echo \"$archived_line\" >> \"$TEMP_FILE\"\n            done\n            ARCHIVED_ITEMS=()  # Clear so we don't duplicate\n        fi\n    else\n        echo \"$line\" >> \"$TEMP_FILE\"\n    fi\ndone < \"$HITL_INDEX\"\n\n# Append any remaining archived items at the end of archived table\nif [[ ${#ARCHIVED_ITEMS[@]} -gt 0 ]]; then\n    # Find where archived table ends and append\n    sed -i '/^### Archived/,/^## / {\n        /^## /{\n            i\\\n'\"$(printf '%s\\n' \"${ARCHIVED_ITEMS[@]}\")\"\n        }\n    }' \"$TEMP_FILE\" 2>/dev/null || {\n        # Fallback: append at end of file\n        for archived_line in \"${ARCHIVED_ITEMS[@]}\"; do\n            echo \"$archived_line\" >> \"$TEMP_FILE\"\n        done\n    }\nfi\n\n# Summary\necho \"\"\nif [[ $ARCHIVED_COUNT -gt 0 ]]; then\n    if [[ \"$DRY_RUN\" == true ]]; then\n        echo -e \"${YELLOW}Would archive $ARCHIVED_COUNT HITL item(s)${NC}\"\n        echo \"Run without --dry-run to apply changes\"\n    else\n        # Replace original file\n        mv \"$TEMP_FILE\" \"$HITL_INDEX\"\n        echo -e \"${GREEN}✓ Archived $ARCHIVED_COUNT HITL item(s)${NC}\"\n        echo \"Updated: $HITL_INDEX\"\n    fi\nelse\n    rm \"$TEMP_FILE\"\n    echo -e \"${GREEN}✓ No HITL items to archive${NC}\"\nfi\n\nexit 0\n"
        },
        {
          "path": "scripts/suggest-waiver.sh",
          "type": "Bash",
          "purpose": "Suggests waiver for gate failure",
          "used_by": [
            "Governance verification"
          ],
          "content": "#!/bin/bash\n# suggest-waiver.sh\n# Suggests waiver creation based on governance-verify failures\n#\n# Usage: ./scripts/suggest-waiver.sh [governance-verify-output-file]\n#   If no file provided, runs governance-verify and captures output\n\nset -euo pipefail\n\nREPO_ROOT=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)\"\ncd \"$REPO_ROOT\"\n\n# Colors\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nBLUE='\\033[0;34m'\nNC='\\033[0m'\n\nif [[ $# -ge 1 ]] && [[ -f \"$1\" ]]; then\n    VERIFY_OUTPUT=$(cat \"$1\")\nelse\n    # Run governance-verify and capture output\n    VERIFY_OUTPUT=$(./scripts/governance-verify.sh 2>&1 || true)\nfi\n\nWAIVERABLE_FAILURES=()\nFAILURE_TYPE=\"\"\n\n# Parse governance-verify output for waiverable failures\nwhile IFS= read -r line; do\n    # Check for waiverable gate failures\n    if echo \"$line\" | grep -qiE \"(warning|waiverable|coverage|performance|bundle|budget)\"; then\n        WAIVERABLE_FAILURES+=(\"$line\")\n    fi\n\n    # Detect failure type\n    if echo \"$line\" | grep -qiE \"coverage\"; then\n        FAILURE_TYPE=\"coverage\"\n    elif echo \"$line\" | grep -qiE \"(performance|bundle|budget)\"; then\n        FAILURE_TYPE=\"performance\"\n    elif echo \"$line\" | grep -qiE \"warning\"; then\n        FAILURE_TYPE=\"warnings\"\n    fi\ndone <<< \"$VERIFY_OUTPUT\"\n\nif [[ ${#WAIVERABLE_FAILURES[@]} -eq 0 ]]; then\n    echo -e \"${GREEN}✓ No waiverable failures detected${NC}\"\n    exit 0\nfi\n\necho -e \"${YELLOW}⚠ Waiverable failures detected${NC}\"\necho \"\"\necho \"The following failures may be waived:\"\nfor failure in \"${WAIVERABLE_FAILURES[@]}\"; do\n    echo \"  - $failure\"\ndone\necho \"\"\n\n# Generate waiver suggestion\nWAIVER_ID=$(./scripts/get-next-task-number.sh | sed 's/TASK/WAIVER/')\nWHAT_WAIVES=\"\"\nWHY=\"\"\n\ncase \"$FAILURE_TYPE\" in\n    coverage)\n        WHAT_WAIVES=\"Coverage target (gradual ratchet)\"\n        WHY=\"Temporary coverage reduction during refactoring/feature development\"\n        ;;\n    performance)\n        WHAT_WAIVES=\"Performance/bundle budget\"\n        WHY=\"Temporary budget exceedance with remediation plan\"\n        ;;\n    warnings)\n        WHAT_WAIVES=\"Warning budget (zero warnings)\"\n        WHY=\"Temporary warnings with fix timeline\"\n        ;;\n    *)\n        WHAT_WAIVES=\"Quality gate failure\"\n        WHY=\"Temporary exception with remediation plan\"\n        ;;\nesac\n\necho -e \"${BLUE}Suggested waiver:${NC}\"\necho \"\"\necho \"Waiver ID: $WAIVER_ID\"\necho \"What it waives: $WHAT_WAIVES\"\necho \"Why: $WHY\"\necho \"\"\necho \"To create this waiver, run:\"\necho -e \"${GREEN}./scripts/create-waiver.sh \\\"$WAIVER_ID\\\" \\\"$WHAT_WAIVES\\\" \\\"$WHY\\\"${NC}\"\necho \"\"\necho \"Or create manually with details:\"\necho \"  - Scope: [Describe what this waiver covers]\"\necho \"  - Remediation plan: [How will this be fixed? Timeline?]\"\necho \"  - Expiration: [Set expiration date]\"\n"
        },
        {
          "path": "scripts/generate-metrics.sh",
          "type": "Bash",
          "purpose": "Generates metrics from agent logs",
          "used_by": [
            "Metrics generation"
          ],
          "content": "#!/bin/bash\n# generate-metrics.sh\n# Generates metrics report for governance framework\n#\n# Usage: ./scripts/generate-metrics.sh [output-format]\n#   output-format: json, markdown, or text (default: markdown)\n\nset -euo pipefail\n\nREPO_ROOT=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)\"\ncd \"$REPO_ROOT\"\n\n# Colors\nGREEN='\\033[0;32m'\nNC='\\033[0m'\n\nOUTPUT_FORMAT=\"${1:-markdown}\"\n\n# Gather metrics\nTODAY=$(date +%Y-%m-%d)\n\n# Task metrics\nTODO_COUNT=$(grep -c \"^### \\[TASK-\" \".repo/tasks/TODO.md\" 2>/dev/null || echo \"0\")\nBACKLOG_COUNT=$(grep -c \"^### \\[TASK-\" \".repo/tasks/BACKLOG.md\" 2>/dev/null || echo \"0\")\nARCHIVE_COUNT=$(grep -c \"^### \\[TASK-\" \".repo/tasks/ARCHIVE.md\" 2>/dev/null || echo \"0\")\n\n# Count by priority\nP0_BACKLOG=$(grep -A 5 \"^### \\[TASK-\" \".repo/tasks/BACKLOG.md\" 2>/dev/null | grep -c \"P0\" || echo \"0\")\nP1_BACKLOG=$(grep -A 5 \"^### \\[TASK-\" \".repo/tasks/BACKLOG.md\" 2>/dev/null | grep -c \"P1\" || echo \"0\")\nP2_BACKLOG=$(grep -A 5 \"^### \\[TASK-\" \".repo/tasks/BACKLOG.md\" 2>/dev/null | grep -c \"P2\" || echo \"0\")\nP3_BACKLOG=$(grep -A 5 \"^### \\[TASK-\" \".repo/tasks/BACKLOG.md\" 2>/dev/null | grep -c \"P3\" || echo \"0\")\n\n# HITL metrics\nHITL_ACTIVE=$(grep -c \"^|HITL-\" \".repo/policy/HITL.md\" 2>/dev/null || echo \"0\")\nHITL_PENDING=$(grep \"|.*Pending\" \".repo/policy/HITL.md\" 2>/dev/null | grep -c \"Pending\" || echo \"0\")\nHITL_COMPLETED=$(grep \"|.*Completed\" \".repo/policy/HITL.md\" 2>/dev/null | grep -c \"Completed\" || echo \"0\")\nHITL_TOTAL=$(find \".repo/hitl\" -name \"HITL-*.md\" 2>/dev/null | wc -l | tr -d ' ' || echo \"0\")\n\n# Waiver metrics\nif [[ -f \".repo/policy/WAIVERS.md\" ]]; then\n    WAIVER_ACTIVE=$(grep -c \"^|WAIVER-\" \".repo/policy/WAIVERS.md\" 2>/dev/null || echo \"0\")\n    WAIVER_EXPIRED=0\n    if [[ -f \"scripts/check-expired-waivers.sh\" ]]; then\n        WAIVER_EXPIRED=$(./scripts/check-expired-waivers.sh 2>&1 | grep -c \"EXPIRED\" || echo \"0\")\n    fi\nelse\n    WAIVER_ACTIVE=0\n    WAIVER_EXPIRED=0\nfi\n\n# Trace log metrics\nTRACE_COUNT=$(find \".repo/traces\" -name \"*.json\" 2>/dev/null | wc -l | tr -d ' ' || echo \"0\")\n\n# Agent log metrics\nLOG_COUNT=$(find \".repo/logs\" -name \"*.json\" 2>/dev/null | wc -l | tr -d ' ' || echo \"0\")\n\n# ADR metrics\nADR_COUNT=$(find \"docs/adr\" -name \"ADR-*.md\" 2>/dev/null | wc -l | tr -d ' ' || echo \"0\")\n\n# Generate output\ncase \"$OUTPUT_FORMAT\" in\n    json)\n        cat <<EOF\n{\n  \"date\": \"$TODAY\",\n  \"tasks\": {\n    \"todo\": $TODO_COUNT,\n    \"backlog\": $BACKLOG_COUNT,\n    \"archive\": $ARCHIVE_COUNT,\n    \"by_priority\": {\n      \"p0\": $P0_BACKLOG,\n      \"p1\": $P1_BACKLOG,\n      \"p2\": $P2_BACKLOG,\n      \"p3\": $P3_BACKLOG\n    }\n  },\n  \"hitl\": {\n    \"active\": $HITL_ACTIVE,\n    \"pending\": $HITL_PENDING,\n    \"completed\": $HITL_COMPLETED,\n    \"total\": $HITL_TOTAL\n  },\n  \"waivers\": {\n    \"active\": $WAIVER_ACTIVE,\n    \"expired\": $WAIVER_EXPIRED\n  },\n  \"artifacts\": {\n    \"trace_logs\": $TRACE_COUNT,\n    \"agent_logs\": $LOG_COUNT,\n    \"adrs\": $ADR_COUNT\n  }\n}\nEOF\n        ;;\n    markdown)\n        cat <<EOF\n# Governance Framework Metrics\n\n**Generated:** $TODAY\n\n## Tasks\n\n| Metric | Count |\n|--------|-------|\n| Active (TODO) | $TODO_COUNT |\n| Backlog | $BACKLOG_COUNT |\n| Archived | $ARCHIVE_COUNT |\n| **Total** | **$((TODO_COUNT + BACKLOG_COUNT + ARCHIVE_COUNT))** |\n\n### Backlog by Priority\n\n| Priority | Count |\n|----------|-------|\n| P0 (Critical) | $P0_BACKLOG |\n| P1 (High) | $P1_BACKLOG |\n| P2 (Medium) | $P2_BACKLOG |\n| P3 (Low) | $P3_BACKLOG |\n\n## HITL Items\n\n| Metric | Count |\n|--------|-------|\n| Active | $HITL_ACTIVE |\n| Pending | $HITL_PENDING |\n| Completed | $HITL_COMPLETED |\n| Total Files | $HITL_TOTAL |\n\n## Waivers\n\n| Metric | Count |\n|--------|-------|\n| Active | $WAIVER_ACTIVE |\n| Expired | $WAIVER_EXPIRED |\n\n## Artifacts\n\n| Type | Count |\n|------|-------|\n| Trace Logs | $TRACE_COUNT |\n| Agent Logs | $LOG_COUNT |\n| ADRs | $ADR_COUNT |\n\n---\n*Run \\`./scripts/generate-metrics.sh\\` to regenerate this report*\nEOF\n        ;;\n    text)\n        cat <<EOF\nGovernance Framework Metrics\nGenerated: $TODAY\n\nTASKS:\n  Active (TODO): $TODO_COUNT\n  Backlog: $BACKLOG_COUNT\n  Archived: $ARCHIVE_COUNT\n  Total: $((TODO_COUNT + BACKLOG_COUNT + ARCHIVE_COUNT))\n\n  Backlog by Priority:\n    P0 (Critical): $P0_BACKLOG\n    P1 (High): $P1_BACKLOG\n    P2 (Medium): $P2_BACKLOG\n    P3 (Low): $P3_BACKLOG\n\nHITL ITEMS:\n  Active: $HITL_ACTIVE\n  Pending: $HITL_PENDING\n  Completed: $HITL_COMPLETED\n  Total Files: $HITL_TOTAL\n\nWAIVERS:\n  Active: $WAIVER_ACTIVE\n  Expired: $WAIVER_EXPIRED\n\nARTIFACTS:\n  Trace Logs: $TRACE_COUNT\n  Agent Logs: $LOG_COUNT\n  ADRs: $ADR_COUNT\nEOF\n        ;;\n    *)\n        echo \"Unknown output format: $OUTPUT_FORMAT\"\n        echo \"Supported formats: json, markdown, text\"\n        exit 1\n        ;;\nesac\n"
        },
        {
          "path": "scripts/generate-dashboard.sh",
          "type": "Bash",
          "purpose": "Generates dashboard from metrics",
          "used_by": [
            "Dashboard generation"
          ],
          "content": "#!/bin/bash\n# generate-dashboard.sh\n# Generates an HTML dashboard from metrics\n#\n# Usage: ./scripts/generate-dashboard.sh [output-file]\n#   output-file: Path to HTML file (default: .repo/dashboard.html)\n\nset -euo pipefail\n\nREPO_ROOT=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)\"\ncd \"$REPO_ROOT\"\n\nOUTPUT_FILE=\"${1:-.repo/dashboard.html}\"\n\n# Generate metrics in JSON format\nMETRICS_JSON=$(./scripts/generate-metrics.sh json)\n\n# Extract values (using basic parsing since we control the format)\nTODAY=$(date +%Y-%m-%d)\n\n# Create HTML dashboard\ncat > \"$OUTPUT_FILE\" <<'EOF'\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Governance Framework Dashboard</title>\n    <style>\n        * {\n            margin: 0;\n            padding: 0;\n            box-sizing: border-box;\n        }\n        body {\n            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;\n            background: #f5f5f5;\n            color: #333;\n            padding: 20px;\n        }\n        .container {\n            max-width: 1200px;\n            margin: 0 auto;\n        }\n        header {\n            background: white;\n            padding: 20px;\n            border-radius: 8px;\n            margin-bottom: 20px;\n            box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n        }\n        h1 {\n            color: #2c3e50;\n            margin-bottom: 10px;\n        }\n        .subtitle {\n            color: #7f8c8d;\n            font-size: 14px;\n        }\n        .grid {\n            display: grid;\n            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));\n            gap: 20px;\n            margin-bottom: 20px;\n        }\n        .card {\n            background: white;\n            padding: 20px;\n            border-radius: 8px;\n            box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n        }\n        .card h2 {\n            color: #2c3e50;\n            font-size: 18px;\n            margin-bottom: 15px;\n            border-bottom: 2px solid #3498db;\n            padding-bottom: 10px;\n        }\n        .metric {\n            display: flex;\n            justify-content: space-between;\n            padding: 10px 0;\n            border-bottom: 1px solid #ecf0f1;\n        }\n        .metric:last-child {\n            border-bottom: none;\n        }\n        .metric-label {\n            color: #7f8c8d;\n        }\n        .metric-value {\n            font-weight: bold;\n            color: #2c3e50;\n        }\n        .metric-value.high {\n            color: #27ae60;\n        }\n        .metric-value.medium {\n            color: #f39c12;\n        }\n        .metric-value.low {\n            color: #e74c3c;\n        }\n        .progress-bar {\n            width: 100%;\n            height: 20px;\n            background: #ecf0f1;\n            border-radius: 10px;\n            overflow: hidden;\n            margin-top: 10px;\n        }\n        .progress-fill {\n            height: 100%;\n            background: linear-gradient(90deg, #3498db, #2ecc71);\n            transition: width 0.3s ease;\n        }\n        .status-badge {\n            display: inline-block;\n            padding: 4px 8px;\n            border-radius: 4px;\n            font-size: 12px;\n            font-weight: bold;\n        }\n        .status-pending {\n            background: #fff3cd;\n            color: #856404;\n        }\n        .status-completed {\n            background: #d4edda;\n            color: #155724;\n        }\n        .status-active {\n            background: #d1ecf1;\n            color: #0c5460;\n        }\n        table {\n            width: 100%;\n            border-collapse: collapse;\n            margin-top: 10px;\n        }\n        th, td {\n            padding: 10px;\n            text-align: left;\n            border-bottom: 1px solid #ecf0f1;\n        }\n        th {\n            background: #f8f9fa;\n            font-weight: 600;\n            color: #2c3e50;\n        }\n        .footer {\n            text-align: center;\n            padding: 20px;\n            color: #7f8c8d;\n            font-size: 12px;\n        }\n        .refresh-btn {\n            background: #3498db;\n            color: white;\n            border: none;\n            padding: 10px 20px;\n            border-radius: 4px;\n            cursor: pointer;\n            font-size: 14px;\n            margin-top: 10px;\n        }\n        .refresh-btn:hover {\n            background: #2980b9;\n        }\n    </style>\n</head>\n<body>\n    <div class=\"container\">\n        <header>\n            <h1>📊 Governance Framework Dashboard</h1>\n            <div class=\"subtitle\">Generated: <span id=\"timestamp\"></span></div>\n            <button class=\"refresh-btn\" onclick=\"location.reload()\">🔄 Refresh</button>\n        </header>\n\n        <div class=\"grid\">\n            <div class=\"card\">\n                <h2>📋 Tasks</h2>\n                <div class=\"metric\">\n                    <span class=\"metric-label\">Active (TODO)</span>\n                    <span class=\"metric-value\" id=\"todo-count\">-</span>\n                </div>\n                <div class=\"metric\">\n                    <span class=\"metric-label\">Backlog</span>\n                    <span class=\"metric-value\" id=\"backlog-count\">-</span>\n                </div>\n                <div class=\"metric\">\n                    <span class=\"metric-label\">Archived</span>\n                    <span class=\"metric-value\" id=\"archive-count\">-</span>\n                </div>\n                <div class=\"metric\">\n                    <span class=\"metric-label\">Total</span>\n                    <span class=\"metric-value high\" id=\"total-tasks\">-</span>\n                </div>\n            </div>\n\n            <div class=\"card\">\n                <h2>🎯 Backlog by Priority</h2>\n                <div class=\"metric\">\n                    <span class=\"metric-label\">P0 (Critical)</span>\n                    <span class=\"metric-value low\" id=\"p0-count\">-</span>\n                </div>\n                <div class=\"metric\">\n                    <span class=\"metric-label\">P1 (High)</span>\n                    <span class=\"metric-value medium\" id=\"p1-count\">-</span>\n                </div>\n                <div class=\"metric\">\n                    <span class=\"metric-label\">P2 (Medium)</span>\n                    <span class=\"metric-value\" id=\"p2-count\">-</span>\n                </div>\n                <div class=\"metric\">\n                    <span class=\"metric-label\">P3 (Low)</span>\n                    <span class=\"metric-value\" id=\"p3-count\">-</span>\n                </div>\n            </div>\n\n            <div class=\"card\">\n                <h2>👤 HITL Items</h2>\n                <div class=\"metric\">\n                    <span class=\"metric-label\">Active</span>\n                    <span class=\"metric-value\" id=\"hitl-active\">-</span>\n                </div>\n                <div class=\"metric\">\n                    <span class=\"metric-label\">Pending</span>\n                    <span class=\"metric-value medium\" id=\"hitl-pending\">-</span>\n                </div>\n                <div class=\"metric\">\n                    <span class=\"metric-label\">Completed</span>\n                    <span class=\"metric-value high\" id=\"hitl-completed\">-</span>\n                </div>\n                <div class=\"metric\">\n                    <span class=\"metric-label\">Total Files</span>\n                    <span class=\"metric-value\" id=\"hitl-total\">-</span>\n                </div>\n            </div>\n\n            <div class=\"card\">\n                <h2>📝 Waivers</h2>\n                <div class=\"metric\">\n                    <span class=\"metric-label\">Active</span>\n                    <span class=\"metric-value\" id=\"waiver-active\">-</span>\n                </div>\n                <div class=\"metric\">\n                    <span class=\"metric-label\">Expired</span>\n                    <span class=\"metric-value low\" id=\"waiver-expired\">-</span>\n                </div>\n            </div>\n\n            <div class=\"card\">\n                <h2>📦 Artifacts</h2>\n                <div class=\"metric\">\n                    <span class=\"metric-label\">Trace Logs</span>\n                    <span class=\"metric-value\" id=\"trace-count\">-</span>\n                </div>\n                <div class=\"metric\">\n                    <span class=\"metric-label\">Agent Logs</span>\n                    <span class=\"metric-value\" id=\"log-count\">-</span>\n                </div>\n                <div class=\"metric\">\n                    <span class=\"metric-label\">ADRs</span>\n                    <span class=\"metric-value\" id=\"adr-count\">-</span>\n                </div>\n            </div>\n        </div>\n\n        <div class=\"footer\">\n            <p>Dashboard generated by governance framework | Run <code>./scripts/generate-dashboard.sh</code> to regenerate</p>\n        </div>\n    </div>\n\n    <script>\n        // Parse metrics JSON and populate dashboard\n        const metrics = JSON.parse(`METRICS_PLACEHOLDER`);\n\n        // Update timestamp\n        document.getElementById('timestamp').textContent = metrics.date || new Date().toLocaleString();\n\n        // Tasks\n        document.getElementById('todo-count').textContent = metrics.tasks.todo || 0;\n        document.getElementById('backlog-count').textContent = metrics.tasks.backlog || 0;\n        document.getElementById('archive-count').textContent = metrics.tasks.archive || 0;\n        document.getElementById('total-tasks').textContent =\n            (metrics.tasks.todo || 0) + (metrics.tasks.backlog || 0) + (metrics.tasks.archive || 0);\n\n        // Priorities\n        document.getElementById('p0-count').textContent = metrics.tasks.by_priority.p0 || 0;\n        document.getElementById('p1-count').textContent = metrics.tasks.by_priority.p1 || 0;\n        document.getElementById('p2-count').textContent = metrics.tasks.by_priority.p2 || 0;\n        document.getElementById('p3-count').textContent = metrics.tasks.by_priority.p3 || 0;\n\n        // HITL\n        document.getElementById('hitl-active').textContent = metrics.hitl.active || 0;\n        document.getElementById('hitl-pending').textContent = metrics.hitl.pending || 0;\n        document.getElementById('hitl-completed').textContent = metrics.hitl.completed || 0;\n        document.getElementById('hitl-total').textContent = metrics.hitl.total || 0;\n\n        // Waivers\n        document.getElementById('waiver-active').textContent = metrics.waivers.active || 0;\n        document.getElementById('waiver-expired').textContent = metrics.waivers.expired || 0;\n\n        // Artifacts\n        document.getElementById('trace-count').textContent = metrics.artifacts.trace_logs || 0;\n        document.getElementById('log-count').textContent = metrics.artifacts.agent_logs || 0;\n        document.getElementById('adr-count').textContent = metrics.artifacts.adrs || 0;\n    </script>\n</body>\n</html>\nEOF\n\n# Replace placeholder with actual JSON\n# Use Python for safe JSON embedding\npython3 <<PYTHON_SCRIPT\nimport json\nimport re\n\nmetrics_json = '''$METRICS_JSON'''\n\n# Read the HTML file\nwith open('$OUTPUT_FILE', 'r', encoding='utf-8') as f:\n    html_content = f.read()\n\n# Escape JSON for JavaScript\nescaped_json = json.dumps(json.loads(metrics_json))\n\n# Replace placeholder\nhtml_content = html_content.replace('METRICS_PLACEHOLDER', escaped_json)\n\n# Write back\nwith open('$OUTPUT_FILE', 'w', encoding='utf-8') as f:\n    f.write(html_content)\nPYTHON_SCRIPT\n\necho \"✅ Dashboard generated: $OUTPUT_FILE\"\necho \"Open in browser: file://$(realpath \"$OUTPUT_FILE\")\"\n"
        },
        {
          "path": "scripts/get-next-task-number.sh",
          "type": "Bash",
          "purpose": "Gets next task number for new tasks",
          "used_by": [
            "Task creation"
          ],
          "content": "#!/bin/bash\n# get-next-task-number.sh\n# Gets the next available task number by scanning TODO.md, BACKLOG.md, and ARCHIVE.md\n#\n# Usage: ./scripts/get-next-task-number.sh\n\nset -euo pipefail\n\nREPO_ROOT=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)\"\ncd \"$REPO_ROOT\"\n\nTASKS_DIR=\".repo/tasks\"\nTODO_FILE=\"$TASKS_DIR/TODO.md\"\nBACKLOG_FILE=\"$TASKS_DIR/BACKLOG.md\"\nARCHIVE_FILE=\"$TASKS_DIR/ARCHIVE.md\"\n\n# Find all task numbers\nALL_TASK_NUMS=$(cat \"$TODO_FILE\" \"$BACKLOG_FILE\" \"$ARCHIVE_FILE\" 2>/dev/null | \\\n    grep -oE '\\[TASK-[0-9]+\\]' | \\\n    sed 's/\\[TASK-\\([0-9]*\\)\\]/\\1/' | \\\n    sort -n)\n\n# Get highest number\nLAST_NUM=$(echo \"$ALL_TASK_NUMS\" | tail -1 || echo \"0\")\n\n# Next number\nNEXT_NUM=$((LAST_NUM + 1))\n\n# Format as TASK-XXX (zero-padded to 3 digits)\nprintf \"TASK-%03d\\n\" \"$NEXT_NUM\"\n"
        },
        {
          "path": "scripts/migrate.sh",
          "type": "Bash",
          "purpose": "Migration script",
          "used_by": [
            "Migrations"
          ],
          "content": "#!/bin/bash\n# Database Migration Script for UBOS\n# Run this after Phase 1 architectural refactor\n\nset -e\n\necho \"==========================================\"\necho \"UBOS - Database Migration Setup\"\necho \"==========================================\"\necho \"\"\necho \"This script creates and applies migrations for:\"\necho \"  - CRM Module (Leads, Prospects, Campaigns, Proposals, Contracts)\"\necho \"  - Clients Module (Client, ClientPortalUser, ClientNote, ClientEngagement)\"\necho \"  - Updated foreign keys (Projects, Documents, Finance)\"\necho \"\"\n\n# Check if Docker is running\nif ! docker info > /dev/null 2>&1; then\n    echo \"❌ Error: Docker is not running\"\n    echo \"Please start Docker and try again.\"\n    exit 1\nfi\n\necho \"✅ Docker is running\"\necho \"\"\n\n# Start database\necho \"📦 Starting PostgreSQL database...\"\ndocker-compose up -d db\nsleep 5\necho \"✅ Database started\"\necho \"\"\n\n# Create migrations\necho \"🔨 Creating migrations...\"\ndocker-compose run --rm web python manage.py makemigrations\n\necho \"\"\necho \"✅ Migrations created successfully!\"\necho \"\"\n\n# Show migration plan\necho \"📋 Migration plan:\"\ndocker-compose run --rm web python manage.py showmigrations\n\necho \"\"\nread -p \"Apply these migrations? (y/n) \" -n 1 -r\necho \"\"\n\nif [[ $REPLY =~ ^[Yy]$ ]]; then\n    echo \"⚙️  Applying migrations...\"\n    docker-compose run --rm web python manage.py migrate\n\n    echo \"\"\n    echo \"✅ Migrations applied successfully!\"\n    echo \"\"\n\n    # Create superuser prompt\n    read -p \"Create a superuser for Django admin? (y/n) \" -n 1 -r\n    echo \"\"\n\n    if [[ $REPLY =~ ^[Yy]$ ]]; then\n        docker-compose run --rm web python manage.py createsuperuser\n    fi\nelse\n    echo \"⏸️  Migration cancelled. Run './scripts/migrate.sh' again when ready.\"\n    exit 0\nfi\n\necho \"\"\necho \"==========================================\"\necho \"✅ Database setup complete!\"\necho \"==========================================\"\necho \"\"\necho \"Next steps:\"\necho \"  1. Start the development server:\"\necho \"     docker-compose up\"\necho \"\"\necho \"  2. Access Django admin:\"\necho \"     http://localhost:8000/admin\"\necho \"\"\necho \"  3. Access API documentation:\"\necho \"     http://localhost:8000/api/docs/\"\necho \"\"\necho \"Available API endpoints:\"\necho \"  - /api/crm/leads/\"\necho \"  - /api/crm/prospects/\"\necho \"  - /api/crm/campaigns/\"\necho \"  - /api/crm/proposals/\"\necho \"  - /api/crm/contracts/\"\necho \"  - /api/clients/clients/\"\necho \"  - /api/clients/portal-users/\"\necho \"  - /api/clients/notes/\"\necho \"  - /api/clients/engagements/\"\necho \"  - /api/projects/projects/\"\necho \"  - /api/finance/invoices/\"\necho \"  - /api/documents/folders/\"\necho \"  - /api/assets/assets/\"\necho \"\"\n"
        },
        {
          "path": "scripts/setup-migrations.sh",
          "type": "Bash",
          "purpose": "Sets up migrations",
          "used_by": [
            "Migration setup"
          ],
          "content": "#!/bin/bash\n#\n# Database Migrations Setup Script\n# Run this after Docker is installed to create initial migrations\n#\n\nset -e\n\necho \"=========================================\"\necho \"UBOS - Database Migrations Setup\"\necho \"=========================================\"\necho \"\"\n\n# Check if Docker is installed\nif ! command -v docker &> /dev/null; then\n    echo \"ERROR: Docker is not installed.\"\n    echo \"Please install Docker and Docker Compose first.\"\n    echo \"See: https://docs.docker.com/get-docker/\"\n    exit 1\nfi\n\n# Check if Docker Compose is installed\nif ! command -v docker-compose &> /dev/null; then\n    echo \"ERROR: Docker Compose is not installed.\"\n    echo \"Please install Docker Compose first.\"\n    echo \"See: https://docs.docker.com/compose/install/\"\n    exit 1\nfi\n\necho \"Step 1: Starting PostgreSQL database...\"\ndocker-compose up -d db\n\necho \"\"\necho \"Step 2: Waiting for database to be ready...\"\nsleep 5\n\necho \"\"\necho \"Step 3: Building web container with updated requirements...\"\ndocker-compose build web\n\necho \"\"\necho \"Step 4: Creating database migrations for all modules...\"\ndocker-compose run --rm web python manage.py makemigrations crm\ndocker-compose run --rm web python manage.py makemigrations projects\ndocker-compose run --rm web python manage.py makemigrations finance\ndocker-compose run --rm web python manage.py makemigrations documents\ndocker-compose run --rm web python manage.py makemigrations assets\n\necho \"\"\necho \"Step 5: Applying migrations to database...\"\ndocker-compose run --rm web python manage.py migrate\n\necho \"\"\necho \"Step 6: Creating superuser (admin account)...\"\necho \"You'll be prompted to enter username, email, and password:\"\ndocker-compose run --rm web python manage.py createsuperuser\n\necho \"\"\necho \"=========================================\"\necho \"✓ Setup complete!\"\necho \"=========================================\"\necho \"\"\necho \"Next steps:\"\necho \"1. Start the application:\"\necho \"   docker-compose up\"\necho \"\"\necho \"2. Access Django admin:\"\necho \"   http://localhost:8000/admin/\"\necho \"\"\necho \"3. Access API documentation:\"\necho \"   http://localhost:8000/api/docs/\"\necho \"\"\necho \"4. Install frontend dependencies:\"\necho \"   cd frontend && npm install && npm run dev\"\necho \"\"\n"
        },
        {
          "path": "scripts/INDEX.md",
          "type": "Markdown",
          "purpose": "Index of scripts",
          "used_by": [
            "Script navigation"
          ],
          "content": "# Scripts Directory Index\n\n**File**: `scripts/INDEX.md`\n\nThis file catalogs the scripts in the `scripts/` directory. See [root `INDEX.md`](../INDEX.md) for repository overview.\n\n## Scripts\n\n### `governance-verify.sh`\nEnforces quality gates per `.repo/policy/QUALITY_GATES.md`. Checks required policy files, manifest, HITL items, and repository structure.\n\n**Usage**: `./scripts/governance-verify.sh`\n\n**Exit codes**:\n- `0` - Pass (all checks pass)\n- `1` - Hard failure (blocks merge)\n- `2` - Waiverable failure (requires waiver)\n\n### `migrate.sh`\nDatabase migration script for UBOS. Creates and applies Django migrations, with prompts for user confirmation.\n\n**Usage**: `./scripts/migrate.sh`\n\n**Features**:\n- Creates migrations for all modules\n- Shows migration plan\n- Prompts for confirmation before applying\n- Option to create superuser\n\n### `setup-migrations.sh`\nSets up migration environment and dependencies.\n\n**Usage**: `./scripts/setup-migrations.sh`\n\n## Navigation\n\n- [Root `INDEX.md`](../INDEX.md) - Repository master index\n- [`backend/INDEX.md`](../backend/INDEX.md) - Backend directory index\n\n## See Also\n\n- `scripts/SCRIPTS.md` - What agents may do in this directory\n- [`.repo/policy/QUALITY_GATES.md`](../.repo/policy/QUALITY_GATES.md) - Quality gate definitions\n"
        },
        {
          "path": "scripts/SCRIPTS.md",
          "type": "Markdown",
          "purpose": "Scripts documentation",
          "used_by": [
            "Script usage"
          ],
          "content": "# SCRIPTS.md (Folder-Level Guide)\n\n## Purpose of this folder\n\nThis folder (`scripts/`) contains automation and utility scripts for development, deployment, and maintenance tasks.\n\n## What agents may do here\n\n- Add new utility scripts\n- Modify existing scripts to improve functionality\n- Create automation for common tasks\n- Add helper scripts for development workflow\n\n## What agents may NOT do\n\n- Break existing script interfaces without migration plan\n- Add production code (scripts only)\n- Create scripts that modify production without safeguards\n- Remove scripts that are in active use\n- Create scripts that bypass governance checks\n\n## Required links\n\n- Refer to higher-level policy: `.repo/policy/PRINCIPLES.md` (Principle 11: Prefer Guardrails Over Heroics)\n- See `.repo/policy/SECURITY_BASELINE.md` for security requirements\n- See `scripts/governance-verify.sh` for governance enforcement script\n\n## Script Standards\n\n- Scripts should be executable and well-documented\n- Scripts should follow bash best practices\n- Scripts should include error handling\n- Scripts should not contain secrets or sensitive data\n- Scripts should be idempotent where possible\n"
        },
        {
          "path": "scripts/requirements.txt",
          "type": "Text",
          "purpose": "Python dependencies for scripts",
          "used_by": [
            "Python script setup"
          ],
          "content": "# Python dependencies for automation scripts\n# Install with: pip install -r scripts/requirements.txt\n\nrequests>=2.31.0  # For GitHub API integration in sync-hitl-to-pr.py\n"
        }
      ]
    },
    "context_files": {
      "description": "Folder-level context files (.agent-context.json)",
      "total_count": 11,
      "files": [
        {
          "path": "backend/.agent-context.json",
          "type": "JSON",
          "lines": 85,
          "purpose": "Backend folder context",
          "key_contents": [
            "Folder: backend/ (purpose: Django backend, layer: api)",
            "agent_rules: can_do, cannot_do, requires_hitl",
            "patterns: model, viewset, serializer (Django patterns)",
            "boundaries: can_import_from (empty), cannot_import_from (frontend), cross_module_requires_adr (true)",
            "quick_links: guide (BACKEND.md), index (INDEX.md), policy (BOUNDARIES.md), best_practices (BESTPR.md)",
            "common_tasks: Add new module, Add field to existing model",
            "metrics: files_count (500), last_modified (2026-01-23), last_verified (2026-01-23), test_coverage (0.82)"
          ],
          "schema": "References .repo/templates/AGENT_CONTEXT_SCHEMA.json",
          "used_by": [
            "Agents entering backend/ directory (Pass 0)"
          ],
          "content": "{\n  \"$schema\": \"../.repo/templates/AGENT_CONTEXT_SCHEMA.json\",\n  \"version\": \"1.0.0\",\n  \"type\": \"folder_context\",\n  \"folder\": {\n    \"path\": \"backend/\",\n    \"purpose\": \"Django backend application with domain modules, API endpoints, and configuration\",\n    \"layer\": \"api\",\n    \"depends_on\": [],\n    \"used_by\": [\"frontend/\"]\n  },\n  \"agent_rules\": {\n    \"can_do\": [\n      \"Create new modules in backend/modules/ (within firm-scoping rules)\",\n      \"Modify existing modules (within boundaries)\",\n      \"Create/modify API endpoints in backend/api/\",\n      \"Update configuration in backend/config/ (with care for production impact)\",\n      \"Add migrations when schema changes\"\n    ],\n    \"cannot_do\": [\n      \"Cross-module imports without ADR (see .repo/policy/BOUNDARIES.md)\",\n      \"Break firm-scoping (all models must be firm-scoped)\",\n      \"Import from backend/modules/core/ and re-export across modules\",\n      \"Modify migrations directly (use makemigrations)\",\n      \"Break existing API contracts without ADR\",\n      \"Add dependencies without security review\"\n    ],\n    \"requires_hitl\": [\n      \"Schema changes affecting other modules\",\n      \"Breaking API changes\",\n      \"Security-related changes\",\n      \"Production configuration changes\",\n      \"Dependency additions\"\n    ]\n  },\n  \"patterns\": {\n    \"model\": \"class ModelName(FirmScopedMixin, models.Model):\\n    firm = models.ForeignKey('firm.Firm', on_delete=models.CASCADE)\",\n    \"viewset\": \"class ModelViewSet(FirmScopedMixin, viewsets.ModelViewSet):\\n    queryset = ModelName.objects.all()\\n    serializer_class = ModelSerializer\",\n    \"serializer\": \"class ModelSerializer(serializers.ModelSerializer):\\n    class Meta:\\n        model = ModelName\\n        fields = '__all__'\"\n  },\n  \"boundaries\": {\n    \"can_import_from\": [],\n    \"cannot_import_from\": [\"frontend/\"],\n    \"cross_module_requires_adr\": true\n  },\n  \"quick_links\": {\n    \"guide\": \"backend/BACKEND.md\",\n    \"index\": \"backend/INDEX.md\",\n    \"policy\": \".repo/policy/BOUNDARIES.md\",\n    \"best_practices\": \".repo/policy/BESTPR.md\"\n  },\n  \"common_tasks\": [\n    {\n      \"task\": \"Add new module\",\n      \"steps\": [\n        \"1. Create directory: backend/modules/{module_name}/\",\n        \"2. Create models.py with FirmScopedMixin\",\n        \"3. Create serializers.py\",\n        \"4. Create views.py with FirmScopedMixin viewsets\",\n        \"5. Create urls.py\",\n        \"6. Register in backend/config/settings.py INSTALLED_APPS\",\n        \"7. Create initial migration: python manage.py makemigrations {module_name}\",\n        \"8. Add tests in tests/{module_name}/\"\n      ],\n      \"files\": [\"backend/modules/{module_name}/*\", \"backend/config/settings.py\", \"tests/{module_name}/*\"]\n    },\n    {\n      \"task\": \"Add field to existing model\",\n      \"steps\": [\n        \"1. Add field to models.py in module\",\n        \"2. Create migration: python manage.py makemigrations {module_name}\",\n        \"3. Update serializer if needed\",\n        \"4. Update tests\"\n      ],\n      \"files\": [\"backend/modules/{module_name}/models.py\", \"backend/modules/{module_name}/serializers.py\", \"backend/modules/{module_name}/migrations/\"]\n    }\n  ],\n  \"metrics\": {\n    \"files_count\": 500,\n    \"last_modified\": \"2026-01-23\",\n    \"last_verified\": \"2026-01-23\",\n    \"test_coverage\": 0.82\n  }\n}\n"
        },
        {
          "path": "frontend/.agent-context.json",
          "type": "JSON",
          "purpose": "Frontend folder context",
          "key_contents": [
            "Folder: frontend/ (purpose: React frontend, layer: ui)",
            "agent_rules: React-specific rules",
            "patterns: React component patterns",
            "boundaries: Frontend-specific boundaries",
            "quick_links: FRONTEND.md, INDEX.md, etc."
          ],
          "schema": "References .repo/templates/AGENT_CONTEXT_SCHEMA.json",
          "used_by": [
            "Agents entering frontend/ directory (Pass 0)"
          ],
          "content": "{\n  \"$schema\": \"../.repo/templates/AGENT_CONTEXT_SCHEMA.json\",\n  \"version\": \"1.0.0\",\n  \"type\": \"folder_context\",\n  \"folder\": {\n    \"path\": \"frontend/\",\n    \"purpose\": \"React/TypeScript frontend application built with Vite\",\n    \"layer\": \"ui\",\n    \"depends_on\": [\"backend/\"],\n    \"used_by\": []\n  },\n  \"agent_rules\": {\n    \"can_do\": [\n      \"Create new React components in frontend/src/components/\",\n      \"Add new pages in frontend/src/pages/\",\n      \"Create API client functions in frontend/src/api/ (organized by domain)\",\n      \"Add React hooks and contexts in frontend/src/\",\n      \"Create E2E tests in frontend/e2e/\",\n      \"Add unit tests in frontend/tests/\",\n      \"Update Vite configuration when needed\",\n      \"Add dependencies (with security review)\"\n    ],\n    \"cannot_do\": [\n      \"Break existing component patterns without justification\",\n      \"Create new abstractions before checking existing patterns\",\n      \"Use non-React Query patterns for API data fetching\",\n      \"Break TypeScript types or skip type checking\",\n      \"Modify build configuration without testing\",\n      \"Add dependencies without security review\",\n      \"Create components that don't follow React Hook Form patterns for forms\"\n    ],\n    \"requires_hitl\": [\n      \"Breaking API contract changes\",\n      \"Security-related changes\",\n      \"Dependency additions\",\n      \"Build configuration changes\"\n    ]\n  },\n  \"patterns\": {\n    \"component\": \"export const Component: React.FC = () => {\\n  const { data } = useQuery(...);\\n  return <div>...</div>;\\n};\",\n    \"api_client\": \"export const useClients = () => {\\n  return useQuery({\\n    queryKey: ['clients'],\\n    queryFn: () => apiClient.get('/api/clients/')\\n  });\\n};\",\n    \"form\": \"const { register, handleSubmit } = useForm();\"\n  },\n  \"boundaries\": {\n    \"can_import_from\": [\"backend/\"],\n    \"cannot_import_from\": [],\n    \"cross_module_requires_adr\": false\n  },\n  \"quick_links\": {\n    \"guide\": \"frontend/FRONTEND.md\",\n    \"index\": \"frontend/INDEX.md\",\n    \"policy\": \".repo/policy/BESTPR.md\",\n    \"best_practices\": \".repo/policy/BESTPR.md\"\n  },\n  \"common_tasks\": [\n    {\n      \"task\": \"Add new page\",\n      \"steps\": [\n        \"1. Create page component in frontend/src/pages/{PageName}.tsx\",\n        \"2. Create co-located CSS file: frontend/src/pages/{PageName}.css\",\n        \"3. Add route in App.tsx or router configuration\",\n        \"4. Create API client function in frontend/src/api/ if needed\",\n        \"5. Add tests in frontend/tests/\"\n      ],\n      \"files\": [\"frontend/src/pages/{PageName}.tsx\", \"frontend/src/pages/{PageName}.css\", \"frontend/src/App.tsx\", \"frontend/src/api/*.ts\"]\n    },\n    {\n      \"task\": \"Add new API client function\",\n      \"steps\": [\n        \"1. Add function to appropriate domain file in frontend/src/api/\",\n        \"2. Use TanStack React Query useQuery or useMutation\",\n        \"3. Export from frontend/src/api/index.ts if needed\",\n        \"4. Add tests in frontend/src/api/__tests__/\"\n      ],\n      \"files\": [\"frontend/src/api/{domain}.ts\", \"frontend/src/api/__tests__/{domain}.test.ts\"]\n    }\n  ],\n  \"metrics\": {\n    \"files_count\": 96,\n    \"last_modified\": \"2026-01-23\",\n    \"test_coverage\": 0.75\n  }\n}\n"
        },
        {
          "path": "frontend/src/components/.agent-context.json",
          "type": "JSON",
          "purpose": "Components folder context",
          "used_by": [
            "Agents working in components/"
          ],
          "content": "{\n  \"$schema\": \"../../../.repo/templates/AGENT_CONTEXT_SCHEMA.json\",\n  \"version\": \"1.0.0\",\n  \"type\": \"folder_context\",\n  \"folder\": {\n    \"path\": \"frontend/src/components\",\n    \"purpose\": \"Reusable React components - Layout, ErrorBoundary, CommandCenter, etc.\",\n    \"layer\": \"ui\",\n    \"depends_on\": [\"frontend/src/api\"],\n    \"used_by\": [\"frontend/src/pages\"]\n  },\n  \"agent_rules\": {\n    \"can_do\": [\n      \"Create new React components\",\n      \"Add TypeScript types\",\n      \"Use React Query hooks for data\",\n      \"Add co-located CSS files\",\n      \"Create reusable components\"\n    ],\n    \"cannot_do\": [\n      \"Break existing component patterns without justification\",\n      \"Create new abstractions before checking existing patterns\",\n      \"Skip TypeScript types\",\n      \"Use non-functional components\",\n      \"Break component API contracts\"\n    ],\n    \"requires_hitl\": [\n      \"Breaking component API changes\",\n      \"Security-related changes\"\n    ]\n  },\n  \"patterns\": {\n    \"component\": \"export const Component: React.FC<ComponentProps> = () => {\\n  const { data } = useQuery(...);\\n  return <div>...</div>;\\n};\",\n    \"with_css\": \"// Component.tsx\\nimport './Component.css';\\n\\nexport const Component: React.FC = () => { ... };\"\n  },\n  \"boundaries\": {\n    \"can_import_from\": [\"frontend/src/api\", \"frontend/src/contexts\"],\n    \"cannot_import_from\": [\"backend/\"],\n    \"cross_module_requires_adr\": false\n  },\n  \"quick_links\": {\n    \"guide\": \"frontend/src/components/.AGENT.md\",\n    \"index\": \"frontend/INDEX.md\",\n    \"policy\": \".repo/policy/BESTPR.md\",\n    \"best_practices\": \".repo/policy/BESTPR.md\"\n  },\n  \"common_tasks\": [\n    {\n      \"task\": \"Add new component\",\n      \"steps\": [\n        \"1. Create Component.tsx in frontend/src/components/\",\n        \"2. Create Component.css (co-located)\",\n        \"3. Add TypeScript types\",\n        \"4. Use functional component pattern\",\n        \"5. Add tests in frontend/tests/\"\n      ],\n      \"files\": [\"frontend/src/components/Component.tsx\", \"frontend/src/components/Component.css\"]\n    }\n  ],\n  \"metrics\": {\n    \"files_count\": 8,\n    \"last_modified\": \"2026-01-23\",\n    \"test_coverage\": 0.80\n  }\n}\n"
        },
        {
          "path": "frontend/src/api/.agent-context.json",
          "type": "JSON",
          "purpose": "API client folder context",
          "used_by": [
            "Agents working in API clients"
          ],
          "content": "{\n  \"$schema\": \"../../../.repo/templates/AGENT_CONTEXT_SCHEMA.json\",\n  \"version\": \"1.0.0\",\n  \"type\": \"folder_context\",\n  \"folder\": {\n    \"path\": \"frontend/src/api\",\n    \"purpose\": \"API client functions organized by domain - uses TanStack React Query for data fetching\",\n    \"layer\": \"ui\",\n    \"depends_on\": [\"backend/\"],\n    \"used_by\": [\"frontend/src/pages\", \"frontend/src/components\"]\n  },\n  \"agent_rules\": {\n    \"can_do\": [\n      \"Create API client functions\",\n      \"Add React Query hooks (useQuery, useMutation)\",\n      \"Organize by domain (clients, crm, finance, etc.)\",\n      \"Add TypeScript types\"\n    ],\n    \"cannot_do\": [\n      \"Use non-React Query patterns for data fetching\",\n      \"Break TypeScript types\",\n      \"Create direct fetch calls (use API client)\",\n      \"Skip error handling\"\n    ],\n    \"requires_hitl\": [\n      \"Breaking API contract changes\",\n      \"Security-related changes\"\n    ]\n  },\n  \"patterns\": {\n    \"query_hook\": \"export const useClients = () => {\\n  return useQuery({\\n    queryKey: ['clients'],\\n    queryFn: () => apiClient.get('/api/clients/')\\n  });\\n};\",\n    \"mutation_hook\": \"export const useCreateClient = () => {\\n  return useMutation({\\n    mutationFn: (data) => apiClient.post('/api/clients/', data)\\n  });\\n};\"\n  },\n  \"boundaries\": {\n    \"can_import_from\": [\"backend/\"],\n    \"cannot_import_from\": [],\n    \"cross_module_requires_adr\": false\n  },\n  \"quick_links\": {\n    \"guide\": \"frontend/src/api/.AGENT.md\",\n    \"index\": \"frontend/INDEX.md\",\n    \"policy\": \".repo/policy/BESTPR.md\",\n    \"best_practices\": \".repo/policy/BESTPR.md\"\n  },\n  \"common_tasks\": [\n    {\n      \"task\": \"Add new API client function\",\n      \"steps\": [\n        \"1. Add function to appropriate domain file (e.g., clients.ts)\",\n        \"2. Use useQuery or useMutation from React Query\",\n        \"3. Add TypeScript types\",\n        \"4. Add error handling\",\n        \"5. Add tests in __tests__/\"\n      ],\n      \"files\": [\"frontend/src/api/{domain}.ts\", \"frontend/src/api/__tests__/{domain}.test.ts\"]\n    }\n  ],\n  \"metrics\": {\n    \"files_count\": 15,\n    \"last_modified\": \"2026-01-23\",\n    \"test_coverage\": 0.85\n  }\n}\n"
        },
        {
          "path": "backend/modules/core/.agent-context.json",
          "type": "JSON",
          "purpose": "Core module context",
          "used_by": [
            "Agents working in core module"
          ],
          "content": "{\n  \"$schema\": \"../../../.repo/templates/AGENT_CONTEXT_SCHEMA.json\",\n  \"version\": \"1.0.0\",\n  \"type\": \"folder_context\",\n  \"folder\": {\n    \"path\": \"backend/modules/core\",\n    \"purpose\": \"Shared platform/core utilities - foundation layer that provides common functionality for all modules\",\n    \"layer\": \"platform\",\n    \"depends_on\": [],\n    \"used_by\": [\n      \"backend/modules/firm\",\n      \"backend/modules/clients\",\n      \"backend/modules/crm\",\n      \"backend/modules/finance\",\n      \"backend/modules/projects\",\n      \"backend/modules/documents\",\n      \"backend/modules/*\"\n    ]\n  },\n  \"agent_rules\": {\n    \"can_do\": [\n      \"Add shared utilities and base classes\",\n      \"Create common functionality used across modules\",\n      \"Provide platform-level abstractions\",\n      \"Update core infrastructure (with care for breaking changes)\"\n    ],\n    \"cannot_do\": [\n      \"Add business logic or domain-specific code\",\n      \"Depend on other modules (core is the foundation)\",\n      \"Create module-specific functionality\",\n      \"Break existing core APIs without migration plan\",\n      \"Add dependencies that other modules must inherit\"\n    ],\n    \"requires_hitl\": [\n      \"Breaking changes to core APIs\",\n      \"Changes affecting all modules\",\n      \"Security-related changes\",\n      \"Dependency additions\"\n    ]\n  },\n  \"patterns\": {\n    \"model\": \"# Core models use standard Django patterns\\nclass ModelName(models.Model):\\n    created_at = models.DateTimeField(auto_now_add=True)\\n    updated_at = models.DateTimeField(auto_now=True)\",\n    \"mixin\": \"# Core mixins provide shared functionality\\nclass MixinName:\\n    def shared_method(self):\\n        pass\",\n    \"utility\": \"# Core utilities are standalone functions\\nfrom django.utils import timezone\\n\\ndef utility_function(param):\\n    return result\"\n  },\n  \"boundaries\": {\n    \"can_import_from\": [],\n    \"cannot_import_from\": [\n      \"backend/modules/firm\",\n      \"backend/modules/clients\",\n      \"backend/modules/crm\",\n      \"backend/modules/finance\",\n      \"backend/modules/projects\"\n    ],\n    \"cross_module_requires_adr\": false\n  },\n  \"quick_links\": {\n    \"guide\": \"backend/modules/core/.AGENT.md\",\n    \"index\": \"backend/modules/core/CORE.md\",\n    \"policy\": \".repo/policy/BOUNDARIES.md\",\n    \"best_practices\": \".repo/policy/BESTPR.md\"\n  },\n  \"common_tasks\": [\n    {\n      \"task\": \"Add new utility function\",\n      \"steps\": [\n        \"1. Create function in appropriate utility file\",\n        \"2. Add type hints\",\n        \"3. Add docstring\",\n        \"4. Add tests in tests/core/\",\n        \"5. Export from __init__.py if needed\"\n      ],\n      \"files\": [\"backend/modules/core/*.py\", \"tests/core/*.py\"]\n    },\n    {\n      \"task\": \"Add new base class or mixin\",\n      \"steps\": [\n        \"1. Create class in appropriate file\",\n        \"2. Document usage patterns\",\n        \"3. Add tests\",\n        \"4. Update documentation\"\n      ],\n      \"files\": [\"backend/modules/core/*.py\", \"tests/core/*.py\"]\n    }\n  ],\n  \"metrics\": {\n    \"files_count\": 30,\n    \"last_modified\": \"2026-01-23\",\n    \"test_coverage\": 0.85\n  }\n}\n"
        },
        {
          "path": "backend/modules/firm/.agent-context.json",
          "type": "JSON",
          "purpose": "Firm module context",
          "used_by": [
            "Agents working in firm module"
          ],
          "content": "{\n  \"$schema\": \"../../../.repo/templates/AGENT_CONTEXT_SCHEMA.json\",\n  \"version\": \"1.0.0\",\n  \"type\": \"folder_context\",\n  \"folder\": {\n    \"path\": \"backend/modules/firm\",\n    \"purpose\": \"Multi-tenant foundation - provides Firm model, FirmMembership, firm context middleware, and firm-scoped utilities\",\n    \"layer\": \"platform\",\n    \"depends_on\": [\"backend/modules/core\"],\n    \"used_by\": [\n      \"backend/modules/clients\",\n      \"backend/modules/crm\",\n      \"backend/modules/finance\",\n      \"backend/modules/projects\",\n      \"backend/modules/documents\",\n      \"backend/modules/*\"\n    ]\n  },\n  \"agent_rules\": {\n    \"can_do\": [\n      \"Add firm-scoped utilities\",\n      \"Update firm context middleware\",\n      \"Add firm-related models (with care)\",\n      \"Update firm scoping helpers\"\n    ],\n    \"cannot_do\": [\n      \"Break firm-scoping invariants\",\n      \"Remove firm context requirement\",\n      \"Break FirmScopedMixin API\",\n      \"Depend on business modules\"\n    ],\n    \"requires_hitl\": [\n      \"Changes to Firm model schema\",\n      \"Changes to firm context resolution\",\n      \"Breaking changes to FirmScopedMixin\",\n      \"Security-related changes\"\n    ]\n  },\n  \"patterns\": {\n    \"model\": \"class ModelName(FirmScopedMixin, models.Model):\\n    firm = models.ForeignKey('firm.Firm', on_delete=models.CASCADE)\",\n    \"viewset\": \"class ModelViewSet(FirmScopedMixin, viewsets.ModelViewSet):\\n    queryset = ModelName.objects.all()\\n    serializer_class = ModelSerializer\",\n    \"firm_scoped_query\": \"from modules.firm.utils import get_request_firm, firm_scoped_queryset\\n\\nfirm = get_request_firm(request)\\nqueryset = firm_scoped_queryset(ModelName, firm)\"\n  },\n  \"boundaries\": {\n    \"can_import_from\": [\"backend/modules/core\"],\n    \"cannot_import_from\": [\n      \"backend/modules/clients\",\n      \"backend/modules/crm\",\n      \"backend/modules/finance\",\n      \"backend/modules/projects\"\n    ],\n    \"cross_module_requires_adr\": true\n  },\n  \"quick_links\": {\n    \"guide\": \"backend/modules/firm/.AGENT.md\",\n    \"index\": \"backend/modules/firm/README.md\",\n    \"policy\": \".repo/policy/BOUNDARIES.md\",\n    \"best_practices\": \".repo/policy/BESTPR.md\"\n  },\n  \"common_tasks\": [\n    {\n      \"task\": \"Add firm-scoped model\",\n      \"steps\": [\n        \"1. Inherit from FirmScopedMixin and models.Model\",\n        \"2. Add firm ForeignKey\",\n        \"3. Create migration: python manage.py makemigrations firm\",\n        \"4. Add serializer\",\n        \"5. Add viewset with FirmScopedMixin\",\n        \"6. Add tests\"\n      ],\n      \"files\": [\"backend/modules/firm/models.py\", \"backend/modules/firm/serializers.py\", \"backend/modules/firm/views.py\"]\n    },\n    {\n      \"task\": \"Update firm context middleware\",\n      \"steps\": [\n        \"1. Modify FirmContextMiddleware in middleware.py\",\n        \"2. Test firm context resolution\",\n        \"3. Update tests\",\n        \"4. Document changes\"\n      ],\n      \"files\": [\"backend/modules/firm/middleware.py\", \"tests/firm/test_middleware.py\"]\n    }\n  ],\n  \"metrics\": {\n    \"files_count\": 34,\n    \"last_modified\": \"2026-01-23\",\n    \"test_coverage\": 0.88\n  }\n}\n"
        },
        {
          "path": "backend/modules/clients/.agent-context.json",
          "type": "JSON",
          "purpose": "Clients module context",
          "used_by": [
            "Agents working in clients module"
          ],
          "content": "{\n  \"$schema\": \"../../../.repo/templates/AGENT_CONTEXT_SCHEMA.json\",\n  \"version\": \"1.0.0\",\n  \"type\": \"folder_context\",\n  \"folder\": {\n    \"path\": \"backend/modules/clients\",\n    \"purpose\": \"Client management module with firm-scoped multi-tenancy - manages clients, contacts, engagements, health scores, and portal access\",\n    \"layer\": \"domain\",\n    \"depends_on\": [\"backend/modules/core\", \"backend/modules/firm\"],\n    \"used_by\": [\"backend/api/clients\", \"frontend/src/api/clients.ts\"]\n  },\n  \"agent_rules\": {\n    \"can_do\": [\n      \"Create new models with FirmScopedMixin\",\n      \"Add serializers for API\",\n      \"Create viewsets with FirmScopedMixin\",\n      \"Add migrations for schema changes\",\n      \"Add client-related utilities\",\n      \"Update portal functionality\"\n    ],\n    \"cannot_do\": [\n      \"Import from other business modules without ADR\",\n      \"Break firm-scoping\",\n      \"Depend on business modules (only core/firm allowed)\",\n      \"Remove firm ForeignKey from models\"\n    ],\n    \"requires_hitl\": [\n      \"Schema changes affecting other modules\",\n      \"Breaking API changes\",\n      \"Security-related changes\",\n      \"Portal access changes\"\n    ]\n  },\n  \"patterns\": {\n    \"model\": \"class Client(FirmScopedMixin, models.Model):\\n    firm = models.ForeignKey('firm.Firm', on_delete=models.CASCADE)\\n    name = models.CharField(max_length=255)\",\n    \"viewset\": \"class ClientViewSet(FirmScopedMixin, viewsets.ModelViewSet):\\n    queryset = Client.objects.all()\\n    serializer_class = ClientSerializer\",\n    \"serializer\": \"class ClientSerializer(serializers.ModelSerializer):\\n    class Meta:\\n        model = Client\\n        fields = '__all__'\"\n  },\n  \"boundaries\": {\n    \"can_import_from\": [\"backend/modules/core\", \"backend/modules/firm\"],\n    \"cannot_import_from\": [\n      \"backend/modules/crm\",\n      \"backend/modules/finance\",\n      \"backend/modules/projects\",\n      \"backend/modules/documents\"\n    ],\n    \"cross_module_requires_adr\": true\n  },\n  \"quick_links\": {\n    \"guide\": \"backend/modules/clients/.AGENT.md\",\n    \"index\": \"backend/INDEX.md\",\n    \"policy\": \".repo/policy/BOUNDARIES.md\",\n    \"best_practices\": \".repo/policy/BESTPR.md\"\n  },\n  \"common_tasks\": [\n    {\n      \"task\": \"Add new client field\",\n      \"steps\": [\n        \"1. Add field to backend/modules/clients/models/clients.py\",\n        \"2. Create migration: python manage.py makemigrations clients\",\n        \"3. Update ClientSerializer in serializers.py\",\n        \"4. Update tests in tests/clients/\"\n      ],\n      \"files\": [\"backend/modules/clients/models/clients.py\", \"backend/modules/clients/serializers.py\", \"backend/modules/clients/migrations/\"]\n    },\n    {\n      \"task\": \"Add new contact model\",\n      \"steps\": [\n        \"1. Create model in backend/modules/clients/models/contacts.py\",\n        \"2. Inherit from FirmScopedMixin\",\n        \"3. Add firm ForeignKey\",\n        \"4. Create migration\",\n        \"5. Add serializer\",\n        \"6. Add viewset\",\n        \"7. Add tests\"\n      ],\n      \"files\": [\"backend/modules/clients/models/contacts.py\", \"backend/modules/clients/serializers.py\", \"backend/modules/clients/views.py\"]\n    }\n  ],\n  \"metrics\": {\n    \"files_count\": 47,\n    \"last_modified\": \"2026-01-23\",\n    \"test_coverage\": 0.82\n  }\n}\n"
        },
        {
          "path": "backend/modules/crm/.agent-context.json",
          "type": "JSON",
          "purpose": "CRM module context",
          "used_by": [
            "Agents working in CRM module"
          ],
          "content": "{\n  \"$schema\": \"../../../.repo/templates/AGENT_CONTEXT_SCHEMA.json\",\n  \"version\": \"1.0.0\",\n  \"type\": \"folder_context\",\n  \"folder\": {\n    \"path\": \"backend/modules/crm\",\n    \"purpose\": \"CRM module - manages leads, prospects, deals, pipelines, proposals, and enrichment\",\n    \"layer\": \"domain\",\n    \"depends_on\": [\"backend/modules/core\", \"backend/modules/firm\"],\n    \"used_by\": [\"backend/api/crm\", \"frontend/src/api/crm.ts\"]\n  },\n  \"agent_rules\": {\n    \"can_do\": [\n      \"Create new CRM models with FirmScopedMixin\",\n      \"Add serializers for API\",\n      \"Create viewsets with FirmScopedMixin\",\n      \"Add migrations for schema changes\",\n      \"Add lead scoring logic\",\n      \"Add enrichment services\"\n    ],\n    \"cannot_do\": [\n      \"Import from other business modules without ADR\",\n      \"Break firm-scoping\",\n      \"Depend on business modules (only core/firm allowed)\"\n    ],\n    \"requires_hitl\": [\n      \"Schema changes affecting other modules\",\n      \"Breaking API changes\",\n      \"Security-related changes\",\n      \"External service integrations\"\n    ]\n  },\n  \"patterns\": {\n    \"model\": \"class Lead(FirmScopedMixin, models.Model):\\n    firm = models.ForeignKey('firm.Firm', on_delete=models.CASCADE)\",\n    \"viewset\": \"class LeadViewSet(FirmScopedMixin, viewsets.ModelViewSet):\\n    queryset = Lead.objects.all()\\n    serializer_class = LeadSerializer\"\n  },\n  \"boundaries\": {\n    \"can_import_from\": [\"backend/modules/core\", \"backend/modules/firm\"],\n    \"cannot_import_from\": [\n      \"backend/modules/clients\",\n      \"backend/modules/finance\",\n      \"backend/modules/projects\"\n    ],\n    \"cross_module_requires_adr\": true\n  },\n  \"quick_links\": {\n    \"guide\": \"backend/modules/crm/.AGENT.md\",\n    \"index\": \"backend/INDEX.md\",\n    \"policy\": \".repo/policy/BOUNDARIES.md\",\n    \"best_practices\": \".repo/policy/BESTPR.md\"\n  },\n  \"common_tasks\": [\n    {\n      \"task\": \"Add new CRM model\",\n      \"steps\": [\n        \"1. Create model in backend/modules/crm/models/\",\n        \"2. Inherit from FirmScopedMixin\",\n        \"3. Add firm ForeignKey\",\n        \"4. Create migration\",\n        \"5. Add serializer\",\n        \"6. Add viewset\",\n        \"7. Add tests\"\n      ],\n      \"files\": [\"backend/modules/crm/models/*.py\", \"backend/modules/crm/serializers.py\", \"backend/modules/crm/views.py\"]\n    }\n  ],\n  \"metrics\": {\n    \"files_count\": 42,\n    \"last_modified\": \"2026-01-23\",\n    \"test_coverage\": 0.80\n  }\n}\n"
        },
        {
          "path": "backend/modules/finance/.agent-context.json",
          "type": "JSON",
          "purpose": "Finance module context",
          "used_by": [
            "Agents working in finance module"
          ],
          "content": "{\n  \"$schema\": \"../../../.repo/templates/AGENT_CONTEXT_SCHEMA.json\",\n  \"version\": \"1.0.0\",\n  \"type\": \"folder_context\",\n  \"folder\": {\n    \"path\": \"backend/modules/finance\",\n    \"purpose\": \"Finance module - manages billing, invoicing, payments, and accounting integrations\",\n    \"layer\": \"domain\",\n    \"depends_on\": [\"backend/modules/core\", \"backend/modules/firm\"],\n    \"used_by\": [\"backend/api/finance\", \"frontend/src/api/finance.ts\"]\n  },\n  \"agent_rules\": {\n    \"can_do\": [\n      \"Create finance models with FirmScopedMixin\",\n      \"Add billing logic\",\n      \"Add payment processing\",\n      \"Add accounting integrations\"\n    ],\n    \"cannot_do\": [\n      \"Import from other business modules without ADR\",\n      \"Break firm-scoping\",\n      \"Modify payment flows without HITL\",\n      \"Add external payment services without security review\"\n    ],\n    \"requires_hitl\": [\n      \"ALL changes (money flows require HITL per Article 8)\",\n      \"Payment flow changes\",\n      \"Billing logic changes\",\n      \"External service integrations\",\n      \"Security-related changes\"\n    ]\n  },\n  \"patterns\": {\n    \"model\": \"class Invoice(FirmScopedMixin, models.Model):\\n    firm = models.ForeignKey('firm.Firm', on_delete=models.CASCADE)\",\n    \"viewset\": \"class InvoiceViewSet(FirmScopedMixin, viewsets.ModelViewSet):\\n    queryset = Invoice.objects.all()\\n    serializer_class = InvoiceSerializer\"\n  },\n  \"boundaries\": {\n    \"can_import_from\": [\"backend/modules/core\", \"backend/modules/firm\"],\n    \"cannot_import_from\": [\n      \"backend/modules/clients\",\n      \"backend/modules/crm\",\n      \"backend/modules/projects\"\n    ],\n    \"cross_module_requires_adr\": true\n  },\n  \"quick_links\": {\n    \"guide\": \"backend/modules/finance/.AGENT.md\",\n    \"index\": \"backend/INDEX.md\",\n    \"policy\": \".repo/policy/SECURITY_BASELINE.md\",\n    \"best_practices\": \".repo/policy/BESTPR.md\"\n  },\n  \"common_tasks\": [\n    {\n      \"task\": \"Add payment method\",\n      \"steps\": [\n        \"1. CREATE HITL ITEM FIRST (money flows require HITL)\",\n        \"2. Add model if needed\",\n        \"3. Add payment service\",\n        \"4. Add tests\",\n        \"5. Get HITL approval before merging\"\n      ],\n      \"files\": [\"backend/modules/finance/models.py\", \"backend/modules/finance/services.py\"]\n    }\n  ],\n  \"metrics\": {\n    \"files_count\": 31,\n    \"last_modified\": \"2026-01-23\",\n    \"test_coverage\": 0.85\n  }\n}\n"
        },
        {
          "path": "backend/modules/projects/.agent-context.json",
          "type": "JSON",
          "purpose": "Projects module context",
          "used_by": [
            "Agents working in projects module"
          ],
          "content": "{\n  \"$schema\": \"../../../.repo/templates/AGENT_CONTEXT_SCHEMA.json\",\n  \"version\": \"1.0.0\",\n  \"type\": \"folder_context\",\n  \"folder\": {\n    \"path\": \"backend/modules/projects\",\n    \"purpose\": \"Project management module - manages projects, tasks, and project workflows\",\n    \"layer\": \"domain\",\n    \"depends_on\": [\"backend/modules/core\", \"backend/modules/firm\"],\n    \"used_by\": [\"backend/api/projects\", \"frontend/src/api/projects.ts\"]\n  },\n  \"agent_rules\": {\n    \"can_do\": [\n      \"Create project models with FirmScopedMixin\",\n      \"Add serializers for API\",\n      \"Create viewsets with FirmScopedMixin\",\n      \"Add migrations for schema changes\",\n      \"Add project management logic\"\n    ],\n    \"cannot_do\": [\n      \"Import from other business modules without ADR\",\n      \"Break firm-scoping\",\n      \"Depend on business modules (only core/firm allowed)\"\n    ],\n    \"requires_hitl\": [\n      \"Schema changes affecting other modules\",\n      \"Breaking API changes\"\n    ]\n  },\n  \"patterns\": {\n    \"model\": \"class Project(FirmScopedMixin, models.Model):\\n    firm = models.ForeignKey('firm.Firm', on_delete=models.CASCADE)\",\n    \"viewset\": \"class ProjectViewSet(FirmScopedMixin, viewsets.ModelViewSet):\\n    queryset = Project.objects.all()\\n    serializer_class = ProjectSerializer\"\n  },\n  \"boundaries\": {\n    \"can_import_from\": [\"backend/modules/core\", \"backend/modules/firm\"],\n    \"cannot_import_from\": [\n      \"backend/modules/clients\",\n      \"backend/modules/crm\",\n      \"backend/modules/finance\"\n    ],\n    \"cross_module_requires_adr\": true\n  },\n  \"quick_links\": {\n    \"guide\": \"backend/modules/projects/.AGENT.md\",\n    \"index\": \"backend/INDEX.md\",\n    \"policy\": \".repo/policy/BOUNDARIES.md\",\n    \"best_practices\": \".repo/policy/BESTPR.md\"\n  },\n  \"common_tasks\": [\n    {\n      \"task\": \"Add project field\",\n      \"steps\": [\n        \"1. Add field to models.py\",\n        \"2. Create migration: python manage.py makemigrations projects\",\n        \"3. Update serializer\",\n        \"4. Update tests\"\n      ],\n      \"files\": [\"backend/modules/projects/models.py\", \"backend/modules/projects/serializers.py\"]\n    }\n  ],\n  \"metrics\": {\n    \"files_count\": 14,\n    \"last_modified\": \"2026-01-23\",\n    \"test_coverage\": 0.78\n  }\n}\n"
        },
        {
          "path": "backend/api/clients/.agent-context.json",
          "type": "JSON",
          "purpose": "Clients API context",
          "used_by": [
            "Agents working in clients API"
          ],
          "content": "{\n  \"$schema\": \"../../../.repo/templates/AGENT_CONTEXT_SCHEMA.json\",\n  \"version\": \"1.0.0\",\n  \"type\": \"folder_context\",\n  \"folder\": {\n    \"path\": \"backend/api/clients\",\n    \"purpose\": \"Client API endpoints - REST API for client management\",\n    \"layer\": \"api\",\n    \"depends_on\": [\"backend/modules/clients\"],\n    \"used_by\": [\"frontend/src/api/clients.ts\"]\n  },\n  \"agent_rules\": {\n    \"can_do\": [\n      \"Create API endpoints\",\n      \"Add serializers for API-specific needs\",\n      \"Add public views for portal access\",\n      \"Update URL routing\"\n    ],\n    \"cannot_do\": [\n      \"Break existing API contracts without ADR\",\n      \"Remove endpoints without deprecation\",\n      \"Change response formats without versioning\"\n    ],\n    \"requires_hitl\": [\n      \"Breaking API changes\",\n      \"Security-related changes\",\n      \"Public endpoint changes\"\n    ]\n  },\n  \"patterns\": {\n    \"viewset\": \"from modules.clients.views import ClientViewSet\\nfrom modules.clients.serializers import ClientSerializer\\n\\n# API endpoints use module viewsets\",\n    \"public_view\": \"from rest_framework.decorators import api_view\\n\\n@api_view(['GET'])\\ndef public_client_view(request):\\n    # Public portal endpoint\"\n  },\n  \"boundaries\": {\n    \"can_import_from\": [\"backend/modules/clients\"],\n    \"cannot_import_from\": [\n      \"backend/modules/crm\",\n      \"backend/modules/finance\",\n      \"backend/modules/projects\"\n    ],\n    \"cross_module_requires_adr\": true\n  },\n  \"quick_links\": {\n    \"guide\": \"backend/api/clients/.AGENT.md\",\n    \"index\": \"backend/INDEX.md\",\n    \"policy\": \".repo/policy/BESTPR.md\",\n    \"best_practices\": \".repo/policy/BESTPR.md\"\n  },\n  \"common_tasks\": [\n    {\n      \"task\": \"Add new API endpoint\",\n      \"steps\": [\n        \"1. Add viewset method or create new view\",\n        \"2. Add URL route in urls.py\",\n        \"3. Update OpenAPI schema: make -C backend openapi\",\n        \"4. Add tests\",\n        \"5. Document in API docs\"\n      ],\n      \"files\": [\"backend/api/clients/views.py\", \"backend/api/clients/urls.py\", \"docs/03-reference/api/openapi.yaml\"]\n    }\n  ],\n  \"metrics\": {\n    \"files_count\": 3,\n    \"last_modified\": \"2026-01-23\",\n    \"test_coverage\": 0.90\n  }\n}\n"
        }
      ]
    },
    "folder_guides": {
      "description": "Folder-level guides (.AGENT.md)",
      "total_count": 6,
      "files": [
        {
          "path": "backend/modules/core/.AGENT.md",
          "type": "Markdown",
          "lines": 78,
          "purpose": "Core module quick reference",
          "key_contents": [
            "Quick rules (can do, cannot do, requires HITL)",
            "Patterns (model, utility function)",
            "Boundaries (can import from: nothing, cannot import from: business modules)",
            "Common tasks (Add utility function)",
            "Links (CORE.md, BOUNDARIES.md, .agent-context.json)"
          ],
          "used_by": [
            "Agents entering core module (Pass 0)"
          ],
          "content": "# Core Module - Agent Quick Reference\n\n**Folder:** `backend/modules/core/`\n**Purpose:** Shared platform/core utilities - foundation layer\n**Layer:** Platform\n\n## Quick Rules\n\n✅ **Can Do:**\n- Add shared utilities and base classes\n- Create common functionality used across modules\n- Provide platform-level abstractions\n- Update core infrastructure (with care for breaking changes)\n\n❌ **Cannot Do:**\n- Add business logic or domain-specific code\n- Depend on other modules (core is the foundation)\n- Create module-specific functionality\n- Break existing core APIs without migration plan\n- Add dependencies that other modules must inherit\n\n⚠️ **Requires HITL:**\n- Breaking changes to core APIs\n- Changes affecting all modules\n- Security-related changes\n- Dependency additions\n\n## Patterns\n\n**Model:**\n```python\nclass ModelName(models.Model):\n    created_at = models.DateTimeField(auto_now_add=True)\n    updated_at = models.DateTimeField(auto_now=True)\n```\n\n**Utility Function:**\n```python\nfrom django.utils import timezone\n\ndef utility_function(param):\n    \"\"\"Utility function description.\"\"\"\n    return result\n```\n\n## Boundaries\n\n**Can Import From:**\n- ✅ Nothing (core is the foundation)\n\n**Cannot Import From:**\n- ❌ `backend/modules/firm`\n- ❌ `backend/modules/clients`\n- ❌ `backend/modules/crm`\n- ❌ Any business modules\n\n**Used By:**\n- All other modules depend on core\n\n## Common Tasks\n\n**Add Utility Function:**\n1. Create function in appropriate utility file\n2. Add type hints\n3. Add docstring\n4. Add tests in `tests/core/`\n5. Export from `__init__.py` if needed\n\n## Links\n\n- Full guide: `backend/modules/core/CORE.md`\n- Policy: `.repo/policy/BOUNDARIES.md`\n- JSON context: `.agent-context.json`\n\n---\n\n**Note:** Core is the foundation - changes here affect all modules. Test thoroughly.\n"
        },
        {
          "path": "backend/modules/firm/.AGENT.md",
          "type": "Markdown",
          "purpose": "Firm module quick reference",
          "used_by": [
            "Agents entering firm module"
          ],
          "content": "# Firm Module - Agent Quick Reference\n\n**Folder:** `backend/modules/firm/`\n**Purpose:** Multi-tenant foundation - Firm model, FirmMembership, firm context middleware\n**Layer:** Platform\n\n## Quick Rules\n\n✅ **Can Do:**\n- Add firm-scoped utilities\n- Update firm context middleware\n- Add firm-related models (with care)\n- Update firm scoping helpers\n\n❌ **Cannot Do:**\n- Break firm-scoping invariants\n- Remove firm context requirement\n- Break FirmScopedMixin API\n- Depend on business modules\n\n⚠️ **Requires HITL:**\n- Changes to Firm model schema\n- Changes to firm context resolution\n- Breaking changes to FirmScopedMixin\n- Security-related changes\n\n## Patterns\n\n**Firm-Scoped Model:**\n```python\nfrom modules.firm.utils import FirmScopedMixin\n\nclass ModelName(FirmScopedMixin, models.Model):\n    firm = models.ForeignKey('firm.Firm', on_delete=models.CASCADE)\n```\n\n**Viewset with Firm Scoping:**\n```python\nfrom modules.firm.utils import FirmScopedMixin\n\nclass ModelViewSet(FirmScopedMixin, viewsets.ModelViewSet):\n    queryset = ModelName.objects.all()\n    serializer_class = ModelSerializer\n```\n\n**Firm-Scoped Query:**\n```python\nfrom modules.firm.utils import get_request_firm, firm_scoped_queryset\n\nfirm = get_request_firm(request)\nqueryset = firm_scoped_queryset(ModelName, firm)\n```\n\n## Boundaries\n\n**Can Import From:**\n- ✅ `backend/modules/core`\n\n**Cannot Import From:**\n- ❌ `backend/modules/clients`\n- ❌ `backend/modules/crm`\n- ❌ `backend/modules/finance`\n- ❌ Any business modules\n\n**Used By:**\n- All business modules depend on firm\n\n## Common Tasks\n\n**Add Firm-Scoped Model:**\n1. Inherit from `FirmScopedMixin` and `models.Model`\n2. Add `firm` ForeignKey\n3. Create migration: `python manage.py makemigrations firm`\n4. Add serializer\n5. Add viewset with `FirmScopedMixin`\n6. Add tests\n\n## Links\n\n- Full guide: `backend/modules/firm/README.md`\n- Policy: `.repo/policy/BOUNDARIES.md`\n- JSON context: `.agent-context.json`\n\n---\n\n**Note:** Firm is the multi-tenant foundation. All business data must be firm-scoped.\n"
        },
        {
          "path": "backend/modules/clients/.AGENT.md",
          "type": "Markdown",
          "purpose": "Clients module quick reference",
          "used_by": [
            "Agents entering clients module"
          ],
          "content": "# Clients Module - Agent Quick Reference\n\n**Folder:** `backend/modules/clients/`\n**Purpose:** Client management with firm-scoped multi-tenancy\n**Layer:** Domain\n\n## Quick Rules\n\n✅ **Can Do:**\n- Create new models with `FirmScopedMixin`\n- Add serializers for API\n- Create viewsets with `FirmScopedMixin`\n- Add migrations for schema changes\n- Add client-related utilities\n- Update portal functionality\n\n❌ **Cannot Do:**\n- Import from other business modules without ADR\n- Break firm-scoping\n- Depend on business modules (only core/firm allowed)\n- Remove firm ForeignKey from models\n\n⚠️ **Requires HITL:**\n- Schema changes affecting other modules\n- Breaking API changes\n- Security-related changes\n- Portal access changes\n\n## Patterns\n\n**Model:**\n```python\nfrom modules.firm.utils import FirmScopedMixin\n\nclass Client(FirmScopedMixin, models.Model):\n    firm = models.ForeignKey('firm.Firm', on_delete=models.CASCADE)\n    name = models.CharField(max_length=255)\n```\n\n**Viewset:**\n```python\nfrom modules.firm.utils import FirmScopedMixin\n\nclass ClientViewSet(FirmScopedMixin, viewsets.ModelViewSet):\n    queryset = Client.objects.all()\n    serializer_class = ClientSerializer\n```\n\n**Serializer:**\n```python\nclass ClientSerializer(serializers.ModelSerializer):\n    class Meta:\n        model = Client\n        fields = '__all__'\n```\n\n## Boundaries\n\n**Can Import From:**\n- ✅ `backend/modules/core`\n- ✅ `backend/modules/firm`\n\n**Cannot Import From:**\n- ❌ `backend/modules/crm` (requires ADR)\n- ❌ `backend/modules/finance` (requires ADR)\n- ❌ `backend/modules/projects` (requires ADR)\n\n**Used By:**\n- `backend/api/clients`\n- `frontend/src/api/clients.ts`\n\n## Test Patterns\n\n**Viewset Test:**\n```python\nimport pytest\nfrom rest_framework.test import APIClient\nfrom modules.firm.models import Firm\nfrom modules.clients.models import Client\n\n@pytest.fixture\ndef api_client(firm, user):\n    client = APIClient()\n    client.force_authenticate(user=user)\n    client.force_authenticate(firm=firm)  # Set request.firm\n    return client\n\ndef test_client_list(api_client, firm):\n    Client.objects.create(firm=firm, name='Test Client')\n    response = api_client.get('/api/clients/')\n    assert response.status_code == 200\n    assert len(response.data['results']) == 1\n    assert response.data['results'][0]['name'] == 'Test Client'\n```\n\n**Model Test:**\n```python\ndef test_client_firm_scoping(firm):\n    client = Client.objects.create(firm=firm, name='Test Client')\n    assert client.firm == firm\n    assert Client.objects.filter(firm=firm).count() == 1\n```\n\n**Serializer Test:**\n```python\ndef test_client_serializer(firm):\n    client = Client.objects.create(firm=firm, name='Test Client')\n    serializer = ClientSerializer(client)\n    assert serializer.data['name'] == 'Test Client'\n    assert serializer.data['firm'] == firm.id\n```\n\n**Coverage Requirements:**\n- Minimum 80% coverage for new code\n- All viewsets must have tests\n- All serializers must have tests\n- Firm-scoping must be tested\n\n## Common Tasks\n\n**Add New Client Field:**\n1. Add field to `backend/modules/clients/models/clients.py`\n2. Create migration: `python manage.py makemigrations clients`\n3. Update `ClientSerializer` in `serializers.py`\n4. Add/update tests in `tests/clients/`\n5. Run: `pytest tests/clients/ -v --cov=modules.clients`\n\n**Add New Contact Model:**\n1. Create model in `backend/modules/clients/models/contacts.py`\n2. Inherit from `FirmScopedMixin`\n3. Add `firm` ForeignKey\n4. Create migration\n5. Add serializer\n6. Add viewset\n7. Add tests (viewset, serializer, model)\n8. Verify coverage: `pytest tests/clients/ --cov=modules.clients --cov-report=term-missing`\n\n## Links\n\n- Full guide: `backend/BACKEND.md`\n- Policy: `.repo/policy/BOUNDARIES.md`\n- JSON context: `.agent-context.json`\n\n---\n\n**Note:** All client data must be firm-scoped. Cross-module imports require ADR.\n"
        },
        {
          "path": "backend/modules/finance/.AGENT.md",
          "type": "Markdown",
          "purpose": "Finance module quick reference",
          "used_by": [
            "Agents entering finance module"
          ],
          "content": "# Finance Module - Agent Quick Reference\n\n**Folder:** `backend/modules/finance/`\n**Purpose:** Finance - billing, invoicing, payments, accounting integrations\n**Layer:** Domain\n\n## Quick Rules\n\n✅ **Can Do:**\n- Create finance models with `FirmScopedMixin`\n- Add billing logic\n- Add payment processing\n- Add accounting integrations\n\n❌ **Cannot Do:**\n- Import from other business modules without ADR\n- Break firm-scoping\n- Modify payment flows without HITL\n- Add external payment services without security review\n\n⚠️ **Requires HITL:**\n- **ALL changes** (money flows require HITL per Article 8)\n- Payment flow changes\n- Billing logic changes\n- External service integrations\n- Security-related changes\n\n## Patterns\n\n**Model:**\n```python\nfrom modules.firm.utils import FirmScopedMixin\n\nclass Invoice(FirmScopedMixin, models.Model):\n    firm = models.ForeignKey('firm.Firm', on_delete=models.CASCADE)\n```\n\n**Viewset:**\n```python\nfrom modules.firm.utils import FirmScopedMixin\n\nclass InvoiceViewSet(FirmScopedMixin, viewsets.ModelViewSet):\n    queryset = Invoice.objects.all()\n    serializer_class = InvoiceSerializer\n```\n\n## Boundaries\n\n**Can Import From:**\n- ✅ `backend/modules/core`\n- ✅ `backend/modules/firm`\n\n**Cannot Import From:**\n- ❌ `backend/modules/clients` (requires ADR)\n- ❌ `backend/modules/crm` (requires ADR)\n- ❌ `backend/modules/projects` (requires ADR)\n\n**Used By:**\n- `backend/api/finance`\n- `frontend/src/api/finance.ts`\n\n## Common Tasks\n\n**Add Payment Method:**\n1. **CREATE HITL ITEM FIRST** (money flows require HITL)\n2. Add model if needed\n3. Add payment service\n4. Add tests\n5. Get HITL approval before merging\n\n## Links\n\n- Full guide: `backend/BACKEND.md`\n- Policy: `.repo/policy/SECURITY_BASELINE.md` (money flows)\n- JSON context: `.agent-context.json`\n\n---\n\n**⚠️ CRITICAL:** All finance changes require HITL. Money flows are high-risk (Article 8).\n"
        },
        {
          "path": "frontend/src/components/.AGENT.md",
          "type": "Markdown",
          "purpose": "Components folder quick reference",
          "used_by": [
            "Agents entering components/"
          ],
          "content": "# Components - Agent Quick Reference\n\n**Folder:** `frontend/src/components/`\n**Purpose:** Reusable React components - Layout, ErrorBoundary, CommandCenter, etc.\n**Layer:** UI\n\n## Quick Rules\n\n✅ **Can Do:**\n- Create new React components\n- Add TypeScript types\n- Use React Query hooks for data\n- Add co-located CSS files\n- Create reusable components\n\n❌ **Cannot Do:**\n- Break existing component patterns without justification\n- Create new abstractions before checking existing patterns\n- Skip TypeScript types\n- Use non-functional components\n- Break component API contracts\n\n⚠️ **Requires HITL:**\n- Breaking component API changes\n- Security-related changes\n\n## Patterns\n\n**Component:**\n```typescript\nexport const Component: React.FC<ComponentProps> = () => {\n  const { data } = useQuery(...);\n  return <div>...</div>;\n};\n```\n\n**With CSS:**\n```typescript\n// Component.tsx\nimport './Component.css';\n\nexport const Component: React.FC = () => {\n  // ...\n};\n```\n\n## Boundaries\n\n**Can Import From:**\n- ✅ `frontend/src/api`\n- ✅ `frontend/src/contexts`\n\n**Cannot Import From:**\n- ❌ `backend/` (use API clients instead)\n\n**Used By:**\n- `frontend/src/pages`\n\n## Test Patterns\n\n**Component Test:**\n```typescript\nimport { render, screen } from '@testing-library/react';\nimport { QueryClient, QueryClientProvider } from '@tanstack/react-query';\nimport { Component } from './Component';\n\nconst queryClient = new QueryClient({\n  defaultOptions: { queries: { retry: false } },\n});\n\nconst wrapper = ({ children }: { children: React.ReactNode }) => (\n  <QueryClientProvider client={queryClient}>{children}</QueryClientProvider>\n);\n\ndescribe('Component', () => {\n  it('renders correctly', () => {\n    render(<Component />, { wrapper });\n    expect(screen.getByText('Expected Text')).toBeInTheDocument();\n  });\n\n  it('handles user interaction', async () => {\n    const { user } = render(<Component />, { wrapper });\n    await user.click(screen.getByRole('button'));\n    expect(screen.getByText('Updated Text')).toBeInTheDocument();\n  });\n});\n```\n\n**Hook Test:**\n```typescript\nimport { renderHook, waitFor } from '@testing-library/react';\nimport { QueryClient, QueryClientProvider } from '@tanstack/react-query';\nimport { useCustomHook } from './useCustomHook';\n\nconst queryClient = new QueryClient({\n  defaultOptions: { queries: { retry: false } },\n});\n\nconst wrapper = ({ children }: { children: React.ReactNode }) => (\n  <QueryClientProvider client={queryClient}>{children}</QueryClientProvider>\n);\n\ndescribe('useCustomHook', () => {\n  it('fetches data correctly', async () => {\n    const { result } = renderHook(() => useCustomHook(), { wrapper });\n    await waitFor(() => expect(result.current.isSuccess).toBe(true));\n    expect(result.current.data).toBeDefined();\n  });\n});\n```\n\n**Coverage Requirements:**\n- Minimum 70% coverage for new components\n- All user interactions must be tested\n- React Query hooks must be tested\n- Error states must be tested\n\n## Common Tasks\n\n**Add New Component:**\n1. Create `Component.tsx` in `frontend/src/components/`\n2. Create `Component.css` (co-located)\n3. Add TypeScript types\n4. Use functional component pattern\n5. Add tests in `frontend/tests/components/Component.test.tsx`\n6. Run: `npm test Component.test.tsx`\n7. Verify coverage: `npm test -- --coverage`\n\n## Links\n\n- Full guide: `frontend/FRONTEND.md`\n- Policy: `.repo/policy/BESTPR.md`\n- JSON context: `.agent-context.json`\n\n---\n\n**Note:** Always use functional components with TypeScript. Check existing patterns first.\n"
        },
        {
          "path": "frontend/src/api/.AGENT.md",
          "type": "Markdown",
          "purpose": "API client folder quick reference",
          "used_by": [
            "Agents entering API clients"
          ],
          "content": "# API Clients - Agent Quick Reference\n\n**Folder:** `frontend/src/api/`\n**Purpose:** API client functions organized by domain - uses TanStack React Query\n**Layer:** UI\n\n## Quick Rules\n\n✅ **Can Do:**\n- Create API client functions\n- Add React Query hooks (`useQuery`, `useMutation`)\n- Organize by domain (clients, crm, finance, etc.)\n- Add TypeScript types\n\n❌ **Cannot Do:**\n- Use non-React Query patterns for data fetching\n- Break TypeScript types\n- Create direct fetch calls (use API client)\n- Skip error handling\n\n⚠️ **Requires HITL:**\n- Breaking API contract changes\n- Security-related changes\n\n## Patterns\n\n**Query Hook:**\n```typescript\nexport const useClients = () => {\n  return useQuery({\n    queryKey: ['clients'],\n    queryFn: () => apiClient.get('/api/clients/')\n  });\n};\n```\n\n**Mutation Hook:**\n```typescript\nexport const useCreateClient = () => {\n  return useMutation({\n    mutationFn: (data) => apiClient.post('/api/clients/', data)\n  });\n};\n```\n\n## Boundaries\n\n**Can Import From:**\n- ✅ `backend/` (for API contracts)\n\n**Cannot Import From:**\n- ❌ Direct imports from backend code\n\n**Used By:**\n- `frontend/src/pages`\n- `frontend/src/components`\n\n## Common Tasks\n\n**Add New API Client Function:**\n1. Add function to appropriate domain file (e.g., `clients.ts`)\n2. Use `useQuery` or `useMutation` from React Query\n3. Add TypeScript types\n4. Add error handling\n5. Add tests in `__tests__/`\n\n## Links\n\n- Full guide: `frontend/FRONTEND.md`\n- Policy: `.repo/policy/BESTPR.md`\n- JSON context: `.agent-context.json`\n\n---\n\n**Note:** Always use React Query for data fetching. Never use direct fetch calls.\n"
        }
      ]
    },
    "cicd_integration": {
      "description": "CI/CD integration files",
      "files": [
        {
          "path": "/Makefile",
          "type": "Makefile",
          "lines": 212,
          "purpose": "Root Makefile orchestrating backend/frontend workflows",
          "key_targets": [
            "setup: Backend + frontend setup",
            "lint: Backend + frontend linting",
            "test: Backend + frontend tests",
            "test-performance: Backend performance tests",
            "typecheck: Backend type checking",
            "e2e: Frontend e2e tests",
            "frontend-build: Frontend build",
            "verify: Full verification (SKIP_HEAVY=1 by default)",
            "ci: CI workflow",
            "check-governance: Runs governance-verify.sh (lines 200-209)"
          ],
          "key_functionality": [
            "Orchestrates backend/frontend Makefiles",
            "Summary reporting",
            "check-governance target calls scripts/governance-verify.sh"
          ],
          "referenced_by": [
            "repo.manifest.yaml (commands resolve to Makefile targets)"
          ],
          "used_by": [
            "CI workflows",
            "local development"
          ],
          "content": "# Meta-commentary:\n# - Current Status: Orchestrates backend/frontend workflows with summary reporting.\n# - Mapping: `test-performance` calls the backend performance target for query-efficiency checks.\n# - Reasoning: Keep verification steps explicit and centralized for deterministic local runs.\n# - Assumption: Backend performance tests run in environments with Django test settings configured.\n# - Limitation: Verify target is best-effort; some steps may fail in constrained environments.\nSHELL := /bin/bash\n.ONESHELL:\n\nQ := @\nifneq ($(V),1)\nQ := @\nelse\nQ :=\nendif\n\nSKIP_HEAVY ?= 1\n\n.PHONY: setup lint test test-performance typecheck dev openapi verify ci e2e frontend-build fixtures check-governance\n\nsetup:\n\t$(Q)set +e\n\tbackend_status=0\n\tfrontend_status=0\n\t$(Q)echo \"=== BACKEND SETUP ===\"\n\t$(Q)$(MAKE) -C backend setup V=$(V)\n\tbackend_status=$$?\n\t$(Q)echo \"=== FRONTEND SETUP ===\"\n\t$(Q)$(MAKE) -C frontend setup V=$(V)\n\tfrontend_status=$$?\n\t$(Q)echo \"=== SUMMARY ===\"\n\t$(Q)if [ $$backend_status -eq 0 ]; then echo \"BACKEND SETUP: PASS\"; else echo \"BACKEND SETUP: FAIL\"; fi\n\t$(Q)if [ $$frontend_status -eq 0 ]; then echo \"FRONTEND SETUP: PASS\"; else echo \"FRONTEND SETUP: FAIL\"; fi\n\t$(Q)summary=0\n\t$(Q)if [ $$backend_status -ne 0 ] || [ $$frontend_status -ne 0 ]; then summary=1; fi\n\t$(Q)exit $$summary\n\nlint:\n\t$(Q)set +e\n\tbackend_status=0\n\tfrontend_status=0\n\t$(Q)echo \"=== BACKEND LINT ===\"\n\t$(Q)$(MAKE) -C backend lint V=$(V)\n\tbackend_status=$$?\n\t$(Q)echo \"=== FRONTEND LINT ===\"\n\t$(Q)$(MAKE) -C frontend lint V=$(V)\n\tfrontend_status=$$?\n\t$(Q)echo \"=== SUMMARY ===\"\n\t$(Q)if [ $$backend_status -eq 0 ]; then echo \"BACKEND LINT: PASS\"; else echo \"BACKEND LINT: FAIL\"; fi\n\t$(Q)if [ $$frontend_status -eq 0 ]; then echo \"FRONTEND LINT: PASS\"; else echo \"FRONTEND LINT: FAIL\"; fi\n\t$(Q)summary=0\n\t$(Q)if [ $$backend_status -ne 0 ] || [ $$frontend_status -ne 0 ]; then summary=1; fi\n\t$(Q)exit $$summary\n\ntest:\n\t$(Q)set +e\n\tbackend_status=0\n\tfrontend_status=0\n\t$(Q)echo \"=== BACKEND TEST ===\"\n\t$(Q)$(MAKE) -C backend test V=$(V)\n\tbackend_status=$$?\n\t$(Q)echo \"=== FRONTEND TEST ===\"\n\t$(Q)$(MAKE) -C frontend test V=$(V)\n\tfrontend_status=$$?\n\t$(Q)echo \"=== SUMMARY ===\"\n\t$(Q)if [ $$backend_status -eq 0 ]; then echo \"BACKEND TEST: PASS\"; else echo \"BACKEND TEST: FAIL\"; fi\n\t$(Q)if [ $$frontend_status -eq 0 ]; then echo \"FRONTEND TEST: PASS\"; else echo \"FRONTEND TEST: FAIL\"; fi\n\t$(Q)summary=0\n\t$(Q)if [ $$backend_status -ne 0 ] || [ $$frontend_status -ne 0 ]; then summary=1; fi\n\t$(Q)exit $$summary\n\ntest-performance:\n\t$(Q)set +e\n\tbackend_status=0\n\t$(Q)echo \"=== BACKEND PERFORMANCE TESTS ===\"\n\t$(Q)$(MAKE) -C backend test-performance V=$(V)\n\tbackend_status=$$?\n\t$(Q)echo \"=== SUMMARY ===\"\n\t$(Q)if [ $$backend_status -eq 0 ]; then echo \"BACKEND PERFORMANCE TESTS: PASS\"; else echo \"BACKEND PERFORMANCE TESTS: FAIL\"; fi\n\t$(Q)exit $$backend_status\n\ntypecheck:\n\t$(Q)set +e\n\tbackend_status=0\n\t$(Q)echo \"=== BACKEND TYPECHECK ===\"\n\t$(Q)$(MAKE) -C backend typecheck V=$(V)\n\tbackend_status=$$?\n\t$(Q)echo \"=== SUMMARY ===\"\n\t$(Q)if [ $$backend_status -eq 0 ]; then echo \"BACKEND TYPECHECK: PASS\"; else echo \"BACKEND TYPECHECK: FAIL\"; fi\n\t$(Q)exit $$backend_status\n\ne2e:\n\t$(Q)set +e\n\tfrontend_status=0\n\t$(Q)echo \"=== FRONTEND E2E ===\"\n\t$(Q)$(MAKE) -C frontend e2e V=$(V)\n\tfrontend_status=$$?\n\t$(Q)echo \"=== SUMMARY ===\"\n\t$(Q)if [ $$frontend_status -eq 0 ]; then echo \"FRONTEND E2E: PASS\"; else echo \"FRONTEND E2E: FAIL\"; fi\n\t$(Q)exit $$frontend_status\n\nfrontend-build:\n\t$(Q)set +e\n\tfrontend_status=0\n\t$(Q)echo \"=== FRONTEND BUILD ===\"\n\t$(Q)$(MAKE) -C frontend build-check V=$(V)\n\tfrontend_status=$$?\n\t$(Q)echo \"=== SUMMARY ===\"\n\t$(Q)if [ $$frontend_status -eq 0 ]; then echo \"FRONTEND BUILD: PASS\"; else echo \"FRONTEND BUILD: FAIL\"; fi\n\t$(Q)exit $$frontend_status\n\ndev:\n\t$(Q)set +e\n\tbackend_status=0\n\tfrontend_status=0\n\t$(Q)echo \"=== BACKEND DEV ===\"\n\t$(Q)$(MAKE) -C backend dev V=$(V)\n\tbackend_status=$$?\n\t$(Q)echo \"=== FRONTEND DEV ===\"\n\t$(Q)$(MAKE) -C frontend dev V=$(V)\n\tfrontend_status=$$?\n\t$(Q)echo \"=== SUMMARY ===\"\n\t$(Q)if [ $$backend_status -eq 0 ]; then echo \"BACKEND DEV: PASS\"; else echo \"BACKEND DEV: FAIL\"; fi\n\t$(Q)if [ $$frontend_status -eq 0 ]; then echo \"FRONTEND DEV: PASS\"; else echo \"FRONTEND DEV: FAIL\"; fi\n\t$(Q)summary=0\n\t$(Q)if [ $$backend_status -ne 0 ] || [ $$frontend_status -ne 0 ]; then summary=1; fi\n\t$(Q)exit $$summary\n\nfixtures:\n\t$(Q)set +e\n\tbackend_status=0\n\t$(Q)echo \"=== BACKEND FIXTURES ===\"\n\t$(Q)$(MAKE) -C backend fixtures V=$(V)\n\tbackend_status=$$?\n\t$(Q)echo \"=== SUMMARY ===\"\n\t$(Q)if [ $$backend_status -eq 0 ]; then echo \"BACKEND FIXTURES: PASS\"; else echo \"BACKEND FIXTURES: FAIL\"; fi\n\t$(Q)exit $$backend_status\n\nopenapi:\n\t$(Q)set +e\n\tbackend_status=0\n\t$(Q)echo \"=== BACKEND OPENAPI ===\"\n\t$(Q)$(MAKE) -C backend openapi V=$(V)\n\tbackend_status=$$?\n\t$(Q)echo \"=== SUMMARY ===\"\n\t$(Q)if [ $$backend_status -eq 0 ]; then echo \"BACKEND OPENAPI: PASS\"; else echo \"BACKEND OPENAPI: FAIL\"; fi\n\t$(Q)exit $$backend_status\n\nverify:\n\t$(Q)set +e\n\tbackend_lint_status=0\n\tbackend_typecheck_status=0\n\tbackend_performance_status=0\n\tfrontend_lint_status=0\n\tbackend_test_status=0\n\tfrontend_test_status=0\n\tfrontend_build_status=0\n\topenapi_status=0\n\topenapi_diff_status=0\n\t$(Q)echo \"=== BACKEND LINT ===\"\n\t$(Q)$(MAKE) -C backend lint V=$(V)\n\tbackend_lint_status=$$?\n\t$(Q)echo \"=== BACKEND TYPECHECK ===\"\n\t$(Q)$(MAKE) -C backend typecheck V=$(V)\n\tbackend_typecheck_status=$$?\n\t$(Q)echo \"=== FRONTEND LINT ===\"\n\t$(Q)$(MAKE) -C frontend lint V=$(V)\n\tfrontend_lint_status=$$?\n\t$(Q)if [ \"$(SKIP_HEAVY)\" = \"1\" ]; then \\\n\t\techo \"=== BACKEND TEST ===\"; echo \"SKIPPED (set SKIP_HEAVY=0 to run)\"; backend_test_status=0; \\\n\t\techo \"=== BACKEND PERFORMANCE TESTS ===\"; echo \"SKIPPED (set SKIP_HEAVY=0 to run)\"; backend_performance_status=0; \\\n\t\techo \"=== FRONTEND TEST ===\"; echo \"SKIPPED (set SKIP_HEAVY=0 to run)\"; frontend_test_status=0; \\\n\t\techo \"=== FRONTEND BUILD ===\"; echo \"SKIPPED (set SKIP_HEAVY=0 to run)\"; frontend_build_status=0; \\\n\t\techo \"=== BACKEND OPENAPI ===\"; echo \"SKIPPED (set SKIP_HEAVY=0 to run)\"; openapi_status=0; openapi_diff_status=0; \\\n\telse \\\n\t\techo \"=== BACKEND TEST ===\"; $(MAKE) -C backend test V=$(V); backend_test_status=$$?; \\\n\t\techo \"=== BACKEND PERFORMANCE TESTS ===\"; $(MAKE) -C backend test-performance V=$(V); backend_performance_status=$$?; \\\n\t\techo \"=== FRONTEND TEST ===\"; $(MAKE) -C frontend test V=$(V); frontend_test_status=$$?; \\\n\t\techo \"=== FRONTEND BUILD ===\"; $(MAKE) -C frontend build-check V=$(V); frontend_build_status=$$?; \\\n\t\techo \"=== BACKEND OPENAPI ===\"; $(MAKE) -C backend openapi V=$(V); openapi_status=$$?; \\\n\t\tgit diff --exit-code backend/openapi.yaml; openapi_diff_status=$$?; \\\n\tfi\n\t$(Q)echo \"=== SUMMARY ===\"\n\t$(Q)if [ $$backend_lint_status -eq 0 ]; then echo \"BACKEND LINT: PASS\"; else echo \"BACKEND LINT: FAIL\"; fi\n\t$(Q)if [ $$backend_typecheck_status -eq 0 ]; then echo \"BACKEND TYPECHECK: PASS\"; else echo \"BACKEND TYPECHECK: FAIL\"; fi\n\t$(Q)if [ $$backend_performance_status -eq 0 ]; then echo \"BACKEND PERFORMANCE TESTS: PASS\"; else echo \"BACKEND PERFORMANCE TESTS: FAIL\"; fi\n\t$(Q)if [ $$frontend_lint_status -eq 0 ]; then echo \"FRONTEND LINT: PASS\"; else echo \"FRONTEND LINT: FAIL\"; fi\n\t$(Q)if [ $$backend_test_status -eq 0 ]; then echo \"BACKEND TEST: PASS\"; else echo \"BACKEND TEST: FAIL\"; fi\n\t$(Q)if [ $$frontend_test_status -eq 0 ]; then echo \"FRONTEND TEST: PASS\"; else echo \"FRONTEND TEST: FAIL\"; fi\n\t$(Q)if [ $$frontend_build_status -eq 0 ]; then echo \"FRONTEND BUILD: PASS\"; else echo \"FRONTEND BUILD: FAIL\"; fi\n\t$(Q)if [ $$openapi_status -eq 0 ]; then echo \"BACKEND OPENAPI: PASS\"; else echo \"BACKEND OPENAPI: FAIL\"; fi\n\t$(Q)if [ $$openapi_diff_status -eq 0 ]; then echo \"OPENAPI DRIFT: PASS\"; else echo \"OPENAPI DRIFT: FAIL\"; fi\n\t$(Q)summary=0\n\t$(Q)if [ $$backend_lint_status -ne 0 ] || [ $$backend_typecheck_status -ne 0 ] || [ $$backend_performance_status -ne 0 ] || \\\n\t\t[ $$frontend_lint_status -ne 0 ] || [ $$backend_test_status -ne 0 ] || \\\n\t\t[ $$frontend_test_status -ne 0 ] || [ $$frontend_build_status -ne 0 ] || [ $$openapi_status -ne 0 ] || \\\n\t\t[ $$openapi_diff_status -ne 0 ]; then summary=1; fi\n\t$(Q)exit $$summary\n\ncheck-governance:\n\t$(Q)set +e\n\tgovernance_status=0\n\t$(Q)echo \"=== GOVERNANCE VERIFICATION ===\"\n\t$(Q)chmod +x scripts/governance-verify.sh\n\t$(Q)./scripts/governance-verify.sh\n\tgovernance_status=$$?\n\t$(Q)echo \"=== SUMMARY ===\"\n\t$(Q)if [ $$governance_status -eq 0 ]; then echo \"GOVERNANCE VERIFICATION: PASS\"; else echo \"GOVERNANCE VERIFICATION: FAIL\"; fi\n\t$(Q)exit $$governance_status\n\nci: verify\n"
        },
        {
          "path": ".pre-commit-config.yaml",
          "type": "YAML",
          "lines": 89,
          "purpose": "Pre-commit hooks configuration",
          "key_hooks": [
            "Ruff (Python linter)",
            "Black (Python formatter)",
            "Mypy (Type checking)",
            "git-secrets (Secret detection)",
            "lint-firm-scoping (Custom firm scoping linter)",
            "Django checks",
            "Frontend ESLint",
            "Trailing whitespace, file endings, YAML/JSON checks",
            "governance-verify (runs on .repo/, agents/, scripts/ changes)"
          ],
          "installation": "pip install pre-commit && pre-commit install",
          "used_by": [
            "Git pre-commit hooks"
          ],
          "status": "Documented, verification needed",
          "content": "# Pre-commit hooks for TIER 0 enforcement\n# Install: pip install pre-commit && pre-commit install\n# Run manually: pre-commit run --all-files\n\nrepos:\n  # Ruff - Modern Python linter\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.1.9\n    hooks:\n      - id: ruff\n        args: [--fix, --exit-non-zero-on-fix]\n\n  # Black - Code formatter\n  - repo: https://github.com/psf/black\n    rev: 23.12.1\n    hooks:\n      - id: black\n\n  # Mypy - Type checking\n  # WHY: Catch type drift before code lands, matching CI expectations.\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.7.1\n    hooks:\n      - id: mypy\n        args: [src]\n        pass_filenames: false\n\n  # TIER 0: Custom firm scoping linter\n  - repo: local\n    hooks:\n      # Git secrets - Prevent accidental secret commits\n      # WHY: git-secrets ships as a system binary, so we invoke it directly to avoid wrapper drift.\n      - id: git-secrets\n        name: git-secrets\n        entry: git-secrets --scan\n        language: system\n        pass_filenames: false\n      - id: lint-firm-scoping\n        name: TIER 0 Firm Scoping Linter\n        entry: python scripts/lint_firm_scoping.py\n        language: system\n        types: [python]\n        pass_filenames: false\n        always_run: true\n\n  # Django checks\n  - repo: local\n    hooks:\n      - id: django-check\n        name: Django System Checks\n        entry: python src/manage.py check\n        language: system\n        types: [python]\n        pass_filenames: false\n        always_run: true\n\n  # Frontend ESLint\n  # WHY: Enforce frontend linting for TS/React changes pre-commit.\n  - repo: local\n    hooks:\n      - id: eslint-frontend\n        name: Frontend ESLint\n        entry: bash -c 'cd src/frontend && npm run lint'\n        language: system\n        files: ^src/frontend/\n        pass_filenames: false\n\n  # Trailing whitespace and file endings\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n      - id: check-json\n      - id: check-added-large-files\n        args: ['--maxkb=1000']\n\n  # Governance checks\n  - repo: local\n    hooks:\n      - id: governance-verify\n        name: Governance Verification\n        entry: bash -c 'chmod +x scripts/governance-verify.sh && ./scripts/governance-verify.sh || true'\n        language: system\n        pass_filenames: false\n        always_run: false\n        files: '\\.(md|yaml|yml|json)$|^\\.repo/|^agents/|^scripts/'\n"
        },
        {
          "path": ".repo/repo.manifest.yaml",
          "type": "YAML",
          "lines": 54,
          "purpose": "Source of truth for executable commands + verification profiles",
          "key_contents": [
            "repo metadata (ships, ship_kind, release_protects)",
            "prerequisites (package_manager, runtime_pinned, platform_tools_required_for_release)",
            "commands (canonical names): install, check:quick, check:ci, check:release, check:governance, check:boundaries, check:security",
            "verify_profiles: quick, ci, release, governance",
            "tests: required_level (unit+integration)",
            "budgets: mode, enforcement, fallback_to_default",
            "security: every_pr, release_includes_security, dependency_vulns_always_hitl, secrets_absolute_prohibition, forbidden_patterns_source",
            "boundaries: enforcement, edges_model, edges"
          ],
          "rule": "Agents MUST NOT guess commands. If unknown, set <UNKNOWN> and open HITL.",
          "referenced_by": [
            "AGENTS.json",
            "rules.json",
            "all agents"
          ],
          "used_by": [
            "Agents before running ANY command"
          ],
          "note": "GitHub Actions workflows (.github/workflows/ci.yml) mentioned in assessments but not found in file system. May need to be created or exists in different location.",
          "content": "# /.repo/repo.manifest.yaml\n# SOURCE OF TRUTH for executable commands + verification profiles.\n# RULE: Agents MUST NOT guess commands. If unknown, set <UNKNOWN> and open HITL.\n\nrepo:\n  ships: true\n  ship_kind: user_facing_app\n  release_protects: [app_stability, login_security, money_flows]\n\nprerequisites:\n  package_manager: npm+pip\n  runtime_pinned: true\n  platform_tools_required_for_release: true\n\n# Canonical commands (names are fixed). Fill values by following docs/development/standards/manifest.md\n# Commands resolved from: Makefile, CI workflow (.github/workflows/ci.yml), package.json scripts\ncommands:\n  install: \"make setup\"\n  check:quick: \"make lint && make frontend-build\"\n  check:ci: \"make verify SKIP_HEAVY=0\"\n  check:release: \"make verify SKIP_HEAVY=0 && pip-audit -r requirements.txt -r requirements-dev.txt && safety check --file requirements.txt && bandit -r backend/ -ll && cd frontend && npm audit --audit-level=moderate && cd .. && trufflehog filesystem --directory . --json || true\"\n  check:governance: \"./scripts/governance-verify.sh\"\n  check:boundaries: \"lint-imports --config .importlinter\"\n  check:security: \"pip-audit -r requirements.txt -r requirements-dev.txt && safety check --file requirements.txt && bandit -r backend/ -ll && cd frontend && npm audit --audit-level=moderate && cd .. && trufflehog filesystem --directory . --json || true\"\n\nverify_profiles:\n  quick: [check:quick]\n  ci: [check:ci]\n  release: [check:release]\n  governance: [check:governance]\n\ntests:\n  required_level: unit+integration\n\nbudgets:\n  mode: both               # bundle + runtime\n  enforcement: hard_fail_with_waiver\n  fallback_to_default: true\n  # defaults live in: /.repo/policy/QUALITY_GATES.md (if repo-specific budgets missing)\n\nsecurity:\n  every_pr: true\n  release_includes_security: true\n  dependency_vulns_always_hitl: true\n  secrets_absolute_prohibition: true\n  forbidden_patterns_source: \"/.repo/policy/SECURITY_BASELINE.md\"\n\nboundaries:\n  enforcement: hybrid_checker_plus_manifest_edges\n  edges_model: layered_allow_list\n  # Explicit edges represent allowed exceptions beyond the default import direction.\n  # Format: from -> to, with reason + required ADR if cross-feature.\n  edges: []\n"
        }
      ]
    },
    "supporting_documentation": {
      "description": "Supporting documentation files",
      "files": [
        {
          "path": ".repo/DOCUMENT_MAP.md",
          "type": "Markdown",
          "lines": 248,
          "purpose": "Token-optimized reference system mapping all documents",
          "key_contents": [
            "Document inventory (when to read, token cost, priority)",
            "Smart reference trails by workflow: Starting a new task, Making code changes, Security/risky changes, Cross-module work, Creating PR, UNKNOWN situation, Task management",
            "Token optimization rules (DO/DON'T)",
            "Token budget by workflow",
            "Document size estimates"
          ],
          "used_by": [
            "Agents for efficient document navigation"
          ],
          "referenced_by": [
            "AGENTS.md"
          ],
          "content": "# Document Map: Token-Optimized Reference System\n\n**Purpose:** Map all documents and when agents need to read them (context-based, not always).\n\n---\n\n## Document Inventory\n\n### Core Policy (Always Available, Read When Needed)\n\n| Document | When to Read | Token Cost | Priority |\n|----------|--------------|-----------|----------|\n| `.repo/policy/CONSTITUTION.md` | When uncertain about authority/process | Medium | High |\n| `.repo/policy/PRINCIPLES.md` | When making decisions about workflow | High | Medium |\n| `.repo/policy/QUALITY_GATES.md` | Before PR, when checking merge requirements | Medium | High |\n| `.repo/policy/SECURITY_BASELINE.md` | When touching security/auth/money/external systems | Medium | High |\n| `.repo/policy/HITL.md` | When creating HITL items or checking blockers | Low | High |\n| `.repo/policy/BOUNDARIES.md` | When importing across modules/features | Low | Medium |\n| `.repo/policy/BESTPR.md` | When working in repo-specific areas (backend/frontend) | High | Medium |\n\n### Agent Framework (Context-Dependent)\n\n| Document | When to Read | Token Cost | Priority |\n|----------|--------------|-----------|----------|\n| `.repo/agents/AGENTS.md` | Deep dive on agent rules (if QUICK_REFERENCE insufficient) | Medium | Low |\n| `.repo/agents/QUICK_REFERENCE.md` | **START HERE** - Quick decision tree | Low | High |\n| `.repo/agents/capabilities.md` | When checking what agent role can do | Low | Low |\n| `.repo/agents/roles/primary.md` | When acting as primary agent | Low | Low |\n| `.repo/agents/roles/secondary.md` | When acting as secondary agent | Low | Low |\n| `.repo/agents/checklists/change-plan.md` | When planning a change | Low | Medium |\n| `.repo/agents/checklists/pr-review.md` | When reviewing/creating PR | Low | Medium |\n| `.repo/agents/prompts/pr_template.md` | When creating PR | Low | Medium |\n| `.repo/agents/prompts/task_packet.md` | When creating task packets | Low | Low |\n\n### Task Management (Workflow-Specific)\n\n| Document | When to Read | Token Cost | Priority |\n|----------|--------------|-----------|----------|\n| `.repo/tasks/TODO.md` | **ALWAYS FIRST** - Current task | Low | Critical |\n| `.repo/tasks/BACKLOG.md` | When promoting tasks or checking priorities | Low | Medium |\n| `.repo/tasks/ARCHIVE.md` | When archiving tasks (reference only) | Low | Low |\n| `.repo/tasks/README.md` | When managing tasks (first time) | Medium | Low |\n\n### Commands & Configuration (Context-Dependent)\n\n| Document | When to Read | Token Cost | Priority |\n|----------|--------------|-----------|----------|\n| `.repo/repo.manifest.yaml` | **ALWAYS** - Before running any command | Low | Critical |\n| `Makefile` | When manifest unclear, checking actual commands | Medium | Low |\n\n### Templates (Only When Creating Artifacts)\n\n| Document | When to Read | Token Cost | Priority |\n|----------|--------------|-----------|----------|\n| `.repo/templates/AGENT_TRACE_SCHEMA.json` | When creating trace logs | Low | Medium |\n| `.repo/templates/AGENT_LOG_TEMPLATE.md` | When creating agent logs | Low | Medium |\n| `.repo/templates/PR_TEMPLATE.md` | When creating PR | Low | Medium |\n| `.repo/templates/ADR_TEMPLATE.md` | When creating ADR | Low | Low |\n| `.repo/templates/WAIVER_TEMPLATE.md` | When creating waiver | Low | Low |\n| `.repo/templates/examples/*` | When unsure of format | Medium | Low |\n\n### Documentation (Reference Only)\n\n| Document | When to Read | Token Cost | Priority |\n|----------|--------------|-----------|----------|\n| `.repo/GOVERNANCE.md` | First-time onboarding, framework overview | High | Low |\n| `.repo/INDEX.md` | Navigation reference | Low | Low |\n| `docs/architecture/README.md` | When understanding system design | High | Medium |\n| `README.md` | Project overview (first time) | Medium | Low |\n\n### Archived Documents (Historical Reference Only)\n\n**Note:** Assessment and analysis documents from the framework design phase have been archived to `docs/archive/` for historical reference. They are not part of the operational documentation and should not be read by agents.\n\n---\n\n## Smart Reference Trails by Workflow\n\n### 🚀 Starting a New Task\n\n**Required Documents (in order):**\n1. `.repo/tasks/TODO.md` - **MUST READ FIRST**\n2. `.repo/repo.manifest.yaml` - Check commands\n3. `.repo/agents/QUICK_REFERENCE.md` - Quick decision tree\n4. `.repo/policy/HITL.md` - Check for blockers\n\n**Conditional Documents:**\n- If task involves security/auth/money → `.repo/policy/SECURITY_BASELINE.md`\n- If task crosses modules → `.repo/policy/BOUNDARIES.md`\n- If task is backend/frontend specific → `.repo/policy/BESTPR.md`\n\n**Token Cost:** ~500-1000 tokens (minimal)\n\n---\n\n### 💻 Making Code Changes\n\n**Required Documents:**\n1. `agents/tasks/TODO.md` - Current task\n2. `.repo/repo.manifest.yaml` - Commands\n3. `.repo/agents/checklists/change-plan.md` - Planning checklist\n\n**Conditional Documents:**\n- If crossing boundaries → `.repo/policy/BOUNDARIES.md`\n- If security-related → `.repo/policy/SECURITY_BASELINE.md`\n- If repo-specific → `.repo/policy/BESTPR.md`\n- If uncertain → `.repo/policy/CONSTITUTION.md` (Article 3: No Guessing)\n\n**Token Cost:** ~300-800 tokens\n\n---\n\n### 🔒 Security/Risky Changes\n\n**Required Documents:**\n1. `.repo/policy/SECURITY_BASELINE.md` - **MUST READ**\n2. `.repo/policy/HITL.md` - Create HITL item\n3. `.repo/templates/examples/example_hitl_item.md` - Format reference\n\n**Conditional Documents:**\n- If external systems → `.repo/policy/CONSTITUTION.md` (Article 8)\n- If uncertain → `.repo/policy/CONSTITUTION.md` (Article 3)\n\n**Token Cost:** ~400-600 tokens\n\n---\n\n### 🔀 Cross-Module/Feature Work\n\n**Required Documents:**\n1. `.repo/policy/BOUNDARIES.md` - **MUST READ**\n2. `.repo/templates/ADR_TEMPLATE.md` - Create ADR\n\n**Conditional Documents:**\n- If uncertain about boundaries → `.repo/policy/PRINCIPLES.md` (P13, P23)\n\n**Token Cost:** ~300-500 tokens\n\n---\n\n### 📝 Creating PR\n\n**Required Documents:**\n1. `.repo/agents/checklists/pr-review.md` - Review checklist\n2. `.repo/templates/PR_TEMPLATE.md` - PR format\n3. `.repo/policy/QUALITY_GATES.md` - Merge requirements\n4. `.repo/policy/HITL.md` - Check HITL status\n\n**Conditional Documents:**\n- If waiverable gates fail → `.repo/templates/WAIVER_TEMPLATE.md`\n- If trace log needed → `.repo/templates/AGENT_TRACE_SCHEMA.json`\n\n**Token Cost:** ~400-700 tokens\n\n---\n\n### ❓ UNKNOWN Situation\n\n**Required Documents:**\n1. `.repo/policy/CONSTITUTION.md` - Article 3 (No Guessing)\n2. `.repo/policy/HITL.md` - Create HITL item\n3. `.repo/templates/examples/example_hitl_item.md` - Format\n\n**Token Cost:** ~300-500 tokens\n\n---\n\n### 📋 Task Management\n\n**Required Documents:**\n1. `.repo/tasks/README.md` - Task workflow\n2. `.repo/tasks/TODO.md` - Current task\n3. `.repo/tasks/BACKLOG.md` - Next task\n\n**Token Cost:** ~200-400 tokens\n\n---\n\n## Token Optimization Rules\n\n### ✅ DO\n\n1. **Read documents in order of priority** - Start with critical, add conditional as needed\n2. **Use QUICK_REFERENCE first** - It's designed to be sufficient for most cases\n3. **Read only when needed** - Don't pre-load everything\n4. **Use examples** - When format is unclear, read template examples\n5. **Check HITL first** - Before starting work, check for blockers\n\n### ❌ DON'T\n\n1. **Don't read assessment documents** - They're for humans only\n2. **Don't read GOVERNANCE.md** - Too verbose, use QUICK_REFERENCE instead\n3. **Don't read all policies upfront** - Read conditionally based on context\n4. **Don't read PRINCIPLES.md fully** - It's 25 principles, read specific ones as needed\n5. **Don't read BESTPR.md unless working in repo-specific areas**\n\n---\n\n## Smart Reference Pattern\n\n**Pattern:** Conditional references based on workflow stage\n\n```\nSTART → TODO.md + manifest.yaml + QUICK_REFERENCE\n  ↓\nIF security → SECURITY_BASELINE.md\nIF boundaries → BOUNDARIES.md\nIF uncertain → CONSTITUTION.md (Article 3) + HITL.md\nIF PR → PR_TEMPLATE + QUALITY_GATES + HITL.md\n```\n\n---\n\n## Token Budget by Workflow\n\n| Workflow | Min Tokens | Max Tokens | Typical |\n|----------|-----------|------------|---------|\n| Starting task | 500 | 1000 | 700 |\n| Code changes | 300 | 800 | 500 |\n| Security work | 400 | 600 | 500 |\n| Cross-module | 300 | 500 | 400 |\n| Creating PR | 400 | 700 | 550 |\n| UNKNOWN | 300 | 500 | 400 |\n| Task management | 200 | 400 | 300 |\n\n**Target:** Keep typical workflows under 1000 tokens total.\n\n---\n\n## Document Size Estimates\n\n| Document | Approx Tokens | Read Frequency |\n|----------|---------------|----------------|\n| QUICK_REFERENCE.md | ~200 | High (start here) |\n| .repo/tasks/TODO.md | ~100 | Critical (always first) |\n| repo.manifest.yaml | ~150 | Critical (before commands) |\n| CONSTITUTION.md | ~300 | Medium (when uncertain) |\n| PRINCIPLES.md | ~800 | Low (read specific principles) |\n| SECURITY_BASELINE.md | ~400 | Medium (security work) |\n| BOUNDARIES.md | ~300 | Medium (cross-module) |\n| BESTPR.md | ~600 | Low (repo-specific work) |\n| QUALITY_GATES.md | ~300 | High (before PR) |\n| HITL.md | ~200 | High (check blockers) |\n\n---\n\n**End of Document Map**\n"
        },
        {
          "path": ".repo/GOVERNANCE.md",
          "type": "Markdown",
          "purpose": "Governance framework overview",
          "status": "First-time onboarding, too verbose for regular use",
          "used_by": [
            "Humans understanding framework (not agents - use QUICK_REFERENCE.md)"
          ],
          "content": "# Governance Framework\n\n**Version:** 1.0.0\n**Status:** Injectable Template\n**Layer:** Entry Point\n\n---\n\n## Welcome to the AI-Native Repository Governance Framework\n\nThis directory (`.repo/`) contains a complete governance framework designed to enable AI agents and human developers to work together safely and effectively.\n\n## 🎯 What This Framework Does\n\nThis governance system provides:\n\n1. **Clear Policies** - Constitutional rules, principles, and quality gates\n2. **Safety Boundaries** - Security baselines and architectural boundaries\n3. **Human-in-the-Loop (HITL)** - Explicit escalation points for risky decisions\n4. **Command Manifest** - Single source of truth for build, test, and verification commands\n5. **Waiver Management** - Formal process for policy exceptions\n6. **Traceability** - Every change must be justified and verifiable\n\n## 📖 Read This First\n\n### For Developers\n1. **Start with**: [`policy/CONSTITUTION.md`](policy/CONSTITUTION.md) - The 8 fundamental articles\n2. **Then read**: [`policy/PRINCIPLES.md`](policy/PRINCIPLES.md) - Operating principles (P3-P25)\n3. **Understand**: [`repo.manifest.yaml`](repo.manifest.yaml) - How to run checks correctly\n\n### For AI Agents\n1. **Always read**: `repo.manifest.yaml` first (your instruction card)\n2. **Follow**: All policies in `policy/` directory\n3. **Escalate**: When in doubt, create HITL item (don't guess)\n4. **Verify**: Every change must have evidence\n\n### For Approvers/Reviewers\n1. **Check**: [`policy/HITL.md`](policy/HITL.md) - Active human-in-the-loop items\n2. **Review**: [`policy/WAIVERS.md`](policy/WAIVERS.md) - Active policy exceptions (if exists)\n3. **Verify**: All changes have proper traceability\n\n## 📂 Directory Structure\n\n```\n.repo/\n├── GOVERNANCE.md           ← You are here (start here)\n├── repo.manifest.yaml      ← Command definitions (critical!)\n├── policy/                 ← Authoritative governance rules\n│   ├── CONSTITUTION.md     ← 8 fundamental articles (immutable)\n│   ├── PRINCIPLES.md       ← Operating principles (updateable)\n│   ├── QUALITY_GATES.md    ← Quality standards and gates\n│   ├── SECURITY_BASELINE.md← Security requirements\n│   ├── BOUNDARIES.md       ← Architectural boundaries\n│   └── HITL.md            ← Human-in-the-loop tracking\n├── agents/                 ← AI agent framework\n│   ├── rules.json         ← Core agent rules (machine-readable)\n│   ├── QUICK_REFERENCE.md  ← Human-readable rules\n│   ├── QUICK_REFERENCE.md ← One-page cheat sheet\n│   ├── capabilities.md    ← Agent capabilities list\n│   └── roles/             ← Agent role definitions\n├── templates/             ← Document templates\n│   ├── AGENT_LOG_TEMPLATE.md\n│   ├── AGENT_TRACE_SCHEMA.json\n│   └── examples/         ← Example files (trace logs, HITL items, etc.)\n├── docs/                  ← Documentation standards\n│   ├── standards/         ← Documentation standards\n│   ├── boundary_checker.md ← Boundary checker docs\n│   ├── ci_integration.md  ← CI integration guide\n│   └── automation_scripts.md ← Automation scripts docs\n└── hitl/                  ← HITL item files\n```\n\n## 🚦 How to Use This Framework\n\n### Daily Development Workflow\n1. Check if your change triggers HITL (see [`policy/SECURITY_BASELINE.md`](policy/SECURITY_BASELINE.md))\n2. Follow principles from [`policy/PRINCIPLES.md`](policy/PRINCIPLES.md)\n3. Use commands defined in [`repo.manifest.yaml`](repo.manifest.yaml)\n4. Verify your changes meet quality gates (see [`policy/QUALITY_GATES.md`](policy/QUALITY_GATES.md))\n\n### Before Merging a PR\n- [ ] All tests pass (use `check:ci` command from manifest)\n- [ ] No active HITL blockers (check [`policy/HITL.md`](policy/HITL.md))\n- [ ] Required waivers are documented (if applicable)\n- [ ] Changes are traceable to task definition\n- [ ] Evidence of verification is included\n\n### When You Need to Deviate\n1. Check if your situation requires a waiver\n2. Follow the waiver process (document in HITL if needed)\n3. Document your justification\n4. Get required approvals\n5. Set expiration date if applicable\n\n## 🔴 Critical Rules (Never Skip These)\n\n1. **Article 3 (No Guessing)**: If you don't know, mark it `<UNKNOWN>` and escalate to HITL\n2. **Article 6 (Safety Before Speed)**: For risky changes → STOP → ASK → VERIFY → PROCEED\n3. **Article 8 (HITL for External Systems)**: Credentials, billing, production = always HITL\n4. **P8 (Read Repo First)**: Always check `.repo/` docs and manifest before deciding\n5. **P10 (Risk Triggers a Stop)**: Non-trivial risk = HITL\n\n## 🎓 Understanding the Layers\n\nThe framework uses a 3-layer update model:\n\n- **Layer 1 (CUSTOM)**: Repository-specific content (HITL, manifest)\n- **Layer 2 (UPDATEABLE)**: Framework-provided but customizable (policies)\n- **Layer 3 (IMMUTABLE)**: Core framework structure\n\nEach file has a marker indicating its layer.\n\n## 📞 Getting Help\n\n### Common Questions\n- **\"Can I change the CONSTITUTION?\"** → Only with explicit founder approval (Article 1)\n- **\"What if I'm not sure about a command?\"** → Set `<UNKNOWN>` in manifest, create HITL\n- **\"Do I need HITL for this?\"** → Check triggers in [`policy/SECURITY_BASELINE.md`](policy/SECURITY_BASELINE.md)\n- **\"How do I request a waiver?\"** → Follow process in HITL or create HITL item\n\n### Support\n- Review policy documents in `policy/` directory\n- Check `docs/standards/manifest.md` for manifest help\n- Create HITL item when uncertain\n- Consult repository owner/founder for ambiguity\n\n## 🚀 Quick Start Checklist\n\nFor new repositories adopting this framework:\n\n1. [ ] Copy `.repo/` folder to your repository root\n2. [ ] Open `repo.manifest.yaml`\n3. [ ] Fill in commands using `docs/standards/manifest.md` guide\n4. [ ] Replace all `<FILL_FROM_REPO>` placeholders\n5. [ ] Set `<UNKNOWN>` for unclear items (with HITL)\n6. [ ] Review and customize `policy/HITL.md` structure\n7. [ ] Test commands locally to verify they work\n8. [ ] Commit the governance framework\n9. [ ] Start using it for all changes\n\n## 📋 Maintenance\n\n- **Review HITL items**: Weekly (or as they come in)\n- **Review Waivers**: Monthly (check for expirations)\n- **Update Manifest**: When build/test commands change\n- **Update Policies**: Only when necessary (follow Layer rules)\n\n---\n\n## 📝 About This Framework\n\nThis governance framework follows the AI-Native Repository Governance System design, enabling:\n- Automated governance enforcement\n- Human-in-the-loop decision making for high-risk items\n- Clear boundaries and policies\n- Incremental delivery and verification\n- Safety before speed\n\n**Remember**: The goal is to enable safe, effective collaboration between AI and humans, not to create bureaucracy. Use judgment, escalate when needed, and always prioritize safety and quality.\n\n---\n\n**Questions?** Start with the CONSTITUTION.md and work your way through the policy documents. When in doubt, create a HITL item.\n"
        },
        {
          "path": ".repo/INDEX.md",
          "type": "Markdown",
          "purpose": "Navigation reference",
          "used_by": [
            "Navigation"
          ],
          "content": "# Governance Directory Index\n\n**File**: `.repo/INDEX.md`\n\nThis file catalogs the contents of the `.repo/` governance directory. See [root `INDEX.md`](../INDEX.md) for repository overview.\n\n## Directory Structure\n\n### Core Files\n- `GOVERNANCE.md` - Framework entry point and overview\n- `repo.manifest.yaml` - Command definitions (source of truth for executable commands)\n- `AGENT.md` - Folder-level agent guide\n- `DOCUMENT_MAP.md` - Token-optimized document reference system\n- `CHANGELOG.md` - Framework change history\n- `INDEX.md` - This file\n\n### Current Analysis & Progress\n- `CRITICAL_ANALYSIS_FAILURES.md` - Current critical analysis of system gaps\n- `PROJECTED_ANALYSIS_AFTER_FIXES.md` - Projected analysis after fixes\n- `IMPLEMENTATION_PROGRESS.md` - Current implementation progress tracking\n\n### Entry Points (Root Level)\n- `AGENTS.json` - **Primary entry point** (structured JSON for model parsing)\n- `AGENTS.md` - Entry point (human-readable fallback)\n\n### `policy/` - Authoritative Governance Rules\n- `CONSTITUTION.md` - 8 fundamental articles (immutable)\n- `PRINCIPLES.md` - Operating principles (P3-P25, updateable)\n- `QUALITY_GATES.md` - Quality standards and merge gates\n- `SECURITY_BASELINE.md` - Security requirements and HITL triggers\n- `BOUNDARIES.md` - Architectural boundaries and import rules\n- `HITL.md` - Human-in-the-loop tracking (index of active/archived items)\n- `BESTPR.md` - Repository-specific best practices\n\n### `agents/` - AI Agent Framework\n- `rules.json` - **Primary rules source** (machine-readable, all rules)\n- `QUICK_REFERENCE.md` - Human-readable rules cheat sheet\n- `AGENTS.md` - Framework documentation (UNKNOWN workflow, 3-pass generation)\n- `rules-compact.md` - Compact format (~200 tokens)\n- `capabilities.md` - List of all agent capabilities\n- `FORMATS.md` - Available format documentation\n- `checklists/` - Agent checklists\n  - `change-plan.md` - Change planning checklist\n  - `pr-review.md` - PR review checklist\n  - `incident.md` - Incident response checklist\n- `prompts/` - Prompt templates\n  - `pr_template.md` - PR prompt template\n  - `task_packet.md` - Task packet template\n- `roles/` - Agent role definitions\n  - `primary.md` - Primary agent role\n  - `secondary.md` - Secondary agent role\n  - `reviewer.md` - Reviewer role (human)\n  - `release.md` - Release role (human)\n\n### `templates/` - Document Templates\n- `AGENT_LOG_TEMPLATE.md` - Agent log structure template\n- `AGENT_TRACE_SCHEMA.json` - Agent trace log JSON schema\n- `PR_TEMPLATE.md` - Pull request template\n- `ADR_TEMPLATE.md` - Architecture decision record template\n- `WAIVER_TEMPLATE.md` - Policy waiver template\n- `RFC_TEMPLATE.md` - Request for comments template\n- `RUNBOOK_TEMPLATE.md` - Runbook template\n- `examples/` - Example files\n  - `example_trace_log.json` - Example trace log\n  - `example_hitl_item.md` - Example HITL item\n  - `example_waiver.md` - Example waiver\n  - `example_task_packet.json` - Example task packet\n  - `README.md` - Examples documentation\n\n### `tasks/` - Task Management\n- `TODO.md` - Current active task (ONE only)\n- `BACKLOG.md` - Prioritized task queue (P0→P3)\n- `ARCHIVE.md` - Completed tasks\n- `REMAINING_TASKS.md` - Remaining implementation tasks from critical analysis\n- `README.md` - Task management workflow\n\n**Note:** Documentation has been moved to root `docs/` directory. See [`docs/README.md`](../docs/README.md) for documentation structure.\n\n### `automation/` - Automation Infrastructure\n- `ci/` - CI automation\n  - `governance-verify.yml` - Governance verification workflow\n- `scripts/` - Automation scripts\n  - `governance-verify.js` - Governance verification script\n  - `validate-agent-trace.js` - Trace log validation script\n\n### `hitl/` - HITL Item Files\n- `README.md` - HITL items directory documentation\n- Individual HITL item files: `HITL-XXXX.md`\n\n### `logs/` - Agent Logs\n- Agent logs stored here (see `templates/AGENT_LOG_TEMPLATE.md`)\n\n### `traces/` - Trace Logs\n- Trace logs stored here (see `templates/AGENT_TRACE_SCHEMA.json`)\n\n### `waivers/` - Policy Waivers\n- Active policy waivers stored here\n\n### `archive/` - Historical Documents\n- `assessments/` - Archived assessment and analysis documents (historical reference only)\n  - See `archive/assessments/README.md` for details\n\n## Navigation\n\n- [Root `INDEX.md`](../INDEX.md) - Repository master index\n- [`backend/INDEX.md`](../backend/INDEX.md) - Backend directory index\n- [`frontend/INDEX.md`](../frontend/INDEX.md) - Frontend directory index\n\n## Entry Point Usage\n\n**For AI Agents:**\n1. Read `AGENTS.json` (root) - Primary structured entry point\n2. Or read `AGENTS.md` (root) - Human-readable entry point\n3. Follow instructions to read required files\n\n**For Humans:**\n- Start with `GOVERNANCE.md` for framework overview\n- Use `DOCUMENT_MAP.md` to navigate documents\n- See `CHANGELOG.md` for recent changes\n\n## See Also\n\n- `.repo/GOVERNANCE.md` - Framework entry point\n- `.repo/AGENT.md` - What agents may do in this directory\n- `.repo/repo.manifest.yaml` - Command definitions\n- `AGENTS.json` - Primary agent entry point (root)\n- `AGENTS.md` - Agent entry point (root, human-readable)\n"
        },
        {
          "path": ".repo/CHANGELOG.md",
          "type": "Markdown",
          "purpose": "Changelog",
          "used_by": [
            "Historical reference"
          ],
          "content": "# Framework Changelog\n\n**File**: `.repo/CHANGELOG.md`\n\nThis file tracks improvements and changes to the governance framework.\n\n## 2026-01-23 - World-Class Documentation Structure\n\n### Added\n\n- **Comprehensive documentation structure** in root `docs/` directory:\n  - `getting-started/` - Quick start guides and onboarding\n  - `guides/` - User, admin, and API guides\n  - `architecture/` - System architecture, modules, ADRs, data models\n  - `development/` - Development workflow, contributing, testing, standards\n  - `operations/` - Operations, monitoring, troubleshooting, runbooks, disaster recovery\n  - `reference/` - API reference, module reference, configuration, CLI\n  - `security/` - Security, compliance, data privacy\n  - `integrations/` - Integration documentation, webhooks, API integrations\n  - `archive/` - Historical documentation (analysis and redundant docs)\n\n### Reorganized\n\n- **Moved `.repo/docs/` to root `docs/`** - Documentation now in standard location\n- **Organized existing docs** - Moved to appropriate sections:\n  - `ONBOARDING.md` → `getting-started/onboarding.md`\n  - `ARCHITECTURE.md` → `architecture/README.md`\n  - `DEVELOPMENT.md` → `development/README.md`\n  - `RUNBOOK.md` → `operations/README.md`\n  - `DOCS.md` → `guides/README.md`\n- **Created structure** - Anticipated future needs based on application (multi-tenant, many modules, integrations, etc.)\n\n### Updated\n\n- **All documentation references** - Updated throughout codebase\n- **INDEX.md** - Updated to reference new docs structure\n- **README.md** - Updated documentation links\n- **`.repo/INDEX.md`** - Removed docs section (now in root)\n- **`.repo/DOCUMENT_MAP.md`** - Updated architecture reference\n\n---\n\n## 2026-01-23 - Directory Reorganization & Entry Point Optimization\n\n### Reorganized\n\n- **Moved `agents/tasks/` to `.repo/tasks/`** - Task management now centralized in `.repo/`\n- **Updated all references** - All file paths updated throughout codebase:\n  - Entry points (`AGENTS.json`, `AGENTS.md`)\n  - Agent framework files (`.repo/agents/rules.json`, `QUICK_REFERENCE.md`)\n  - Scripts (`archive-task.py`, `promote-task.sh`, `generate-metrics.sh`, etc.)\n  - Documentation (`INDEX.md`, `DOCUMENT_MAP.md`, `README.md`)\n\n### Archived\n\n- **Moved 14 documents to `docs/archive/`** for historical reference:\n  - 12 analysis/assessment documents from design phase (all issues resolved)\n  - 2 redundant documentation files (superseded by new entry point system)\n  - See `docs/archive/README.md` for details\n\n### Added\n\n- **`AGENTS.json`** - Structured JSON entry point for better model parsing\n- **Optimized `AGENTS.md`** - Streamlined to imperative, action-oriented style\n- **`docs/archive/`** - Archive directory for historical documentation\n\n### Updated\n\n- **`AGENTS.md`** - Optimized text style for model interaction (imperative, direct commands)\n- **`PROMPT.md`** - Updated to reference JSON as primary format\n- **`DOCUMENT_MAP.md`** - Removed references to archived assessment documents\n- **`.repo/tasks/TODO.md`** - Updated to reference `AGENTS.json` first\n- **`.repo/agents/QUICK_REFERENCE.md`** - Updated to reference JSON entry point\n\n### Improved\n\n- **Entry Point System** - Now uses JSON for structured parsing, markdown for human readability\n- **Text Style** - All entry point documents optimized for model interaction\n- **Documentation Structure** - Cleaner, more focused operational docs\n\n---\n\n## 2026-01-23 - Framework Enhancements (Part 2)\n\n### Added\n\n- **CI Integration**\n  - Governance verification job added to `.github/workflows/ci.yml` (Job 7)\n  - HITL sync runs automatically on PRs via GitHub API\n  - Fixed duplicate CI workflow definitions\n\n- **Makefile Integration**\n  - Added `check-governance` target: `make check-governance`\n  - Runs governance verification locally\n\n- **Pre-commit Hooks**\n  - Added governance verification hook (runs on `.repo/`, `agents/`, `scripts/` changes)\n  - Non-blocking (uses `|| true` to avoid blocking commits)\n\n- **GitHub API Integration**\n  - `sync-hitl-to-pr.py` now updates PRs directly via GitHub API\n  - Automatic token detection from environment\n  - Fallback to manual method if API unavailable\n\n- **Dependencies**\n  - `scripts/requirements.txt` - Python dependencies for automation scripts\n\n### Updated\n\n- `.github/workflows/ci.yml` - Added governance job, fixed duplicates\n- `Makefile` - Added `check-governance` target\n- `.pre-commit-config.yaml` - Added governance verification hook\n- `scripts/sync-hitl-to-pr.py` - Added GitHub API integration\n- Documentation updated to reflect new integrations\n\n---\n\n## 2026-01-23 - Framework Enhancements (Part 1)\n\n### Added\n\n- **Example Files** (`.repo/templates/examples/`)\n  - `example_trace_log.json` - Example trace log format\n  - `example_hitl_item.md` - Example HITL item\n  - `example_waiver.md` - Example waiver\n  - `example_task_packet.json` - Example task packet\n  - `README.md` - Examples documentation\n\n- **Quick Reference** (`.repo/agents/QUICK_REFERENCE.md`)\n  - One-page cheat sheet for agents\n  - Decision tree for HITL requirements\n  - Common commands and workflows\n  - Artifact requirements table\n\n- **Documentation**\n  - `docs/development/boundary_checker.md` - Boundary checker documentation\n  - `docs/development/ci_integration.md` - CI integration guide\n  - `docs/development/automation_scripts.md` - Automation scripts documentation\n\n- **Automation Scripts**\n  - `scripts/sync-hitl-to-pr.py` - Sync HITL status to PRs\n  - `scripts/archive-task.py` - Archive completed tasks\n\n### Enhanced\n\n- **Governance Verify Script** (`scripts/governance-verify.sh`)\n  - Added trace log validation (JSON schema check)\n  - Enhanced HITL item parsing (detailed status checking)\n  - Added artifact checking (ADR detection)\n  - Added boundary checker verification\n  - Better error reporting and categorization\n\n### Updated\n\n- `.repo/agents/AGENTS.md` - Added references to quick reference and examples\n- `.repo/GOVERNANCE.md` - Updated directory structure to reflect new files\n\n### Notes\n\n- Boundary checker confirmed working (import-linter, configured in `.importlinter`)\n- CI integration documented (see `docs/development/ci_integration.md`)\n- Automation scripts are functional but may need GitHub API integration for full automation\n"
        },
        {
          "path": ".repo/CLEANUP_SUMMARY.md",
          "type": "Markdown",
          "purpose": "Cleanup summary",
          "used_by": [
            "Maintenance"
          ],
          "content": "# Documentation Cleanup Summary\n\n**Date:** 2026-01-23\n**Purpose:** Clean up unnecessary assessment/analysis documents in `.repo/` directory\n\n---\n\n## Files Archived\n\nThe following historical assessment and analysis documents have been moved to `.repo/archive/assessments/`:\n\n1. **AGENT_OPTIMIZATION_COMPLETE.md** - Historical optimization completion doc\n2. **AGENT_OPTIMIZATION_IMPLEMENTATION.md** - Historical implementation doc\n3. **AGENT_OPTIMIZATION_PROPOSAL.md** - Historical proposal doc\n4. **AGENT_OPTIMIZATION_SUMMARY.md** - Historical summary doc\n5. **AGENTIC_SYSTEM_ASSESSMENT_2026.md** - Early system assessment\n6. **ASSESSMENT_AGENTIC_SYSTEM.md** - System assessment\n7. **IMPLEMENTATION_SUMMARY.md** - Historical implementation summary\n8. **REPOSITORY_BEST_PRACTICES_ANALYSIS.md** - Best practices analysis\n9. **TOKEN_OPTIMIZATION_ANALYSIS.md** - Token optimization analysis\n10. **TOKEN_OPTIMIZATION_STRATEGY.md** - Token optimization strategy\n\n**Total:** 10 files archived\n\n---\n\n## Files Kept (Active)\n\n### Current Analysis & Progress\n- `CRITICAL_ANALYSIS_FAILURES.md` - Current critical analysis\n- `PROJECTED_ANALYSIS_AFTER_FIXES.md` - Projected analysis\n- `IMPLEMENTATION_PROGRESS.md` - Current progress tracking\n\n### Core Documentation\n- `GOVERNANCE.md` - Framework entry point\n- `AGENT.md` - Folder-level agent guide\n- `DOCUMENT_MAP.md` - Document navigation\n- `INDEX.md` - Directory index\n- `CHANGELOG.md` - Change history\n\n### Policy & Framework\n- All files in `policy/` - Active policy documents\n- All files in `agents/` - Active agent framework\n- All files in `templates/` - Active templates\n- All files in `tasks/` - Active task management\n- All files in `automation/` - Active automation scripts\n\n---\n\n## Archive Location\n\n**Location:** `.repo/archive/assessments/`\n\n**Purpose:** Historical reference only. These documents are not part of operational documentation and should not be read by agents.\n\n**See:** `.repo/archive/assessments/README.md` for details\n\n---\n\n## Updated References\n\n- `INDEX.md` - Updated to reflect archive location\n- `DOCUMENT_MAP.md` - Already mentions archived documents (no change needed)\n\n---\n\n## Result\n\n**Before:** 10+ assessment/analysis documents cluttering `.repo/` root\n**After:** Clean `.repo/` root with only active documentation\n\n**Benefits:**\n- Easier navigation\n- Clearer what's active vs historical\n- Reduced confusion for agents\n- Better organization\n\n---\n\n**Note:** Archived documents are kept for historical reference but are not part of the operational framework.\n"
        },
        {
          "path": ".repo/CRITICAL_ANALYSIS_FAILURES.md",
          "type": "Markdown",
          "lines": 730,
          "purpose": "Critical analysis of failures",
          "used_by": [
            "Historical reference",
            "assessment documents"
          ],
          "content": "# Critical Analysis: Agentic System Failures & Gaps\n\n**Date:** 2026-01-23\n**Purpose:** Harsh, critical reanalysis identifying real failures, gaps, and incomplete implementations\n**Tone:** Brutally honest - focusing on what will actually fail\n\n---\n\n## Executive Summary\n\n**Grade: C+ (Good Foundation, Critical Integration Gaps)**\n\nThe system has excellent governance documentation but **critical integration failures** that will prevent it from working as designed. Many features are \"documented but not wired\" - they exist on paper but agents won't use them.\n\n---\n\n## 🔴 CRITICAL FAILURES (Will Break in Production)\n\n### 0. **Change Type Determination Is Impossible - Agents Can't Classify PRs**\n\n**Severity:** CRITICAL\n**Impact:** Agents can't determine what artifacts are required\n\n**Evidence:**\n- ✅ Artifacts defined by change type in `rules.json`: feature, api_change, security, cross_module, non_doc_change\n- ✅ `QUALITY_GATES.md` says \"Required artifacts are missing for the declared change type\"\n- ❌ **NO WORKFLOW TO DETERMINE CHANGE TYPE**\n- ❌ `AGENTS.json` doesn't explain how to classify\n- ❌ `QUICK_REFERENCE.md` doesn't explain how to classify\n- ❌ `governance-verify` can't check artifacts because it doesn't know change type\n- ❌ PR template has `change_type` field but no guidance on how to fill it\n\n**The Problem:**\nAgents need to know if a PR is \"feature\", \"api_change\", \"security\", \"cross_module\", or \"non_doc_change\" to know what artifacts to create. But there's no decision tree or guidance on how to determine this.\n\n**What Will Happen:**\n- Agents will guess change type (wrong)\n- Wrong artifacts will be created (or missing)\n- `governance-verify` will pass invalid PRs\n- Quality gates will fail silently\n- System will be inconsistent\n\n**Fix Required:**\n- Add change type decision tree to `QUICK_REFERENCE.md`\n- Add to workflow: \"Pass 1: Determine change type\"\n- Add examples of each change type\n- Update `governance-verify` to parse change type from PR description\n- Add validation that change type matches actual changes\n\n---\n\n### 1. **Context Files Are Orphaned - Agents Don't Know They Exist**\n\n**Severity:** CRITICAL\n**Impact:** Agents will never read `.agent-context.json` files\n\n**Evidence:**\n- ✅ Context files created: 11 files\n- ❌ `AGENTS.json` doesn't mention them\n- ❌ `QUICK_REFERENCE.md` doesn't mention them\n- ❌ `AGENT.md` doesn't mention them\n- ❌ No workflow step says \"read .agent-context.json\"\n\n**The Problem:**\nAgents follow `AGENTS.json` → `QUICK_REFERENCE.md` → workflow. Nowhere in that chain do we tell them to read context files. They're invisible.\n\n**What Will Happen:**\n- Agents will ignore context files completely\n- They'll read full `.repo/` docs repeatedly (wasting tokens)\n- Context files will become stale and useless\n- All optimization work is wasted\n\n**Fix Required:**\n- Add to `AGENTS.json` context_determination: \"read .agent-context.json when entering folder\"\n- Add to `QUICK_REFERENCE.md`: \"When entering folder, read .agent-context.json first\"\n- Add to workflow: \"Pass 0: Read folder context files\"\n\n---\n\n### 2. **Logging Infrastructure Exists But Nothing Logs**\n\n**Severity:** CRITICAL\n**Impact:** No way to measure agent effectiveness or identify problems\n\n**Evidence:**\n- ✅ `.agent-logs/` directory created\n- ✅ README documents log format\n- ❌ **NO CODE ACTUALLY LOGS ANYTHING**\n- ❌ No logging hooks in agent workflow\n- ❌ No logging library or SDK\n- ❌ No integration with agent execution\n\n**The Problem:**\nWe created empty directories and documentation. There's no actual logging code. Agents can't log because there's no mechanism to do so.\n\n**What Will Happen:**\n- `.agent-logs/` will remain empty forever\n- No metrics will be collected\n- Can't identify where agents struggle\n- Can't measure optimization effectiveness\n- Can't debug agent failures\n\n**Fix Required:**\n- Create logging SDK/library that agents can call\n- Add logging hooks to agent workflow\n- Integrate with agent execution environment\n- Create log collector/aggregator\n- Add logging to governance-verify\n\n---\n\n### 3. **Validation Scripts Don't Actually Validate**\n\n**Severity:** HIGH\n**Impact:** Invalid context files will slip through\n\n**Evidence:**\n- ✅ `validate-agent-context.js` exists\n- ❌ Only does basic field checks (version, type, folder.path)\n- ❌ **Doesn't validate against JSON schema**\n- ❌ Doesn't check if patterns match actual code\n- ❌ Doesn't validate boundaries are correct\n- ❌ Doesn't check if links are valid\n\n**The Problem:**\nThe validator is a stub. It checks 3 fields and calls it done. It doesn't use the schema we created.\n\n**What Will Happen:**\n- Invalid context files will be accepted\n- Schema violations will go undetected\n- Broken links won't be caught\n- Wrong patterns won't be caught\n- System will degrade over time\n\n**Fix Required:**\n- Use actual JSON schema validation (ajv or similar)\n- Validate all required fields\n- Check file paths exist\n- Validate patterns against actual code\n- Check boundaries are correct\n\n---\n\n### 4. **Pattern Files May Be Wrong - Not Verified**\n\n**Severity:** HIGH\n**Impact:** Agents will follow incorrect patterns\n\n**Evidence:**\n- ✅ Pattern files created: 3 files\n- ❌ Patterns extracted from documentation, not actual code\n- ❌ No verification that patterns match codebase\n- ❌ No automated sync between code and patterns\n- ❌ Patterns may be outdated\n\n**The Problem:**\nWe wrote patterns based on what we *think* the code looks like. We didn't verify they match actual code.\n\n**What Will Happen:**\n- Agents will follow wrong patterns\n- Code will be inconsistent\n- Patterns will drift from reality\n- System will become unreliable\n\n**Fix Required:**\n- Extract patterns from actual code\n- Verify patterns match codebase\n- Create automated pattern extraction\n- Add pattern validation to CI\n- Keep patterns in sync with code\n\n---\n\n### 5. **HITL Workflow Is Unclear - Agents Don't Know How**\n\n**Severity:** HIGH\n**Impact:** Agents won't create HITL items correctly\n\n**Evidence:**\n- ✅ `create-hitl-item.sh` exists\n- ✅ HITL.md documents format\n- ❌ **Agents don't know WHEN to call the script**\n- ❌ No integration with agent workflow\n- ❌ No clear \"create HITL\" step in three-pass workflow\n- ❌ Decision tree says \"create HITL\" but doesn't say HOW\n\n**The Problem:**\nThe decision tree says \"create HITL\" but doesn't tell agents:\n- Which script to run\n- What parameters to use\n- How to format the item\n- How to add it to index\n- How to link it to PR\n\n**What Will Happen:**\n- Agents will skip HITL creation\n- Or create HITL items incorrectly\n- Or create them in wrong location\n- System will fail silently\n\n**Fix Required:**\n- Add explicit HITL creation steps to workflow\n- Document exact command to run\n- Add HITL creation to QUICK_REFERENCE\n- Create agent-friendly HITL creation function\n- Add validation that HITL was created\n\n---\n\n### 6. **Boundary Enforcement Is Vague - No Clear Mechanism**\n\n**Severity:** HIGH\n**Impact:** Agents will violate boundaries unknowingly\n\n**Evidence:**\n- ✅ `BOUNDARIES.md` documents rules\n- ✅ Context files list boundaries\n- ❌ **No clear enforcement mechanism**\n- ❌ `governance-verify` only checks if tool exists\n- ❌ No automated boundary checking in workflow\n- ❌ Agents don't know how to check boundaries\n\n**The Problem:**\nBoundaries are documented but not enforced. Agents have to manually check if they're violating boundaries, which they won't do.\n\n**What Will Happen:**\n- Agents will violate boundaries\n- Violations won't be caught until PR\n- System will degrade over time\n- Architecture will become messy\n\n**Fix Required:**\n- Add boundary checking to agent workflow\n- Integrate with import-linter or similar\n- Add boundary checks to governance-verify\n- Fail fast on boundary violations\n- Add boundary checking to CI\n\n---\n\n### 7. **Context Files Will Go Stale - No Update Mechanism**\n\n**Severity:** MEDIUM\n**Impact:** Context files will become inaccurate over time\n\n**Evidence:**\n- ✅ Context files created\n- ❌ **No process to keep them updated**\n- ❌ No validation that they're current\n- ❌ No automated sync with code\n- ❌ No alerts when they're outdated\n\n**The Problem:**\nContext files are snapshots. Code changes, but context files don't. They'll become wrong over time.\n\n**What Will Happen:**\n- Context files will have wrong patterns\n- Wrong boundaries\n- Wrong dependencies\n- Agents will follow outdated guidance\n- System will become unreliable\n\n**Fix Required:**\n- Add context file validation to CI\n- Create automated context file updates\n- Add \"last verified\" dates\n- Alert when context files are stale\n- Create update workflow\n\n---\n\n### 8. **No Monitoring or Alerting - Failures Go Unnoticed**\n\n**Severity:** MEDIUM\n**Impact:** Problems won't be detected until too late\n\n**Evidence:**\n- ✅ Logging infrastructure exists (but empty)\n- ❌ **No monitoring system**\n- ❌ No alerts for failures\n- ❌ No dashboards\n- ❌ No metrics collection\n- ❌ No health checks\n\n**The Problem:**\nEven if logging worked, there's no way to monitor it or get alerted to problems.\n\n**What Will Happen:**\n- Failures will go unnoticed\n- Problems will accumulate\n- System will degrade silently\n- No way to measure effectiveness\n\n**Fix Required:**\n- Create monitoring system\n- Add health checks\n- Create dashboards\n- Add alerting\n- Collect metrics\n\n---\n\n### 9. **Missing Critical Integrations**\n\n**Severity:** MEDIUM\n**Impact:** System doesn't work end-to-end\n\n**Evidence:**\n- ✅ Individual components exist\n- ❌ **Not integrated with each other**\n- ❌ Context files not in workflow\n- ❌ Logging not in workflow\n- ❌ Validation not in CI\n- ❌ Patterns not verified\n\n**The Problem:**\nWe built pieces but didn't wire them together. It's like building a car with all the parts but no connections.\n\n**What Will Happen:**\n- Components work in isolation\n- But system doesn't work as whole\n- Agents won't use optimizations\n- Benefits won't be realized\n\n**Fix Required:**\n- Integrate all components\n- Wire into agent workflow\n- Add to CI pipeline\n- Create end-to-end tests\n- Verify system works\n\n---\n\n### 10. **Agent Logs vs Trace Logs - Confusion Will Happen**\n\n**Severity:** MEDIUM\n**Impact:** Agents will create wrong logs or skip logging\n\n**Evidence:**\n- ✅ Both log types documented\n- ✅ Distinction explained\n- ❌ **Workflow doesn't clearly separate them**\n- ❌ Easy to confuse which to create when\n- ❌ No validation that right log type was created\n\n**The Problem:**\nThe distinction is documented but not enforced. Agents will get confused about which log to create.\n\n**What Will Happen:**\n- Agents will create wrong log type\n- Or skip logging entirely\n- Or create both when only one needed\n- System will be inconsistent\n\n**Fix Required:**\n- Make workflow explicit about log types\n- Add validation for log types\n- Create clear decision tree\n- Add examples\n- Simplify if possible\n\n---\n\n### 11. **Task Packet Creation Is Unclear - When and How?**\n\n**Severity:** HIGH\n**Impact:** Task packets won't be created consistently\n\n**Evidence:**\n- ✅ Task packet template exists: `.repo/agents/prompts/task_packet.md`\n- ✅ Example exists: `example_task_packet.json`\n- ✅ Required for: feature, api_change, cross_module\n- ❌ **NOT IN WORKFLOW**\n- ❌ No guidance on when to create (Pass 1? Before PR?)\n- ❌ No guidance on where to store\n- ❌ No validation that task packet exists\n\n**The Problem:**\nTask packets are required for most change types, but agents don't know when or how to create them.\n\n**What Will Happen:**\n- Task packets will be skipped\n- Or created incorrectly\n- Or created in wrong location\n- Quality gates will fail\n\n**Fix Required:**\n- Add to workflow: \"Pass 1: Create task packet\"\n- Document where to store (TODO.md? Separate file?)\n- Add validation to `governance-verify`\n- Add examples\n\n---\n\n### 12. **ADR Directory Doesn't Exist - Scripts Will Fail**\n\n**Severity:** HIGH\n**Impact:** ADR creation scripts will fail\n\n**Evidence:**\n- ✅ ADR template exists\n- ✅ `create-adr-from-trigger.sh` exists\n- ✅ Workflow says \"Store in `docs/adr/ADR-XXX.md`\"\n- ❌ **`docs/adr/` directory doesn't exist**\n- ❌ Scripts will fail when trying to create ADRs\n\n**The Problem:**\nThe ADR directory is referenced but doesn't exist. Scripts will fail.\n\n**What Will Happen:**\n- ADR creation will fail\n- Agents will skip ADRs\n- System will break\n\n**Fix Required:**\n- Create `docs/adr/` directory\n- Add README explaining ADR format\n- Test ADR creation scripts\n\n---\n\n### 13. **Testing Guidance Is Minimal - Agents Don't Know What Tests to Write**\n\n**Severity:** MEDIUM\n**Impact:** Tests will be inconsistent or missing\n\n**Evidence:**\n- ✅ Testing tools documented: pytest, vitest\n- ✅ Test patterns mentioned in templates\n- ❌ **No clear guidance on what tests to write**\n- ❌ No examples of test patterns\n- ❌ No guidance on test coverage requirements\n- ❌ No integration with quality gates\n\n**The Problem:**\nAgents know they need tests but don't know what tests to write or how to write them.\n\n**What Will Happen:**\n- Tests will be inconsistent\n- Important tests will be missing\n- Test quality will be poor\n- Coverage will be low\n\n**Fix Required:**\n- Add test patterns to folder-level `.AGENT.md` files\n- Add test examples\n- Document test coverage requirements\n- Add test validation to quality gates\n\n---\n\n### 14. **Governance-Verify Artifact Checking Is a Stub**\n\n**Severity:** HIGH\n**Impact:** Invalid PRs will pass quality gates\n\n**Evidence:**\n- ✅ `governance-verify.sh` has \"Check 8: Required artifacts\"\n- ✅ Comment says \"This is a simplified check\"\n- ❌ **Only checks if ADR exists, not other artifacts**\n- ❌ Doesn't check task packet\n- ❌ Doesn't check trace log\n- ❌ Doesn't check agent log\n- ❌ Doesn't know change type\n\n**The Problem:**\nThe artifact checking is a stub. It doesn't actually verify required artifacts exist.\n\n**What Will Happen:**\n- Missing artifacts won't be caught\n- Quality gates will pass invalid PRs\n- System will be inconsistent\n\n**Fix Required:**\n- Parse change type from PR description\n- Check all required artifacts for that change type\n- Fail hard gates if artifacts missing\n- Add to CI\n\n---\n\n### 15. **PR Creation Workflow Doesn't Specify Change Type**\n\n**Severity:** MEDIUM\n**Impact:** PRs will have wrong or missing change types\n\n**Evidence:**\n- ✅ PR template has `change_type` field\n- ✅ `AGENTS.json` lists required PR sections\n- ❌ **No guidance on how to determine change type**\n- ❌ No validation that change type is correct\n- ❌ No examples\n\n**The Problem:**\nPRs need a change type, but agents don't know how to determine it.\n\n**What Will Happen:**\n- PRs will have wrong change types\n- Or missing change types\n- Quality gates will fail\n- System will be inconsistent\n\n**Fix Required:**\n- Add change type decision tree to PR creation workflow\n- Add validation\n- Add examples\n\n---\n\n## ⚠️ DESIGN FLAWS (Will Cause Problems)\n\n### 1. **Too Many Entry Points - Agents Will Get Confused**\n\n**Problem:**\n- `AGENTS.json` (machine-readable)\n- `AGENT.md` (human-readable)\n- `QUICK_REFERENCE.md` (quick reference)\n- `AGENTS.md` (framework docs)\n- All say slightly different things\n\n**Impact:** Agents will read wrong file or get conflicting information.\n\n**Fix:** Consolidate to ONE canonical entry point, others reference it.\n\n---\n\n### 2. **Context Files Duplicate Information**\n\n**Problem:**\n- Context files have same info as `.AGENT.md`\n- Same info as `PATTERNS.md`\n- Same info as `BACKEND.md` / `FRONTEND.md`\n- Information will drift\n\n**Impact:** Maintenance burden, conflicting information.\n\n**Fix:** Context files should reference, not duplicate. Or use single source of truth.\n\n---\n\n### 3. **No Failure Recovery Mechanism**\n\n**Problem:**\n- What if HITL creation fails?\n- What if logging fails?\n- What if validation fails?\n- System doesn't handle failures gracefully\n\n**Impact:** System will break and stay broken.\n\n**Fix:** Add error handling, fallbacks, recovery mechanisms.\n\n---\n\n### 4. **No Testing of Agent Workflows**\n\n**Problem:**\n- No tests that verify agent workflow works\n- No tests that verify context files are used\n- No tests that verify logging works\n- No end-to-end tests\n\n**Impact:** System may not work at all, and we won't know.\n\n**Fix:** Create test suite for agent workflows, integration tests.\n\n---\n\n## 📊 What's Actually Complete vs What's Just Documented\n\n| Feature | Status | Reality Check |\n|---------|--------|---------------|\n| Context Files | ✅ Created | ❌ Not integrated, agents won't use |\n| Quick References | ✅ Created | ⚠️ Not in workflow |\n| Pattern Files | ✅ Created | ❌ Not verified against code |\n| Logging Infrastructure | ✅ Created | ❌ No actual logging code |\n| Validation Scripts | ✅ Created | ❌ Stub validation only |\n| HITL Creation | ✅ Script exists | ❌ Not in workflow |\n| Boundary Enforcement | ✅ Documented | ❌ Not enforced |\n| Governance Verify | ✅ Implemented | ✅ Actually works |\n| Task Management | ✅ Implemented | ✅ Actually works |\n| Three-Pass Workflow | ✅ Documented | ⚠️ Not enforced |\n\n---\n\n## 🎯 What Will Actually Fail\n\n1. **Agents won't use context files** - Not in workflow\n2. **No logging will happen** - No code to log\n3. **Context files will go stale** - No update mechanism\n4. **Patterns will be wrong** - Not verified\n5. **HITL creation will be skipped** - Unclear workflow\n6. **Boundaries will be violated** - Not enforced\n7. **Validation will pass invalid files** - Stub validation\n8. **System won't be monitored** - No monitoring\n9. **Failures won't be detected** - No alerting\n10. **System won't work end-to-end** - Not integrated\n\n---\n\n## 💡 What Needs to Happen (Priority Order)\n\n### Priority 1: Integration (Do First)\n\n1. **Wire context files into workflow**\n   - Add to `AGENTS.json` context_determination\n   - Add to `QUICK_REFERENCE.md`\n   - Add to three-pass workflow\n\n2. **Create actual logging code**\n   - Logging SDK/library\n   - Integration hooks\n   - Log collector\n\n3. **Fix validation**\n   - Use JSON schema validation\n   - Validate all fields\n   - Check file paths\n\n### Priority 2: Enforcement (Do Next)\n\n4. **Add HITL creation to workflow**\n   - Explicit steps\n   - Clear commands\n   - Validation\n\n5. **Enforce boundaries**\n   - Automated checking\n   - Fail fast\n   - CI integration\n\n6. **Verify patterns**\n   - Extract from code\n   - Validate against codebase\n   - Keep in sync\n\n### Priority 3: Maintenance (Do After)\n\n7. **Keep context files updated**\n   - Automated updates\n   - Validation\n   - Alerts\n\n8. **Add monitoring**\n   - Metrics collection\n   - Dashboards\n   - Alerting\n\n9. **Test workflows**\n   - End-to-end tests\n   - Integration tests\n   - Failure scenarios\n\n---\n\n## 🔴 Bottom Line\n\n**The system is 60% complete, not 90%.**\n\n- ✅ Governance framework: Excellent (95%)\n- ✅ Documentation: Excellent (90%)\n- ⚠️ Integration: Poor (30%)\n- ❌ Enforcement: Missing (20%)\n- ❌ Monitoring: Missing (0%)\n\n**Most optimizations are \"documented but not wired.\"** They exist on paper but agents won't use them because they're not integrated into the workflow.\n\n**The system will work for basic tasks** (governance-verify, task management) but **will fail for optimizations** (context files, logging, patterns) because they're not actually connected.\n\n---\n\n## 🎓 Honest Assessment\n\n**What Works:**\n- Governance framework is solid\n- Documentation is comprehensive\n- Basic workflows are clear\n- Task management works\n\n**What Doesn't Work:**\n- Context files (orphaned)\n- Logging (no code)\n- Pattern verification (not done)\n- HITL workflow (unclear)\n- Boundary enforcement (vague)\n- Integration (missing)\n\n**Recommendation:**\n**Stop adding features. Start integrating what exists.**\n\nFocus on:\n1. Wiring context files into workflow\n2. Creating actual logging code\n3. Fixing validation\n4. Adding enforcement\n\nThen measure if it actually works before adding more.\n\n---\n\n---\n\n## 📊 Additional Gaps Found (Second Pass)\n\n### Missing Infrastructure\n- ❌ `docs/adr/` directory doesn't exist (referenced but missing)\n- ❌ No test pattern examples in folder-level guides\n- ❌ No change type decision tree anywhere\n\n### Unclear Workflows\n- ❌ Change type determination (no guidance)\n- ❌ Task packet creation (when? where? how?)\n- ❌ PR change type validation (how to verify?)\n\n### Incomplete Validation\n- ❌ `governance-verify` artifact checking is stub\n- ❌ No change type parsing from PR\n- ❌ No task packet validation\n- ❌ No test pattern validation\n\n### Missing Examples\n- ❌ No examples of each change type\n- ❌ No examples of task packets for different types\n- ❌ No examples of test patterns\n- ❌ No examples of ADR creation\n\n---\n\n**End of Critical Analysis**\n"
        },
        {
          "path": ".repo/IMPLEMENTATION_PROGRESS.md",
          "type": "Markdown",
          "purpose": "Implementation progress tracking",
          "status": "May be outdated (conflicts with REMAINING_TASKS.md)",
          "used_by": [
            "Progress tracking"
          ],
          "content": "# Implementation Progress: Critical Fixes\n\n**Date:** 2026-01-23\n**Based on:** `.repo/CRITICAL_ANALYSIS_FAILURES.md` and `.repo/PROJECTED_ANALYSIS_AFTER_FIXES.md`\n\n---\n\n## ✅ Completed Fixes (6/15)\n\n### 1. ✅ Change Type Determination\n- **Status:** COMPLETE\n- **Changes:**\n  - Added decision tree to `.repo/agents/QUICK_REFERENCE.md`\n  - Added to Pass 1 workflow in `AGENTS.json`\n  - Added examples of each change type\n  - Created artifact checking script: `.repo/automation/scripts/check-artifacts-by-change-type.js`\n  - Integrated into `governance-verify.js`\n\n### 2. ✅ Context Files Integration\n- **Status:** COMPLETE\n- **Changes:**\n  - Added `pass0_context` to `AGENTS.json` workflow\n  - Added `folder_entry` to context_determination in `AGENTS.json`\n  - Updated `AGENT.md` to mention context files\n  - Updated `QUICK_REFERENCE.md` to mention context files in workflow\n\n### 3. ✅ ADR Directory\n- **Status:** COMPLETE\n- **Changes:**\n  - Created `docs/adr/` directory\n  - Added `docs/adr/README.md` with ADR format and workflow\n  - Updated `QUICK_REFERENCE.md` to note directory requirement\n\n### 4. ✅ HITL Workflow\n- **Status:** COMPLETE\n- **Changes:**\n  - Added HITL creation workflow section to `QUICK_REFERENCE.md`\n  - Documented exact command: `scripts/create-hitl-item.sh [category] [summary]`\n  - Explained parameters, format, and linking to PR\n\n### 5. ✅ Governance-Verify Artifact Checking\n- **Status:** COMPLETE\n- **Changes:**\n  - Created `check-artifacts-by-change-type.js` script\n  - Integrated into `governance-verify.js` as Check 11\n  - Parses change type from PR description\n  - Checks all required artifacts for that change type\n  - Fails hard gates if artifacts missing\n\n### 6. ✅ PR Change Type Guidance\n- **Status:** COMPLETE\n- **Changes:**\n  - Updated `PR_TEMPLATE.md` with change type decision tree\n  - Added change_type to required sections in `AGENTS.json`\n  - Added change_type_determination section to `AGENTS.json` pr_creation\n\n---\n\n## 🚧 Remaining Fixes (9/15)\n\n### 7. ⏳ Logging Implementation\n- **Status:** PENDING\n- **Priority:** HIGH\n- **What's Needed:**\n  - Create logging SDK/library (Node.js or Python)\n  - Add logging hooks to agent workflow\n  - Create log collector/aggregator\n  - Document how agents call logging functions\n\n### 8. ⏳ Validation Schema\n- **Status:** PENDING\n- **Priority:** HIGH\n- **What's Needed:**\n  - Update `validate-agent-context.js` to use JSON schema (ajv)\n  - Validate all required fields from schema\n  - Check file paths exist\n  - Validate patterns against actual code\n  - Check boundaries are correct\n\n### 9. ⏳ Task Packet Workflow\n- **Status:** PENDING\n- **Priority:** MEDIUM\n- **What's Needed:**\n  - Add to Pass 1 workflow when to create task packets\n  - Document where to store (TODO.md or separate file)\n  - Add examples for each change type\n\n### 10. ⏳ Boundary Enforcement\n- **Status:** PENDING\n- **Priority:** MEDIUM\n- **What's Needed:**\n  - Integrate boundary checking into agent workflow\n  - Add automated checking (import-linter or similar)\n  - Add boundary checks to governance-verify\n  - Fail fast on violations\n  - Add to CI pipeline\n\n### 11. ⏳ Testing Guidance\n- **Status:** PENDING\n- **Priority:** MEDIUM\n- **What's Needed:**\n  - Add test patterns to folder-level `.AGENT.md` files\n  - Create test examples for common patterns\n  - Document test coverage requirements\n  - Add test validation hints to quality gates\n\n### 12. ⏳ Pattern Verification\n- **Status:** PENDING\n- **Priority:** LOW\n- **What's Needed:**\n  - Extract patterns from actual codebase\n  - Verify existing pattern files match code\n  - Create automated pattern extraction script\n  - Add pattern validation to CI (advisory)\n\n### 13. ⏳ Context File Updates\n- **Status:** PENDING\n- **Priority:** LOW\n- **What's Needed:**\n  - Add `last_verified` date field to context files\n  - Create script to check for stale context files\n  - Add alerts/warnings when context files are outdated\n  - Document update workflow\n\n### 14. ⏳ Consolidate Entry Points\n- **Status:** PENDING\n- **Priority:** LOW\n- **What's Needed:**\n  - Review `AGENTS.json`, `AGENT.md`, `QUICK_REFERENCE.md`, `AGENTS.md` for conflicts\n  - Ensure all reference single canonical source\n  - Update cross-references to be consistent\n\n### 15. ⏳ Failure Recovery\n- **Status:** PENDING\n- **Priority:** LOW\n- **What's Needed:**\n  - Add error handling to HITL creation script\n  - Add fallbacks for logging failures\n  - Add graceful degradation for validation failures\n  - Document what to do when scripts fail\n\n---\n\n## 📊 Summary\n\n**Completed:** 6/15 (40%)\n**In Progress:** 0/15 (0%)\n**Pending:** 9/15 (60%)\n\n**Critical Fixes Completed:**\n- ✅ Change type determination\n- ✅ Context files integration\n- ✅ ADR directory\n- ✅ HITL workflow\n- ✅ Governance-verify artifacts\n- ✅ PR change type guidance\n\n**High Priority Remaining:**\n- ⏳ Logging implementation\n- ⏳ Validation schema\n\n**Next Steps:**\n1. Implement logging SDK/library\n2. Fix validation to use JSON schema\n3. Add task packet workflow clarification\n4. Add boundary enforcement\n\n---\n\n**Note:** This progress is based on the critical analysis. Some fixes may require additional work or iteration based on real-world usage.\n"
        },
        {
          "path": ".repo/PROJECTED_ANALYSIS_AFTER_FIXES.md",
          "type": "Markdown",
          "purpose": "Projected analysis after fixes",
          "used_by": [
            "Historical reference"
          ],
          "content": "# Projected Analysis: What Will Still Fail After All Fixes\n\n**Date:** 2026-01-23\n**Purpose:** Critical analysis assuming all identified fixes are implemented\n**Tone:** Brutally honest - what will STILL break even after fixes\n\n**Assumption:** All fixes from `CRITICAL_ANALYSIS_FAILURES.md` are implemented:\n- ✅ Context files integrated into workflow\n- ✅ Logging code created and integrated\n- ✅ Validation uses JSON schema\n- ✅ Patterns verified against code\n- ✅ HITL workflow clarified\n- ✅ Boundaries enforced\n- ✅ Change type determination added\n- ✅ Task packet workflow clarified\n- ✅ ADR directory created\n- ✅ Testing guidance added\n- ✅ Governance-verify artifact checking implemented\n\n---\n\n## Executive Summary\n\n**Grade After Fixes: B+ (Good System, Fundamental Limitations)**\n\nEven with all fixes implemented, the system will still have **fundamental limitations** that will cause failures. These are not bugs or gaps - they're inherent to the design approach.\n\n---\n\n## 🔴 WHAT WILL STILL FAIL (Even After All Fixes)\n\n### 1. **Agents Will Still Guess Change Types Incorrectly**\n\n**Severity:** HIGH\n**Why It Will Still Fail:** Change type determination is inherently ambiguous\n\n**The Problem:**\nEven with a decision tree, many changes are ambiguous:\n- Is adding a new API endpoint \"feature\" or \"api_change\"?\n- Is fixing a security bug \"security\" or \"feature\"?\n- Is refactoring across modules \"cross_module\" or \"feature\"?\n- Is updating docs \"non_doc_change\" or just \"docs\"?\n\n**What Will Happen:**\n- Agents will classify inconsistently\n- Same change will be classified differently by different agents\n- Quality gates will be inconsistent\n- System will be unpredictable\n\n**Why It Can't Be Fixed:**\n- Classification is subjective\n- Real-world changes don't fit clean categories\n- No objective criteria can cover all cases\n\n**Mitigation (Not Fix):**\n- Add \"hybrid\" change types\n- Allow multiple change types\n- Make classification advisory, not strict\n- Add human review for ambiguous cases\n\n---\n\n### 2. **Context Files Will Still Go Stale - Update Mechanism Is Manual**\n\n**Severity:** MEDIUM\n**Why It Will Still Fail:** No automated sync with code\n\n**The Problem:**\nEven if we add update mechanisms, they'll be:\n- Manual (agents must remember to update)\n- Incomplete (won't catch all changes)\n- Slow (updates lag behind code)\n- Error-prone (agents will forget or update incorrectly)\n\n**What Will Happen:**\n- Context files will become outdated\n- Agents will follow wrong patterns\n- System will degrade over time\n- Manual maintenance burden\n\n**Why It Can't Be Fixed:**\n- Automated extraction is hard (patterns are subjective)\n- Code changes faster than documentation\n- No way to automatically detect pattern changes\n- Requires human judgment\n\n**Mitigation (Not Fix):**\n- Add \"last verified\" dates\n- Add alerts when context files are stale\n- Add automated pattern extraction (partial)\n- Make context files optional, not required\n\n---\n\n### 3. **Pattern Verification Will Be Incomplete - Patterns Are Subjective**\n\n**Severity:** MEDIUM\n**Why It Will Still Fail:** Patterns can't be objectively verified\n\n**The Problem:**\nPatterns are:\n- Subjective (what's a pattern vs. anti-pattern?)\n- Context-dependent (works here, not there)\n- Evolving (patterns change over time)\n- Incomplete (can't document all patterns)\n\n**What Will Happen:**\n- Pattern verification will miss cases\n- False positives (flag correct code as wrong)\n- False negatives (miss actual violations)\n- Agents will be confused\n\n**Why It Can't Be Fixed:**\n- Patterns are human judgment, not rules\n- Can't automate subjective verification\n- Patterns evolve faster than verification\n\n**Mitigation (Not Fix):**\n- Make pattern verification advisory\n- Focus on critical patterns only\n- Add human review for pattern violations\n- Accept that patterns will be imperfect\n\n---\n\n### 4. **Boundary Enforcement Will Have False Positives**\n\n**Severity:** MEDIUM\n**Why It Will Still Fail:** Boundaries are complex and context-dependent\n\n**The Problem:**\nBoundary checking will:\n- Flag legitimate imports as violations\n- Miss actual violations (dynamic imports, etc.)\n- Be too strict (block valid refactoring)\n- Be too loose (allow violations)\n\n**What Will Happen:**\n- Legitimate code will be blocked\n- Violations will slip through\n- Agents will work around enforcement\n- System will be frustrating\n\n**Why It Can't Be Fixed:**\n- Boundaries are architectural, not syntactic\n- Can't detect all violation patterns\n- Context matters (sometimes violations are OK)\n\n**Mitigation (Not Fix):**\n- Make boundary checking advisory\n- Add exceptions mechanism\n- Focus on critical boundaries only\n- Add human review for violations\n\n---\n\n### 5. **HITL Workflow Will Be Bypassed - Too Many False Positives**\n\n**Severity:** HIGH\n**Why It Will Still Fail:** HITL triggers will be too broad\n\n**The Problem:**\nHITL triggers are:\n- Too broad (everything is \"risky\")\n- Too narrow (miss actual risks)\n- Context-dependent (risky here, not there)\n- Slow (blocks work unnecessarily)\n\n**What Will Happen:**\n- Agents will create too many HITL items\n- Humans will be overwhelmed\n- Agents will bypass HITL (skip creating items)\n- System will be slow\n\n**Why It Can't Be Fixed:**\n- Risk assessment is subjective\n- Can't automate risk detection perfectly\n- Too many edge cases\n\n**Mitigation (Not Fix):**\n- Make HITL triggers more specific\n- Add risk levels (low/medium/high)\n- Allow agents to proceed with low-risk HITL\n- Add auto-approval for common cases\n\n---\n\n### 6. **Logging Will Be Incomplete - Agents Will Skip It**\n\n**Severity:** MEDIUM\n**Why It Will Still Fail:** Logging is manual and time-consuming\n\n**The Problem:**\nEven with logging hooks:\n- Agents must remember to log\n- Logging takes time (slows down work)\n- Logging is boring (agents will skip)\n- Logs will be incomplete\n\n**What Will Happen:**\n- Logs will be missing\n- Logs will be incomplete\n- Logs will be inaccurate\n- System won't be measurable\n\n**Why It Can't Be Fixed:**\n- Can't force agents to log\n- Logging is overhead\n- Agents optimize for speed, not logging\n\n**Mitigation (Not Fix):**\n- Make logging automatic (hook into agent actions)\n- Make logging optional for non-critical actions\n- Add incentives (logging helps agents)\n- Accept incomplete logs\n\n---\n\n### 7. **Testing Guidance Will Be Insufficient - Tests Are Hard**\n\n**Severity:** MEDIUM\n**Why It Will Still Fail:** Writing good tests is difficult\n\n**The Problem:**\nEven with test patterns:\n- Tests are hard to write correctly\n- Test patterns don't cover all cases\n- Tests require domain knowledge\n- Tests take time\n\n**What Will Happen:**\n- Tests will be incomplete\n- Tests will be low quality\n- Tests will be missing\n- Coverage will be low\n\n**Why It Can't Be Fixed:**\n- Testing is a skill, not a pattern\n- Can't automate test writing\n- Tests require understanding of code\n\n**Mitigation (Not Fix):**\n- Focus on critical tests only\n- Add test generation tools\n- Make tests optional for low-risk changes\n- Accept that tests will be imperfect\n\n---\n\n### 8. **Governance-Verify Will Have False Positives and Negatives**\n\n**Severity:** MEDIUM\n**Why It Will Still Fail:** Verification is inherently imperfect\n\n**The Problem:**\nEven with full artifact checking:\n- Can't verify artifacts are correct (only that they exist)\n- Can't verify change type is correct\n- Can't verify content quality\n- Will miss edge cases\n\n**What Will Happen:**\n- Valid PRs will be blocked\n- Invalid PRs will pass\n- System will be inconsistent\n- Agents will be frustrated\n\n**Why It Can't Be Fixed:**\n- Can't automate quality assessment\n- Verification is syntactic, not semantic\n- Too many edge cases\n\n**Mitigation (Not Fix):**\n- Make verification advisory\n- Focus on critical checks only\n- Add human review for edge cases\n- Accept that verification will be imperfect\n\n---\n\n### 9. **Task Packets Will Be Incomplete - Too Much Work**\n\n**Severity:** MEDIUM\n**Why It Will Still Fail:** Task packets are time-consuming\n\n**The Problem:**\nEven with templates:\n- Task packets take time to create\n- Agents will skip optional fields\n- Task packets will be incomplete\n- Maintenance burden\n\n**What Will Happen:**\n- Task packets will be minimal\n- Important information will be missing\n- Task packets will be outdated\n- System will be less useful\n\n**Why It Can't Be Fixed:**\n- Can't force agents to be thorough\n- Task packets are overhead\n- Agents optimize for speed\n\n**Mitigation (Not Fix):**\n- Make task packets optional for simple changes\n- Auto-generate from code changes\n- Focus on critical fields only\n- Accept incomplete task packets\n\n---\n\n### 10. **ADR Creation Will Be Skipped - Too Much Friction**\n\n**Severity:** MEDIUM\n**Why It Will Still Fail:** ADRs are time-consuming and feel like overhead\n\n**The Problem:**\nEven with templates and scripts:\n- ADRs take time to write\n- ADRs feel like bureaucracy\n- Agents will skip when possible\n- ADRs will be minimal\n\n**What Will Happen:**\n- ADRs will be skipped\n- ADRs will be incomplete\n- System will be less documented\n- Decisions won't be captured\n\n**Why It Can't Be Fixed:**\n- Can't force agents to write good ADRs\n- ADRs are overhead\n- Agents optimize for speed\n\n**Mitigation (Not Fix):**\n- Make ADRs optional for low-impact changes\n- Auto-generate ADRs from code\n- Focus on critical decisions only\n- Accept that ADRs will be minimal\n\n---\n\n## ⚠️ FUNDAMENTAL LIMITATIONS (Can't Be Fixed)\n\n### 1. **Agents Are Not Perfect - They Will Make Mistakes**\n\n**Reality:**\n- Agents will misunderstand requirements\n- Agents will make coding errors\n- Agents will skip steps\n- Agents will optimize for speed over quality\n\n**Impact:**\n- System will have errors\n- Quality will be inconsistent\n- Some failures are inevitable\n\n**Mitigation:**\n- Add more validation\n- Add human review\n- Accept that perfection is impossible\n\n---\n\n### 2. **Documentation Can't Keep Up With Code**\n\n**Reality:**\n- Code changes faster than documentation\n- Documentation is manual\n- Documentation is incomplete\n- Documentation goes stale\n\n**Impact:**\n- Context files will be outdated\n- Patterns will be wrong\n- Agents will follow outdated guidance\n\n**Mitigation:**\n- Auto-generate documentation\n- Make documentation optional\n- Accept that docs will be imperfect\n\n---\n\n### 3. **Automation Can't Replace Human Judgment**\n\n**Reality:**\n- Many decisions require human judgment\n- Automation is syntactic, not semantic\n- Edge cases require human review\n- Quality assessment is subjective\n\n**Impact:**\n- Automated checks will be imperfect\n- False positives and negatives\n- System will need human oversight\n\n**Mitigation:**\n- Make automation advisory\n- Add human review for edge cases\n- Accept that automation is imperfect\n\n---\n\n### 4. **System Will Degrade Over Time**\n\n**Reality:**\n- Code accumulates technical debt\n- Patterns drift from reality\n- Documentation becomes outdated\n- System becomes inconsistent\n\n**Impact:**\n- System will need maintenance\n- Quality will degrade\n- Failures will increase\n\n**Mitigation:**\n- Regular maintenance cycles\n- Automated health checks\n- Accept that degradation is inevitable\n\n---\n\n## 📊 What Will Actually Work (After Fixes)\n\n### ✅ Will Work Well\n- Basic governance framework (rules, policies)\n- Task management (TODO/BACKLOG/ARCHIVE)\n- Basic workflows (three-pass)\n- File structure (organization)\n- Basic validation (syntax, existence)\n\n### ⚠️ Will Work But Be Imperfect\n- Change type determination (will have errors)\n- Artifact creation (will be incomplete)\n- Pattern following (will be inconsistent)\n- Boundary enforcement (will have false positives)\n- HITL workflow (will be bypassed sometimes)\n\n### ❌ Will Still Fail\n- Perfect change type classification\n- Complete context file updates\n- Perfect pattern verification\n- Complete boundary enforcement\n- Complete logging\n- Perfect test coverage\n- Perfect artifact quality\n\n---\n\n## 💡 Realistic Expectations\n\n### What the System CAN Do\n- Provide structure and guidance\n- Enforce basic rules\n- Track tasks and changes\n- Validate syntax and existence\n- Guide agent behavior\n\n### What the System CANNOT Do\n- Guarantee perfect agent behavior\n- Keep all documentation current\n- Automate all quality checks\n- Eliminate all errors\n- Replace human judgment\n\n### What You Should Expect\n- **60-80% compliance** with rules (not 100%)\n- **Incomplete but useful** documentation\n- **Imperfect but helpful** automation\n- **Good enough** quality (not perfect)\n- **Ongoing maintenance** required\n\n---\n\n## 🎯 Recommendations for After Fixes\n\n### 1. **Accept Imperfection**\n- Don't expect 100% compliance\n- Don't expect perfect automation\n- Don't expect complete documentation\n- Focus on \"good enough\"\n\n### 2. **Focus on Critical Paths**\n- Prioritize high-impact checks\n- Make low-impact checks optional\n- Accept that edge cases will slip through\n\n### 3. **Add Human Oversight**\n- Review critical changes\n- Review ambiguous cases\n- Review edge cases\n- Don't rely on automation alone\n\n### 4. **Regular Maintenance**\n- Update documentation regularly\n- Review and update patterns\n- Clean up stale context files\n- Fix accumulated issues\n\n### 5. **Measure and Iterate**\n- Track what actually works\n- Track what fails\n- Adjust based on reality\n- Don't assume fixes will work\n\n---\n\n## 🔴 Bottom Line (After All Fixes)\n\n**The system will be B+ (Good, Not Perfect)**\n\n**What Will Work:**\n- Basic governance and structure\n- Task management\n- Basic workflows\n- Basic validation\n\n**What Will Still Fail:**\n- Perfect classification\n- Complete documentation\n- Perfect automation\n- 100% compliance\n\n**What You Should Do:**\n- Accept imperfection\n- Focus on critical paths\n- Add human oversight\n- Regular maintenance\n- Measure and iterate\n\n**The system will help, but it won't be perfect. That's OK.**\n\n---\n\n**End of Projected Analysis**\n"
        },
        {
          "path": ".repo/REPOSITORY_BEST_PRACTICES_ANALYSIS.md",
          "type": "Markdown",
          "purpose": "Best practices analysis",
          "used_by": [
            "Historical reference"
          ],
          "content": "# Repository Best Practices: Master List & Gap Analysis\n\n**Created:** 2026-01-23\n**Purpose:** Comprehensive analysis of repository best practices, current state, and implementation roadmap for enterprise-grade standards\n\n---\n\n## Executive Summary\n\nThis document provides a comprehensive master list of repository best practices from conception to maintenance, including enterprise-grade standards, innovative techniques, and automation strategies. It also includes a detailed gap analysis comparing what exists in this repository versus what needs to be implemented.\n\n**Repository Type:** Full-stack monorepo (Django backend + React frontend)\n**Current State:** Well-structured with agentic workflow framework, needs enhancement in standard documentation and automation\n\n---\n\n## Table of Contents\n\n1. [Master List: Essential Files & Documentation](#master-list-essential-files--documentation)\n2. [Master List: Security & Code Quality](#master-list-security--code-quality)\n3. [Master List: Git & Version Control](#master-list-git--version-control)\n4. [Master List: CI/CD & Automation](#master-list-cicd--automation)\n5. [Master List: Repository Structure](#master-list-repository-structure)\n6. [Master List: Advanced Practices](#master-list-advanced-practices)\n7. [Gap Analysis: What Exists vs. What's Needed](#gap-analysis-what-exists-vs-whats-needed)\n8. [Implementation Roadmap](#implementation-roadmap)\n\n---\n\n## Master List: Essential Files & Documentation\n\n### Core Documentation Files (Required)\n\n| File | Purpose | Priority | Status |\n|------|---------|----------|--------|\n| `README.md` | Project overview, installation, usage, quick start | P0 | ✅ Exists (needs enhancement) |\n| `LICENSE` | Legal framework for code usage | P0 | ✅ Exists (Proprietary) |\n| `CONTRIBUTING.md` | Contribution guidelines and expectations | P0 | ✅ Exists (basic) |\n| `SECURITY.md` | Security vulnerability reporting procedures | P0 | ✅ Exists (basic) |\n| `CODE_OF_CONDUCT.md` | Community standards and behavior expectations | P1 | ❌ Missing |\n| `CHANGELOG.md` | Version history and release notes | P1 | ✅ Exists (`.repo/CHANGELOG.md`) |\n| `AUTHORS.md` | Project contributors and credits | P2 | ❌ Missing |\n| `CITATION.cff` | Citation information (for research projects) | P3 | ❌ Missing |\n| `ROADMAP.md` | Future plans and priorities | P2 | ❌ Missing |\n| `VISION.md` | Project goals and scope | P2 | ❌ Missing |\n\n### GitHub-Specific Files\n\n| File | Purpose | Priority | Status |\n|------|---------|----------|--------|\n| `.github/PULL_REQUEST_TEMPLATE.md` | PR standardization | P0 | ✅ Exists |\n| `.github/ISSUE_TEMPLATE/` | Issue standardization | P1 | ❌ Missing |\n| `.github/CODEOWNERS` | Code ownership rules | P1 | ✅ Exists |\n| `.github/workflows/` | CI/CD automation | P0 | ✅ Exists (basic) |\n| `.github/dependabot.yml` | Dependency update automation | P1 | ❌ Missing |\n| `.github/renovate.json` | Alternative to Dependabot (more advanced) | P2 | ❌ Missing |\n\n### Architecture & Design Documentation\n\n| File | Purpose | Priority | Status |\n|------|---------|----------|--------|\n| `docs/architecture/README.md` | System design overview | P1 | ✅ Exists |\n| `docs/architecture/decisions/` | Architecture Decision Records (ADRs) | P1 | ✅ Exists (structure) |\n| `ARCHITECTURE.md` | High-level architecture overview | P2 | ❌ Missing (has docs/architecture/) |\n| `DESIGN_DECISIONS.md` | Design decision log | P2 | ❌ Missing (has ADR structure) |\n\n### Process Documentation\n\n| File | Purpose | Priority | Status |\n|------|---------|----------|--------|\n| `WORKING_AGREEMENT.md` | Team norms and expectations | P2 | ❌ Missing |\n| `DEFINITION_OF_DONE.md` | Completion criteria for work items | P2 | ❌ Missing |\n| `DEFINITION_OF_READY.md` | User story acceptance criteria | P2 | ❌ Missing |\n| `CODE_REVIEW_CHECKLIST.md` | Review standards | P2 | ❌ Missing |\n| `docs/getting-started/onboarding.md` | Getting started guide | P1 | ✅ Exists |\n\n---\n\n## Master List: Security & Code Quality\n\n### GitHub Security Features\n\n| Feature | Purpose | Priority | Status |\n|---------|---------|----------|--------|\n| **Dependabot alerts** | Dependency vulnerability notifications | P0 | ⚠️ Needs verification |\n| **Secret scanning** | Detect API keys, tokens, credentials | P0 | ⚠️ Needs verification |\n| **Push protection** | Block secrets before commit | P0 | ⚠️ Needs verification |\n| **Code scanning** | Identify vulnerabilities automatically | P1 | ⚠️ Needs verification |\n| **Private vulnerability reporting** | Secure disclosure channel | P1 | ⚠️ Needs verification |\n| **Dependency review** | Review dependency changes in PRs | P1 | ❌ Missing |\n\n### Code Quality Tools\n\n| Tool/Feature | Purpose | Priority | Status |\n|--------------|---------|----------|--------|\n| **Pre-commit hooks** | Code quality checks before commits | P0 | ✅ Exists (`.pre-commit-config.yaml`) |\n| **Linting** | Code style enforcement | P0 | ✅ Exists (ruff, eslint) |\n| **Formatting** | Code formatting (black, prettier) | P0 | ✅ Exists |\n| **Type checking** | Static type analysis | P0 | ✅ Exists (mypy, TypeScript) |\n| **SAST** | Static Application Security Testing | P1 | ✅ Exists (bandit in CI) |\n| **DAST** | Dynamic Application Security Testing | P2 | ❌ Missing |\n| **Code coverage** | Test coverage tracking | P0 | ✅ Exists (pytest, vitest) |\n| **Coverage thresholds** | Minimum coverage requirements | P1 | ⚠️ Needs configuration |\n| **SonarQube/SonarCloud** | Advanced code quality analysis | P2 | ❌ Missing |\n\n### Security Scanning Tools\n\n| Tool | Purpose | Priority | Status |\n|------|---------|----------|--------|\n| **pip-audit** | Python dependency vulnerability scanning | P0 | ✅ Exists (in CI) |\n| **safety** | Python dependency security check | P0 | ✅ Exists (in CI) |\n| **bandit** | Python security linter | P0 | ✅ Exists (in CI) |\n| **npm audit** | Node.js dependency vulnerability scanning | P0 | ✅ Exists (in CI) |\n| **trufflehog** | Secret scanning | P0 | ✅ Exists (in CI) |\n| **Snyk** | Advanced dependency and container scanning | P2 | ❌ Missing |\n| **OWASP ZAP** | Web application security testing | P2 | ❌ Missing |\n\n---\n\n## Master List: Git & Version Control\n\n### Branching Strategy\n\n| Practice | Purpose | Priority | Status |\n|----------|---------|----------|--------|\n| **Protected branches** | Prevent direct commits to main | P0 | ⚠️ Needs verification |\n| **Branch protection rules** | Require PR reviews, status checks | P0 | ⚠️ Needs verification |\n| **Feature branch workflow** | Work in branches, not directly on main | P0 | ✅ Implemented |\n| **Branch naming conventions** | Consistent naming (feature/, fix/, etc.) | P1 | ⚠️ Needs documentation |\n| **Release branches** | Separate release branches | P2 | ❌ Missing |\n| **Hotfix branches** | Emergency fix workflow | P2 | ❌ Missing |\n\n### Git Configuration Files\n\n| File | Purpose | Priority | Status |\n|------|---------|----------|--------|\n| `.gitignore` | Exclude unnecessary files | P0 | ✅ Exists |\n| `.gitattributes` | Git behavior configuration | P1 | ❌ Missing |\n| `.gitmessage` | Commit message template | P2 | ❌ Missing |\n| `.editorconfig` | Editor configuration | P1 | ❌ Missing |\n\n### Commit Standards\n\n| Practice | Purpose | Priority | Status |\n|----------|---------|----------|--------|\n| **Conventional Commits** | Standardized commit messages | P1 | ⚠️ Needs enforcement |\n| **Semantic versioning** | Version numbering (MAJOR.MINOR.PATCH) | P1 | ✅ Exists (`VERSION` file) |\n| **Commit message linting** | Enforce commit message format | P2 | ❌ Missing |\n| **Signed commits** | GPG-signed commits for security | P2 | ❌ Missing |\n\n### Large File Management\n\n| Feature | Purpose | Priority | Status |\n|---------|---------|----------|--------|\n| **Git LFS** | Manage large files (>100MB) | P2 | ❌ Missing (if needed) |\n| **File size limits** | Prevent large files in repo | P1 | ⚠️ Needs configuration |\n\n---\n\n## Master List: CI/CD & Automation\n\n### GitHub Actions Workflows\n\n| Workflow | Purpose | Priority | Status |\n|----------|---------|----------|--------|\n| **CI workflow** | Automated testing on PRs | P0 | ✅ Exists (`.github/workflows/ci.yml`) |\n| **Lint workflow** | Code quality checks | P0 | ✅ Exists (in CI) |\n| **Test workflow** | Automated test execution | P0 | ✅ Exists (in CI) |\n| **Security workflow** | Security scanning | P0 | ✅ Exists (in CI) |\n| **Build workflow** | Build verification | P0 | ✅ Exists (in CI) |\n| **Deploy workflow** | Automated deployment | P1 | ⚠️ Exists (staging placeholder) |\n| **Release workflow** | Automated releases | P2 | ❌ Missing |\n| **Docs workflow** | Documentation generation/validation | P1 | ✅ Exists (`.github/workflows/docs.yml`) |\n| **Dependency update workflow** | Automated dependency updates | P1 | ❌ Missing (needs Dependabot/Renovate) |\n\n### CI/CD Best Practices\n\n| Practice | Purpose | Priority | Status |\n|----------|---------|----------|--------|\n| **Matrix builds** | Test across multiple versions | P1 | ⚠️ Partial (Python/Node versions) |\n| **Parallel jobs** | Faster CI execution | P1 | ✅ Implemented |\n| **Caching** | Speed up builds | P1 | ✅ Implemented (pip, npm) |\n| **Artifact management** | Store build artifacts | P1 | ✅ Implemented |\n| **Status badges** | Show CI status in README | P1 | ✅ Exists |\n| **Required status checks** | Block merge if checks fail | P0 | ⚠️ Needs verification |\n| **Conditional workflows** | Run workflows conditionally | P1 | ✅ Implemented |\n| **Workflow dispatch** | Manual workflow triggers | P2 | ❌ Missing |\n\n### Dependency Management Automation\n\n| Tool | Purpose | Priority | Status |\n|------|---------|----------|--------|\n| **Dependabot** | Automated dependency updates | P1 | ❌ Missing (needs config) |\n| **Renovate** | Advanced dependency management | P2 | ❌ Missing |\n| **Automated security patches** | Auto-merge security updates | P2 | ❌ Missing |\n| **Dependency review** | Review dependency changes | P1 | ❌ Missing |\n\n---\n\n## Master List: Repository Structure\n\n### Directory Organization\n\n| Structure | Purpose | Priority | Status |\n|-----------|---------|----------|--------|\n| **Monorepo structure** | Multiple projects in one repo | P0 | ✅ Implemented |\n| **Separated concerns** | Clear module boundaries | P0 | ✅ Implemented |\n| **Documentation directory** | Organized docs (`docs/`) | P0 | ✅ Exists |\n| **Tests directory** | Separate test structure | P0 | ✅ Exists |\n| **Scripts directory** | Automation scripts | P0 | ✅ Exists |\n| **Config directory** | Configuration files | P0 | ✅ Exists |\n| **Templates directory** | Reusable templates | P1 | ✅ Exists (`.repo/templates/`) |\n\n### File Organization Standards\n\n| Practice | Purpose | Priority | Status |\n|----------|---------|----------|--------|\n| **INDEX.md files** | Module navigation | P1 | ✅ Exists |\n| **Consistent naming** | Standardized file names | P1 | ✅ Implemented |\n| **Clear hierarchy** | Logical directory structure | P1 | ✅ Implemented |\n| **Documentation co-location** | Docs near code | P1 | ✅ Implemented |\n\n---\n\n## Master List: Advanced Practices\n\n### Architecture Decision Records (ADRs)\n\n| Practice | Purpose | Priority | Status |\n|----------|---------|----------|--------|\n| **ADR structure** | Document architectural decisions | P1 | ✅ Exists (`docs/architecture/decisions/`) |\n| **ADR template** | Standardized ADR format | P1 | ✅ Exists (`.repo/templates/ADR_TEMPLATE.md`) |\n| **ADR index** | List of all ADRs | P1 | ⚠️ Needs maintenance |\n| **ADR review process** | ADR approval workflow | P2 | ❌ Missing |\n\n### Version Management\n\n| Practice | Purpose | Priority | Status |\n|----------|---------|----------|--------|\n| **Semantic versioning** | Version numbering | P1 | ✅ Exists (`VERSION` file) |\n| **Version automation** | Auto-increment versions | P2 | ❌ Missing |\n| **Release notes** | Automated release notes | P2 | ❌ Missing |\n| **Changelog automation** | Auto-generate changelog | P2 | ❌ Missing |\n\n### Code Quality Metrics\n\n| Metric | Purpose | Priority | Status |\n|--------|---------|----------|--------|\n| **Code coverage** | Test coverage percentage | P1 | ✅ Exists (needs thresholds) |\n| **Complexity metrics** | Cyclomatic complexity | P2 | ❌ Missing |\n| **Technical debt tracking** | Track technical debt | P2 | ❌ Missing |\n| **Code quality scores** | Overall quality metrics | P2 | ❌ Missing |\n\n### Documentation Automation\n\n| Practice | Purpose | Priority | Status |\n|----------|---------|----------|--------|\n| **API documentation** | Auto-generated API docs | P1 | ✅ Exists (OpenAPI) |\n| **Code documentation** | Docstring standards | P1 | ✅ Exists (needs enforcement) |\n| **Documentation linting** | Validate documentation | P2 | ❌ Missing |\n| **Documentation coverage** | Track doc coverage | P2 | ❌ Missing |\n\n### Monitoring & Observability\n\n| Practice | Purpose | Priority | Status |\n|----------|---------|----------|--------|\n| **Error tracking** | Application error monitoring | P1 | ⚠️ Exists (Sentry in frontend) |\n| **Performance monitoring** | Application performance | P2 | ❌ Missing |\n| **Uptime monitoring** | Service availability | P2 | ❌ Missing |\n| **Log aggregation** | Centralized logging | P2 | ❌ Missing |\n\n### Agentic Workflow (Unique to This Repo)\n\n| Feature | Purpose | Priority | Status |\n|---------|---------|----------|--------|\n| **Agent rules framework** | AI agent governance | P0 | ✅ Exists (`.repo/agents/`) |\n| **Task management** | Structured task workflow | P0 | ✅ Exists (`.repo/tasks/`) |\n| **HITL system** | Human-in-the-loop approvals | P0 | ✅ Exists (`.repo/hitl/`) |\n| **Governance verification** | Automated governance checks | P0 | ✅ Exists (scripts) |\n| **Trace logging** | Agent action logging | P0 | ✅ Exists (`.repo/traces/`) |\n| **Policy framework** | Comprehensive policies | P0 | ✅ Exists (`.repo/policy/`) |\n| **Manifest system** | Command source of truth | P0 | ✅ Exists (`.repo/repo.manifest.yaml`) |\n\n---\n\n## Gap Analysis: What Exists vs. What's Needed\n\n### ✅ What Exists (Strengths)\n\n#### Documentation\n- ✅ Comprehensive README.md with badges, quick start, architecture diagram\n- ✅ LICENSE file (Proprietary)\n- ✅ CONTRIBUTING.md (basic)\n- ✅ SECURITY.md (basic)\n- ✅ CHANGELOG.md (in `.repo/`)\n- ✅ Well-organized documentation structure (`docs/`)\n- ✅ Architecture documentation (`docs/architecture/`)\n- ✅ Getting started guide (`docs/getting-started/`)\n- ✅ Development guides (`docs/development/`)\n- ✅ Operations documentation (`docs/operations/`)\n\n#### Security & Quality\n- ✅ Pre-commit hooks configured (`.pre-commit-config.yaml`)\n- ✅ Linting (ruff, eslint)\n- ✅ Formatting (black, prettier)\n- ✅ Type checking (mypy, TypeScript)\n- ✅ Security scanning in CI (pip-audit, safety, bandit, npm audit, trufflehog)\n- ✅ Code coverage tracking (pytest, vitest)\n- ✅ OpenAPI documentation\n\n#### CI/CD\n- ✅ Comprehensive CI workflow (`.github/workflows/ci.yml`)\n- ✅ Multiple CI jobs (lint, test, security, docker, governance)\n- ✅ Parallel job execution\n- ✅ Caching (pip, npm)\n- ✅ Artifact management\n- ✅ Status badges in README\n- ✅ Docs workflow (`.github/workflows/docs.yml`)\n\n#### Repository Structure\n- ✅ Well-organized monorepo structure\n- ✅ Clear module boundaries\n- ✅ INDEX.md files for navigation\n- ✅ Scripts directory with automation\n- ✅ Templates directory (`.repo/templates/`)\n- ✅ Task management system (`.repo/tasks/`)\n\n#### Agentic Workflow (Unique)\n- ✅ Comprehensive agent framework (`.repo/agents/`)\n- ✅ Task management system (TODO/BACKLOG/ARCHIVE)\n- ✅ HITL system for approvals\n- ✅ Governance verification scripts\n- ✅ Policy framework (CONSTITUTION, PRINCIPLES, etc.)\n- ✅ Manifest system for commands\n- ✅ Trace logging system\n\n#### Git Configuration\n- ✅ `.gitignore` (comprehensive)\n- ✅ Feature branch workflow\n- ✅ VERSION file for semantic versioning\n- ✅ CODEOWNERS file\n\n### ❌ What's Missing (Gaps)\n\n#### Documentation\n- ❌ CODE_OF_CONDUCT.md\n- ❌ AUTHORS.md\n- ❌ ROADMAP.md\n- ❌ VISION.md\n- ❌ CITATION.cff (if applicable)\n- ❌ WORKING_AGREEMENT.md\n- ❌ DEFINITION_OF_DONE.md\n- ❌ DEFINITION_OF_READY.md\n- ❌ CODE_REVIEW_CHECKLIST.md\n\n#### GitHub Configuration\n- ❌ `.github/ISSUE_TEMPLATE/` directory with templates\n- ❌ `.github/dependabot.yml` configuration\n- ❌ Branch protection rules (needs verification)\n- ❌ Required status checks configuration (needs verification)\n\n#### Git Configuration\n- ❌ `.gitattributes` file\n- ❌ `.gitmessage` commit template\n- ❌ `.editorconfig` file\n- ❌ Conventional commits enforcement\n- ❌ Commit message linting\n\n#### Advanced Automation\n- ❌ Dependabot configuration\n- ❌ Renovate configuration (alternative)\n- ❌ Automated release workflow\n- ❌ Automated changelog generation\n- ❌ Version automation\n- ❌ Dependency review in PRs\n\n#### Code Quality\n- ❌ Coverage thresholds enforcement\n- ❌ Code complexity metrics\n- ❌ Technical debt tracking\n- ❌ SonarQube/SonarCloud integration\n- ❌ Documentation coverage tracking\n\n#### Security (Needs Verification)\n- ⚠️ Dependabot alerts (needs verification in GitHub settings)\n- ⚠️ Secret scanning (needs verification in GitHub settings)\n- ⚠️ Push protection (needs verification in GitHub settings)\n- ⚠️ Code scanning (needs verification in GitHub settings)\n- ⚠️ Private vulnerability reporting (needs verification)\n- ❌ Dependency review workflow\n- ❌ Snyk integration\n- ❌ OWASP ZAP integration\n\n#### Monitoring & Observability\n- ⚠️ Error tracking (Sentry exists in frontend, needs backend)\n- ❌ Performance monitoring\n- ❌ Uptime monitoring\n- ❌ Log aggregation\n- ❌ Application metrics\n\n#### Advanced Practices\n- ❌ ADR review process\n- ❌ Release notes automation\n- ❌ Hotfix branch workflow\n- ❌ Release branch workflow\n- ❌ GPG-signed commits\n- ❌ Workflow dispatch triggers\n\n---\n\n## Implementation Roadmap\n\n### Phase 1: Critical Foundation (P0) - Immediate\n\n**Goal:** Establish essential documentation and security baseline\n\n1. **Verify GitHub Security Features**\n   - [ ] Enable Dependabot alerts in repository settings\n   - [ ] Enable secret scanning in repository settings\n   - [ ] Enable push protection in repository settings\n   - [ ] Enable code scanning (CodeQL) in repository settings\n   - [ ] Enable private vulnerability reporting\n\n2. **Verify Branch Protection**\n   - [ ] Configure branch protection rules for `main`\n   - [ ] Require pull request reviews (at least 1)\n   - [ ] Require status checks to pass\n   - [ ] Require branches to be up to date\n   - [ ] Document branch protection strategy\n\n3. **Enhance Core Documentation**\n   - [ ] Enhance README.md with more comprehensive examples\n   - [ ] Create CODE_OF_CONDUCT.md\n   - [ ] Enhance CONTRIBUTING.md with more detail\n   - [ ] Enhance SECURITY.md with more comprehensive guidelines\n\n**Estimated Time:** 2-4 hours\n**Priority:** P0 (Critical)\n\n---\n\n### Phase 2: Essential Automation (P1) - Short-term\n\n**Goal:** Implement essential automation and tooling\n\n1. **Dependency Management**\n   - [ ] Create `.github/dependabot.yml` configuration\n   - [ ] Configure automated dependency updates\n   - [ ] Set up dependency review in PRs\n\n2. **Issue & PR Templates**\n   - [ ] Create `.github/ISSUE_TEMPLATE/` directory\n   - [ ] Create bug report template\n   - [ ] Create feature request template\n   - [ ] Create question template\n   - [ ] Enhance PR template if needed\n\n3. **Git Configuration**\n   - [ ] Create `.gitattributes` file\n   - [ ] Create `.editorconfig` file\n   - [ ] Create `.gitmessage` commit template\n   - [ ] Document commit message conventions\n\n4. **Code Quality Enhancements**\n   - [ ] Set coverage thresholds in CI\n   - [ ] Add coverage badges to README\n   - [ ] Document code quality standards\n\n**Estimated Time:** 4-6 hours\n**Priority:** P1 (High)\n\n---\n\n### Phase 3: Advanced Practices (P2) - Medium-term\n\n**Goal:** Implement advanced automation and best practices\n\n1. **Release Automation**\n   - [ ] Create release workflow\n   - [ ] Set up automated changelog generation\n   - [ ] Implement version automation\n   - [ ] Create release notes template\n\n2. **Advanced Documentation**\n   - [ ] Create ROADMAP.md\n   - [ ] Create VISION.md\n   - [ ] Create WORKING_AGREEMENT.md\n   - [ ] Create DEFINITION_OF_DONE.md\n   - [ ] Create DEFINITION_OF_READY.md\n   - [ ] Create CODE_REVIEW_CHECKLIST.md\n\n3. **Monitoring & Observability**\n   - [ ] Set up backend error tracking (Sentry)\n   - [ ] Configure performance monitoring\n   - [ ] Set up uptime monitoring\n   - [ ] Implement log aggregation\n\n4. **Advanced Security**\n   - [ ] Integrate Snyk (optional)\n   - [ ] Set up OWASP ZAP scanning (optional)\n   - [ ] Implement dependency review workflow\n\n**Estimated Time:** 8-12 hours\n**Priority:** P2 (Medium)\n\n---\n\n### Phase 4: Enterprise Enhancements (P3) - Long-term\n\n**Goal:** Implement enterprise-grade features\n\n1. **Advanced Metrics**\n   - [ ] Set up code complexity tracking\n   - [ ] Implement technical debt tracking\n   - [ ] Create code quality dashboard\n   - [ ] Set up SonarQube/SonarCloud\n\n2. **Advanced Workflows**\n   - [ ] Implement hotfix branch workflow\n   - [ ] Create release branch strategy\n   - [ ] Set up GPG-signed commits\n   - [ ] Add workflow dispatch triggers\n\n3. **Documentation Automation**\n   - [ ] Set up documentation linting\n   - [ ] Track documentation coverage\n   - [ ] Automate API documentation updates\n\n4. **Additional Features**\n   - [ ] Create AUTHORS.md\n   - [ ] Create CITATION.cff (if applicable)\n   - [ ] Set up ADR review process\n   - [ ] Implement Renovate (alternative to Dependabot)\n\n**Estimated Time:** 12-16 hours\n**Priority:** P3 (Low)\n\n---\n\n## Summary Statistics\n\n### Current State\n- **Total Best Practices Identified:** 150+\n- **Currently Implemented:** ~85 (57%)\n- **Partially Implemented:** ~15 (10%)\n- **Missing:** ~50 (33%)\n\n### By Category\n- **Documentation:** 60% complete\n- **Security:** 70% complete (needs verification)\n- **CI/CD:** 80% complete\n- **Git Workflow:** 70% complete\n- **Automation:** 50% complete\n- **Advanced Practices:** 40% complete\n- **Agentic Workflow:** 95% complete (unique strength)\n\n### Strengths\n1. **Excellent agentic workflow framework** - Unique and comprehensive\n2. **Strong CI/CD pipeline** - Comprehensive testing and security\n3. **Well-organized structure** - Clear module boundaries\n4. **Good documentation foundation** - Organized documentation structure\n\n### Areas for Improvement\n1. **GitHub security features** - Need verification and configuration\n2. **Dependency management automation** - Missing Dependabot/Renovate\n3. **Issue/PR templates** - Missing issue templates\n4. **Advanced automation** - Release automation, changelog generation\n5. **Monitoring** - Backend error tracking, performance monitoring\n\n---\n\n## Recommendations\n\n### Immediate Actions (This Week)\n1. Verify and enable all GitHub security features\n2. Configure branch protection rules\n3. Create CODE_OF_CONDUCT.md\n4. Set up Dependabot\n\n### Short-term Actions (This Month)\n1. Create issue templates\n2. Enhance documentation\n3. Set up coverage thresholds\n4. Create `.gitattributes` and `.editorconfig`\n\n### Medium-term Actions (Next Quarter)\n1. Implement release automation\n2. Set up monitoring and observability\n3. Create advanced documentation files\n4. Enhance security tooling\n\n### Long-term Actions (Ongoing)\n1. Implement advanced metrics\n2. Set up enterprise-grade monitoring\n3. Continuous improvement of automation\n4. Regular review and update of best practices\n\n---\n\n## Notes\n\n- This repository has a **unique strength** in its agentic workflow framework, which is more advanced than typical repositories\n- The **CI/CD pipeline is comprehensive** and well-structured\n- **Documentation structure is excellent**, but some standard files are missing\n- **Security tooling is in place**, but GitHub features need verification\n- **Focus should be on automation** and standard documentation files\n\n---\n\n**Last Updated:** 2026-01-23\n**Next Review:** 2026-02-23\n"
        },
        {
          "path": ".repo/docs/TROUBLESHOOTING.md",
          "type": "Markdown",
          "purpose": "Troubleshooting guide",
          "used_by": [
            "Problem resolution"
          ],
          "content": "# Troubleshooting Guide\n\n**File**: `.repo/docs/TROUBLESHOOTING.md`\n\nThis guide helps resolve common issues with agent workflows and automation scripts.\n\n## Script Failures\n\n### HITL Creation Script Fails\n\n**Symptom:** `scripts/create-hitl-item.sh` fails with error\n\n**Possible Causes:**\n1. File permissions issue\n2. `.repo/hitl/` directory doesn't exist\n3. `.repo/policy/HITL.md` is locked or missing\n\n**Solutions:**\n1. Check permissions: `ls -la scripts/create-hitl-item.sh`\n2. Create directory: `mkdir -p .repo/hitl`\n3. Check HITL index: `cat .repo/policy/HITL.md`\n4. Manual creation: Create `HITL-XXXX.md` in `.repo/hitl/` and update `.repo/policy/HITL.md` manually\n\n### Logging SDK Fails\n\n**Symptom:** `agent-logger.js` throws errors or doesn't write logs\n\n**Possible Causes:**\n1. `.agent-logs/` directory doesn't exist\n2. File permissions issue\n3. Disk space full\n\n**Solutions:**\n1. Create directories: `mkdir -p .agent-logs/{interactions,errors,metrics}`\n2. Check permissions: `ls -la .agent-logs/`\n3. Check disk space: `df -h`\n4. Graceful fallback: Logging failures are non-blocking - workflow continues\n\n### Validation Script Fails\n\n**Symptom:** `validate-agent-context.js` fails validation\n\n**Possible Causes:**\n1. JSON syntax error in context file\n2. Missing required fields\n3. Schema validation failure (ajv not installed)\n\n**Solutions:**\n1. Check JSON syntax: `cat .agent-context.json | python -m json.tool`\n2. Review schema: `.repo/templates/AGENT_CONTEXT_SCHEMA.json`\n3. Install dependencies: `cd .repo/automation/scripts && npm install`\n4. Basic validation: Script falls back to basic checks if ajv not installed\n\n### Boundary Check Fails\n\n**Symptom:** `check-boundaries.js` or `lint-imports` fails\n\n**Possible Causes:**\n1. `import-linter` not installed\n2. `.importlinter` config file missing\n3. Actual boundary violations in code\n\n**Solutions:**\n1. Install: `pip install import-linter==2.0`\n2. Check config: `cat .importlinter`\n3. Fix violations: Review error output and refactor imports\n4. Create waiver: If exception needed (see `.repo/policy/QUALITY_GATES.md`)\n\n### Governance-Verify Fails\n\n**Symptom:** `governance-verify.sh` or `governance-verify.js` reports failures\n\n**Possible Causes:**\n1. Missing required artifacts\n2. HITL items not completed\n3. Boundary violations\n4. Stale context files\n\n**Solutions:**\n1. Review error output for specific failures\n2. Complete required HITL items\n3. Fix boundary violations\n4. Update context files: `node .repo/automation/scripts/update-context-verified.js --all`\n\n## Workflow Issues\n\n### Context Files Not Found\n\n**Symptom:** Agent can't find `.agent-context.json` files\n\n**Solutions:**\n1. Verify files exist: `find . -name \".agent-context.json\"`\n2. Check file paths in context files are correct\n3. Regenerate if needed: `node .repo/automation/scripts/generate-agent-context.js`\n\n### Pattern Files Out of Date\n\n**Symptom:** Patterns in `PATTERNS.md` don't match actual code\n\n**Solutions:**\n1. Review actual code in folder\n2. Update `PATTERNS.md` to match\n3. Update `.agent-context.json` patterns field\n4. Run verification: `node .repo/automation/scripts/pattern-verification.js`\n\n### Task Packet Missing\n\n**Symptom:** `governance-verify` reports missing task packet\n\n**Solutions:**\n1. Create task packet: See `.repo/agents/QUICK_REFERENCE.md` Task Packet Workflow\n2. Store in `.repo/tasks/packets/TASK-XXX-packet.json` or include in `TODO.md`\n3. Link in PR description\n\n## Recovery Procedures\n\n### When Scripts Fail Completely\n\n1. **Check logs:** Review error messages carefully\n2. **Manual steps:** Follow manual procedures documented in this guide\n3. **Create HITL:** If issue is blocking, create HITL item for help\n4. **Bypass (temporary):** Only if absolutely necessary, create waiver (see `.repo/policy/QUALITY_GATES.md`)\n\n### When Workflow Is Blocked\n\n1. **Identify blocker:** Review HITL items, waivers, or quality gate failures\n2. **Resolve blocker:** Complete HITL items, fix violations, or create waivers\n3. **Re-run verification:** `./scripts/governance-verify.sh`\n\n### When Context Files Are Stale\n\n1. **Check staleness:** `node .repo/automation/scripts/check-stale-context.js`\n2. **Update files:** `node .repo/automation/scripts/update-context-verified.js --all`\n3. **Verify patterns:** Review actual code and update patterns if needed\n\n## Getting Help\n\n- **Policy questions:** See `.repo/policy/` directory\n- **Workflow questions:** See `.repo/agents/QUICK_REFERENCE.md`\n- **Blocking issues:** Create HITL item in `.repo/policy/HITL.md`\n- **Script issues:** Check this troubleshooting guide first\n\n---\n\n**Last updated:** 2026-01-23\n"
        },
        {
          "path": ".repo/hitl/README.md",
          "type": "Markdown",
          "purpose": "HITL directory documentation",
          "used_by": [
            "Understanding HITL structure"
          ],
          "content": "# HITL Items Directory\n\n**File**: `.repo/hitl/README.md`\n\nThis directory contains individual HITL (Human-In-The-Loop) item files.\n\n## Format\nEach HITL item is stored as `HITL-XXXX.md` where XXXX is a sequential number.\n\n## Index\nSee `.repo/policy/HITL.md` for the index of active and archived HITL items.\n\n## File Naming\n- Format: `HITL-0001.md`, `HITL-0002.md`, etc.\n- Sequential numbering ensures uniqueness\n- Leading zeros for sorting\n\n## Status\n- Active items are tracked in `.repo/policy/HITL.md` Active table\n- Completed/Superseded items are moved to Archived table\n- Item files remain in this directory for historical reference\n"
        },
        {
          "path": ".repo/waivers/",
          "type": "Directory",
          "purpose": "Waiver files storage",
          "used_by": [
            "Waiver management"
          ],
          "content": null
        },
        {
          "path": ".repo/traces/",
          "type": "Directory",
          "purpose": "Trace log storage",
          "status": "Empty (infrastructure ready, awaiting first use)",
          "used_by": [
            "Trace log storage"
          ],
          "content": null
        },
        {
          "path": ".repo/logs/",
          "type": "Directory",
          "purpose": "Agent log storage",
          "status": "Empty (infrastructure ready, awaiting first use)",
          "used_by": [
            "Agent log storage"
          ],
          "content": null
        },
        {
          "path": ".agent-logs/",
          "type": "Directory",
          "purpose": "Agent interaction logs (from agent-logger.js)",
          "subdirectories": [
            "interactions/ (YYYY-MM-DD.jsonl files)",
            "errors/ (YYYY-MM-DD.jsonl files)",
            "metrics/ (YYYY-MM-DD.json files)"
          ],
          "status": "Directories exist, may be empty",
          "used_by": [
            "agent-logger.js"
          ],
          "content": null
        },
        {
          "path": ".repo/archive/assessments/",
          "type": "Directory",
          "files": "11 markdown files",
          "purpose": "Archived assessment documents",
          "status": "Historical reference only (not for agents)",
          "content": null
        }
      ]
    }
  },
  "statistics": {
    "file_counts": {
      "root_entry_points": 2,
      "policy_files": 7,
      "agent_framework_files": 17,
      "task_management_files": 6,
      "templates_schemas": 20,
      "automation_scripts": 18,
      "shell_scripts": 25,
      "context_files": 11,
      "folder_guides": 6,
      "cicd_integration": 3,
      "supporting_documentation": 15,
      "total": 120
    }
  },
  "key_directories": {
    ".repo/policy/": {
      "purpose": "Governance policies",
      "key_files": [
        "CONSTITUTION.md",
        "PRINCIPLES.md",
        "SECURITY_BASELINE.md"
      ]
    },
    ".repo/agents/": {
      "purpose": "Agent framework",
      "key_files": [
        "rules.json",
        "QUICK_REFERENCE.md",
        "checklists/",
        "roles/",
        "prompts/"
      ]
    },
    ".repo/tasks/": {
      "purpose": "Task management",
      "key_files": [
        "TODO.md",
        "BACKLOG.md",
        "ARCHIVE.md"
      ]
    },
    ".repo/templates/": {
      "purpose": "Templates & schemas",
      "key_files": [
        "PR_TEMPLATE.md",
        "ADR_TEMPLATE.md",
        "schemas",
        "examples/"
      ]
    },
    ".repo/automation/scripts/": {
      "purpose": "Node.js automation",
      "key_files": [
        "governance-verify.js",
        "agent-logger.js",
        "validation scripts"
      ]
    },
    "scripts/": {
      "purpose": "Shell scripts",
      "key_files": [
        "governance-verify.sh",
        "archive-task.py",
        "create-hitl-item.sh"
      ]
    },
    ".repo/hitl/": {
      "purpose": "HITL items",
      "key_files": [
        "HITL-XXXX.md files"
      ]
    },
    ".repo/waivers/": {
      "purpose": "Waivers",
      "key_files": [
        "WAIVER-XXX.md files"
      ]
    },
    ".repo/traces/": {
      "purpose": "Trace logs",
      "key_files": [
        "TASK-XXX-trace.json files"
      ]
    },
    ".repo/logs/": {
      "purpose": "Agent logs",
      "key_files": [
        "Agent log files"
      ]
    },
    ".agent-logs/": {
      "purpose": "Interaction logs",
      "subdirectories": [
        "interactions/",
        "errors/",
        "metrics/"
      ]
    }
  },
  "integration_points": {
    "cicd_integration": {
      "makefile": "check-governance target calls scripts/governance-verify.sh",
      "pre_commit": ".pre-commit-config.yaml includes governance-verify hook",
      "github_actions": "Template exists (.repo/automation/ci/governance-verify.yml) but needs integration",
      "hitl_sync": "scripts/sync-hitl-to-pr.py syncs HITL status to PRs"
    },
    "command_resolution": {
      "source_of_truth": ".repo/repo.manifest.yaml",
      "resolution": "Commands resolve to Makefile targets or direct scripts",
      "rule": "Agents MUST use manifest, never guess commands"
    },
    "workflow_integration": {
      "entry_point": "AGENTS.json or AGENTS.md",
      "reading_order": "TODO.md → manifest.yaml → rules.json/QUICK_REFERENCE.md",
      "pass_0": "Read .agent-context.json and .AGENT.md when entering folder",
      "pass_1_3": "Three-pass workflow (Plan → Change → Verify)"
    }
  },
  "dependencies": {
    "core": [
      {
        "from": "AGENTS.json",
        "to": [
          "TODO.md",
          "manifest.yaml",
          "rules.json",
          "policy files"
        ]
      },
      {
        "from": "rules.json",
        "to": [
          "CONSTITUTION.md",
          "PRINCIPLES.md",
          "manifest.yaml"
        ]
      },
      {
        "from": "QUICK_REFERENCE.md",
        "to": [
          "All policy files",
          "manifest",
          "templates"
        ]
      },
      {
        "from": "governance-verify.js",
        "to": [
          "agent-logger.js",
          "check-artifacts-by-change-type.js",
          "check-boundaries.js",
          "validate-agent-context.js"
        ]
      },
      {
        "from": ".agent-context.json",
        "to": [
          "AGENT_CONTEXT_SCHEMA.json"
        ]
      },
      {
        "from": "archive-task.py",
        "to": [
          "TODO.md",
          "BACKLOG.md",
          "ARCHIVE.md"
        ]
      },
      {
        "from": "create-hitl-item.sh",
        "to": [
          ".repo/hitl/HITL-XXXX.md",
          ".repo/policy/HITL.md"
        ]
      }
    ],
    "external": [
      {
        "name": "lint-imports",
        "purpose": "Boundary checking",
        "type": "Python package"
      },
      {
        "name": "ajv",
        "purpose": "JSON schema validation",
        "type": "Node.js package",
        "optional": true,
        "fallback": true
      },
      {
        "name": "requests",
        "purpose": "GitHub API",
        "type": "Python package",
        "optional": true
      },
      {
        "name": "pre-commit",
        "purpose": "Git hooks framework",
        "type": "Python package"
      },
      {
        "name": "ruff, black, mypy",
        "purpose": "Python tooling",
        "type": "Python packages"
      },
      {
        "name": "ESLint, Prettier",
        "purpose": "Frontend tooling",
        "type": "Node.js packages"
      }
    ]
  },
  "file_status": {
    "production_ready": [
      "All policy files (CONSTITUTION.md, PRINCIPLES.md, etc.)",
      "All agent framework files (rules.json, QUICK_REFERENCE.md, etc.)",
      "All templates and schemas",
      "Core automation scripts (governance-verify.js, agent-logger.js, etc.)",
      "Core shell scripts (governance-verify.sh, archive-task.py, promote-task.sh)",
      "All context files (.agent-context.json)",
      "All folder guides (.AGENT.md)",
      "Makefile integration",
      "Pre-commit configuration"
    ],
    "needs_verification": [
      "Pre-commit hooks installation status",
      "GitHub Actions workflow integration (template exists, needs integration)",
      "Agent logger actual usage by agents (SDK exists, used by scripts, unclear if agents call it)"
    ],
    "missing_incomplete": [
      "Learning from failures (no analysis scripts)",
      "Self-healing (no retry logic, no automatic recovery)",
      "Auto-triggering (scripts exist but not scheduled)",
      "Trend analysis (no historical analysis)",
      "Pattern extraction from code (basic verification exists, no extraction)"
    ]
  },
  "usage_patterns": {
    "agent_startup_flow": [
      "Read AGENTS.json or AGENTS.md",
      "Read .repo/tasks/TODO.md (current task)",
      "Read .repo/repo.manifest.yaml (commands)",
      "Read .repo/agents/rules.json or QUICK_REFERENCE.md (rules)",
      "Enter folder → Read .agent-context.json and .AGENT.md (Pass 0)"
    ],
    "task_completion_flow": [
      "Mark criteria [x] in TODO.md",
      "Run scripts/archive-task.py",
      "Script archives task to ARCHIVE.md",
      "Script promotes next task from BACKLOG.md to TODO.md"
    ],
    "pr_creation_flow": [
      "Read .repo/agents/checklists/pr-review.md",
      "Read .repo/templates/PR_TEMPLATE.md",
      "Read .repo/policy/QUALITY_GATES.md",
      "Read .repo/policy/HITL.md (check blockers)",
      "Create PR with required sections",
      "Run governance-verify (checks artifacts, boundaries, HITL, etc.)"
    ],
    "hitl_flow": [
      "Agent encounters risky/unknown situation",
      "Agent runs scripts/create-hitl-item.sh",
      "HITL item created in .repo/hitl/HITL-XXXX.md",
      "Entry added to .repo/policy/HITL.md (Active table)",
      "Human reviews and marks Completed",
      "Agent runs scripts/sync-hitl-to-pr.py (updates PR)",
      "Agent runs scripts/archive-hitl-items.sh (moves to Archived)"
    ]
  }
}